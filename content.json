{"posts":[{"title":"2023.9.19 DailyNote","text":"2023-09-19 星期二2023.09.19 Tue 🌞 今年已过了 262 天（第 39 周/共 53 周）,距离 2024 年还有 103 天。距离 2023-11-04 高级-架构师考试还有 46 天。🗓️Weather：🌞🌥☁️⛈🌧🌦🌈🌪🌀⚡❄️🔥🥶🌊🌫🏠Location： 中国·广东省🛌Sleep：1：00 → 7：45 希望早日调整好作息时间 ⏰Must-To-Do 第一次发表… 没有早起 🚀️进展 自律：没有进展，依旧六块腹肌，单手五十俯卧撑 英法：菜够，法语真的难学 遇见：无，又是平凡的一天 其他：参加斗地主比赛 🐣Mini-Habits 月计划与反思 每日Golang 数据结构和算法 回顾昨天 每天早起 🧠今日反省思源功能太强大… 已经玩不明白了… 日历配置这个DailyNote template 配置原理又忘记了… 算了… 毕竟只是工具而已 争取每日后续更新一篇博客 日记推送到timeline​tag下 大概一周一次 看心情决定是否发布 随机复习 距离 2024-07-01​ 还剩 285​ 天，加油，你一定行！ 随机复习是一个好习惯，可惜现在笔记内容提炼不够精简，就不放到博客上展示了….","link":"/post/20230919-tuesday-uuzu4.html"},{"title":"命运齿轮","text":"命运齿轮2023.10.14 Sat 🌞 今年已过了 287 天（第 42 周/共 53 周）,距离 2024 年还有 78 天。距离 2023-11-04 高级-架构师考试还有 21 天。🗓️Weather：🌞🌥☁️⛈🌧🌦🌈🌪🌀⚡❄️🔥🥶🌊🌫🏠Location： 中国·广东省🛌Sleep：5.30 → 12 熬了个大夜-深夜思考人生《痛苦面具》 ⏰Must-To-Do ‍ 🚀️进展 自律：周五晚拉满了，游泳0.5h、力量训练1h、骑车10KM、跑步5kM 25min、核心训练0.5h 英法：IOS 播客很好用 遇见：清华经管-混血修勾？？ 其他：努力永远不会错 🐣Mini-Habits 月计划与反思 每日Golang 数据结构和算法 回顾昨天 每天早起 🧠今日反省 我发现很多技术手段，或者思想在某种程度上都是类似的，到一定阶段必然是融汇贯通的。 很多知识会就是会，不会就是不会，如果一些问题有过自己的思考量，即使知识本身的内容记不住，但是这个逻辑关系，逻辑追溯还是很重要的 最近玩且看狼人杀，记忆力好真的很关键，逻辑梳理更是一种能力，需要培养 ✨随缘记随便写点什么吧…. 缓存的分片有用到哈希算法与一致性哈希算法，同等联想到负载均衡的一种策略，也是一致性哈希算法，瞬间有点悟，好多其实都是相通的… ‍","link":"/post/20231014-saturday-zh8hf1.html"},{"title":"2023.8.30","text":"2023.8.30从今天起，要狠狠滴加练，潶櫹潶櫹！！！ ‍","link":"/post/2023830-zy8cbl.html"},{"title":"几个后端的问题","text":"6.14 以下几个简单但并不简单的问题验证下自己的后端能力水平 业务Rpc服务如何理解 什么场景下应用RPC 是远程调用协议，服务之间只需要维持一个通信协议即可，不需要对编程语言有任何限制，也不用关系底层网络协议。多数是用在微服务、分布式场景下。 分布式下rpc如何调用可以通过注册中心+服务发现的方式实现调用，市面上很多组件比如consul、etcd等等都可以实现。 负载均衡策略有哪些 你们公司用的是哪种包括轮询、随机、加权、一致性哈希及最小连接数等。我们用的是轮询方式。 这个最好是有自己实现过的代码。 手写负载均衡、手写缓存中间件…后续再补充 Rpc协议和HTTP协议如何理解，有什么区别 RPC协议是远程调用协议，HTTP是超文本传输协议； RPC多用在微服务分布式和内部调用，HTTP多用在外部api服务； RPC的调用速度快于HTTP，但HTTP的实现要比RPC简单很多。 RPC有什么优势 为什么有这种优势RPC 不要考虑编程语言，服务只需要维持一个通信协议即可；调用速度非常的快；封装了很多方法，比如负载均衡等；适用于分布式微服务场景，内部扩展型较好。 为什么有这种优势不会答，我估计是要深入到socket层面 月百万级数据以上，总共一亿数据如何管理 优化思路如果是这种场景可以根据时间来划分，按月水平分表，这种思路，可以及时清理掉冷数据，如果在业务评估阶段就估计月表的数据量是百万级，且又可能在业务高峰期上升到千万或者亿界别的数据，那么可以考虑多一个月的数据再次分片，按照大小拆分，建议500w数据量拆分一个，虽然单表的数据量在2000w的时候，MySQL也能维持较好的层数，但是考虑到性能等问题，参考阿里巴巴数据库的设计思路，他们在海量数据的业务场景下经验丰富，比较推荐500w拆分一张 另外一种思路是根据用户id来进行hash分片拆分，多个MySQL部署，举个例子通过userid来计算哈希函数，然后和哈希掩码取模，可以快速定位到用户的数据存储在哪一个实例中，比较推荐使用MyCat这种业内比较成熟的数据库分片组件。 按月分表情况下(几十张表），这种情况下如何查某个用户的所有的订单可以加一层设计，比如用Redis的Hash结构，用户的userid作为key，list作为field，value是所有的订单信息的月份、id等，可以快速定位表位置、索引的信息。 12345678910111213141516{ &quot;user_id_1&quot;: { &quot;order_info&quot;: { &quot;2022-01&quot;: [&quot;order_1&quot;, &quot;order_2&quot;], &quot;2022-02&quot;: [&quot;order_3&quot;], &quot;2022-03&quot;: [&quot;order_4&quot;, &quot;order_5&quot;] } }, &quot;user_id_2&quot;: { &quot;order_info&quot;: { &quot;2022-01&quot;: [&quot;order_6&quot;, &quot;order_7&quot;], &quot;2022-02&quot;: [&quot;order_8&quot;], &quot;2022-03&quot;: [&quot;order_9&quot;, &quot;order_10&quot;] } }} 在这个示例中，每个 userid 都是 Hash 表的 key，而对应的 value 是一个包含了 order_info​ 这个 field。order_info​ 是一个内部的 Hash 结构，它使用年月（例如 “2022-01”）作为 field，而对应的值是一个列表，包含该用户在该月份下的所有订单编号。 通过这种设计，你可以快速定位到指定用户的订单信息，并按照不同月份进行索引。例如： 获取某个用户的所有订单：使用 HGETALL user_id_x 命令获取该用户的完整信息，然后再读取其中的 order_info​ 字段即可得到该用户在不同月份下的订单列表。 获取某个用户指定月份的订单信息：使用 HGET user_id_x order_info:YYYY-MM 命令获取对应月份的订单列表。 需要注意的是，为了保证不同月份的订单信息不会相互冲突，每个月份的 field 最好采用类似 “YYYY-MM” 的格式进行命名。 这种结构可以帮助你更好地组织和索引订单信息，同时也提供了快速定位、查询和统计的能力。 可以实现以下快速定位和索引的优势： 快速访问指定用户的订单信息：通过用户的 userid 作为 key，直接从 Redis 中获取对应的 Hash 结构，从而快速获取该用户的订单信息。 快速定位到指定年月的订单列表：在用户的订单信息中，使用年月作为 field，可以直接访问指定年月的订单列表，而无需遍历整个订单信息。 高效添加和删除订单信息：使用 Redis 的 List 结构存储订单列表，可通过头尾插入和删除操作，快速添加和删除订单，而不会影响其他年月的订单列表。 订单状态怎么查（已支付，待支付，待发货这种）设定字段订单状态status，通过上述的redis方案快速在数据库中查询，这里正好使用了Redis，可以设定缓存，但这就涉及到数据库和缓存更新的一致性问题了，写操作先更新数据库再删除缓存，读如果命中则直接返回，没命中则读取后写入缓存的方案可以避免。 如果用热点数据如何定义热点数据可以用 Redis 的 Zset 来给数据进行评分，这里的热点可以以时间、点击量、购买数等等因素综合考量。 订单状态转换如何更新？如何保持同步这个在上面已经说明了，写是先更新数据库再删除缓存，读是命中则返回，没命中则读取后写入缓存保持同步。这里同样需要保证了两步操作同时执行成功，可以用两种方案来保证，一种是重试机制，将操作发送到消息队列中，执行成功则在消息队列中删除该信息，如果失败则重新读取这条消息，超过一定次数则向上游返回报错，第二种方案是订阅MySQL的binlog日志，由于MySQL执行完之后会将操作记录在binlog里，所以可以使用binlog来找到具体的操作，这里推荐使用阿里巴巴的canal组件，他的思想就是模拟了mysql主从的交互协议实现这个功能。 服务器线上问题有排查过吗，怎么定位问题所在，整体链路讲讲，比如504这种问题。结合实际场景和原因进行分析有排查过，首先思路是并不是问题出现了再去排查问题，我们先要设计一套预防方案，如果是常规的报错问题，可以通过日志、链路追踪查询定位到，如果是服务崩溃等信息，可以通过监控报警，比如grafana，包括在CPU、内存负载压力过高的时候可以提前预警人工介入。 真的是线上出现了bug、崩溃、超时等问题，那么整体流程是，先通过链路追踪定位返回错误信息或者崩溃的服务是哪个，查看服务崩溃的日志的具体原因，精确到代码行，如果无法从代码的逻辑角度排查问题，我们要看CPU、内存的使用情况，通过系统监控确定是哪一个环节出问题，然后查看是否是内存泄漏、SQL慢查询、GC异常等问题。 504 是属于 http请求返回超时的问题，举一个实际场景的例子，比如我做过一个音视频合成的例子，之前我调用合成api接口的超时，然后返回给上游的调度服务错误信息，定位到是我服务返回的超时，模拟了当时的请求信息，通过链路追踪，在jager上查看了收到合成api请求的时间耗时过长，解决方案是，最开始合成方是用http的方式返回合成url，后来我们采用grpc 流式传输的方案可以实时返回，在没接收到结束信号时，不断开链接。 502 和 504 区别 502 是网络无法请求，接收到错误的响应； 504 是网络请求，但是接受响应超时； MySQL慢查询有涉及过吗？如果用了索引还是慢查询该怎么办 ？慢查询可以通过 MySQL 的慢查询日志查到，不过默认 MySQL 的慢查询日志是关闭的。 如果用了索引还是慢查询，可以使用 explain 命令来查看 sql 语句的执行计划，可以查看是否正常使用了索引，排查是否存在索引失效的可能。另外排查是否是数据库的参数，比如缓存、连接等待等问题。 数据量过大该如何优化数据量过大可以考虑分库分表了。分库就是根据实际场景将数据分散到多个库，分表是将数据拆分成多个表，防止单表过大。 如何分库分表 垂直拆分：由于前期表的设计没有抽象，所以这时候要根据关系性较强的几个字段对表进行拆分。一种思路是将长度比较大、不常用的信息，移到扩展表。 水平拆分：将一张大表拆分成数据结构相同的几个表，防止单表过大。 这里举个商城的例子来说明，我们可以拆分成订单信息库、用户信息库、商品详情库，每个库中的表的数据量过于庞大，比如超过500万行就可以考虑水平拆分，如果有几个关系性较强的字段，可以垂直拆分建立一张新表，具体根据自己的业务实际场景来进行扩展。 你常用的索引有哪些 结合业务说明 按照类型分类：B+ 数索引，哈希索引，fulltext索引； 按照存储方式分类：聚簇索引和非聚簇索引； 按照使用的列分类：联合索引和单一索引； 按照使用的字段分类：主键索引、唯一索引、前缀索引和普通索引。 常用的是联合索引和主键索引，比如通过id直接查询一条记录的完整信息，我们可以使用主键索引快速定位，再比如联合性比较强的两个字段，可以建立联合索引，比如要查询年龄为x、成绩是y的成员name，可以用（x，y，name）建立联合索引，利用覆盖索引可以减少回表。 什么是聚簇索引，什么是非聚簇索引，它们有什么区别聚簇索引具有唯一性，比如主键就是聚簇索引，如果没有主键会选择唯一且不为NULL的列作为主键索引，如果没有则会生成一个自增id作为主键索引。聚簇索引存放的信息是完整的数据记录，而非聚簇索引只存放聚簇索引信息。如果查询语句使用的是非聚簇索引，且查询的数据不是主键值，会在叶子节点找到主键值后进行回表，如果是主键值就会进行索引覆盖。 主键索引的底层存储结构 大致实现过程B+ 树。B+ 树是由 B 树改进而来的，所有的索引都存放在叶子节点，并构成有序的链表，其实是双向链表，叶子节点的值存放的是数据页，数据页里包含完整的记录，而非叶子节点只存放索引，非叶子节点会作为叶子节点中索引的最大或者最小节点，比如举个例子，根节点存放的索引是 (1、10、19)，那么第二层就可以是 (1、4、7)，(10、13、16)，(19、22、25)，而第三层如果是叶子节点，就会存放完整的索引和数据。并且支持范围查询，由于 MySQL 的 B+ 树底层节点是双向链表，所以范围查询效率很高；B+ 树的非叶子节点只存放索引，可以存放更多的记录，所以相同数据量下，B+ 树更矮胖，减少了 磁盘 IO；B+ 树有大量的冗余节点，在插入和删除时不会发生过多的树结构变化。 非主键索引、联合索引等的存储结构B+ 树。 这些索引在存储数据时有什么区别主键索引的值是完整的数据记录，其他索引存储的值是主键索引，联合索引的key是多个字段，查询的时候按照最左匹配原则。 主键索引的索引信息存在哪里叶子节点 MySQL的数据存在哪里存在磁盘中，如果是 InnoDB 引擎，则会按照三个文件存放，db.opt 存放的是数据库设置的默认字符集和字符校验规则，.frm 文件是存放表的结构信息，比如列、数据类型、索引等，.ibd 是存放数据的内容。 范围查询时主键索引是如何去做的首先通过二分查找定位到边界，然后通过双向链表，开始遍历即可。 什么是索引覆盖索引覆盖是在联合索引是，查询的内容在联合索引的key上就可以查到，避免了回表。比如联合索引（x，y），现在想通过x条件查询y的内容，就可以使用（x，y）避免再次回表。 MySQL用过什么存储引擎常见的是 Innodb、MyISAM、Memory等。现在默认是 InnoDB。 InnoDB有什么特性 存储：存放在 .frm、.ibd文件； 索引：支持聚簇索引和非聚簇索引； 事务：有undo log 和 redo log，支持事务； 故障恢复：有 redo log，支持故障恢复； 锁：支持表级锁和行级锁； 就针对和 MyISAM 的区别聊 事务有什么特性ACID，原子性、隔离性、一致性、持久性。 可重复读是如何做的，如何实现的通过 MVCC 实现的。 MySQL在事务启动后会为事务生成一个 Read View 快照，Read View 会记录当前事务的id、活跃的事务id列表、活跃事务id的最小值、下一个创建的事务id值，MySQL的行数据也会记录最新修改过这一行的事务id，同样会记录该行的上一版本记录的指针，像一个链表一样。当事务A启动后，事务B启动，事务B的活跃事务id列表就是A和B的事务id，现在事务要对一个行数据进行操作，如果活跃事务id列表的最小值比当前行数据记录的最新修改过这一行的事务id值大，说明最新操作该行数据记录的事务已经提交完成，所以可以对该行进行操作，如果大于下一个创建的事务id值，说明这个最新操作该行数据记录的事务是在当前事务A和B启动之后再启动的事务，那么就不可以对这行数据进行操作。之后要分两种情况讨论，如果在活跃的事务id列表之间，说明有其他事务在操作该行，那么不可以对该行操作，会去找该行记录的上一版本指针，如果不在则说明最新操作该行数据记录的事务已经提交，那么可以对该行进行操作，操作了之后，该行记录会更新最新修改这一样的事务id，同样以链表形式将上一版本记录连接起来。 MVCC 是如何做的上面那一段 如果commit 时，数据版本和快照版本不一致该怎么办回滚 如果加锁的话加的什么锁没懂要问啥，如果是问的可重复读里面的幻读问题，那就是间隙锁，如果带有记录的话是 nextkey lock（间隙锁+记录锁），举个例子： 事务A，执行了 for update 语句 当前读，查询大于等于 5 的记录，这时候事务 B，插入了一条 10 的记录，这样事务 A 如果再次查询的话，前后两次查询就会幻读，所以这时候会引入一个 next key lock，锁住 [5, +∞]的记录，（如果是大于 5 那就是间隙锁）。 Redis常用数据类型String、List、Hash、Set、Sort Set。 可以加上 Hyperloglog、Stream、Bitmap、Geospatial index 。 大 key 问题如何解决如果是 Set 结构则可以修改为 Hash，不要一次性全查。可以将大 key 拆分成多个小 key，读取的时候批量读取拼接即可。而且尽量给大 key 设置较长的过期时间，不让其在缓存中淘汰。删除可以用分批次删除或者异步删除的做法，避免阻塞主线程。 用的 Redis 单机还是集群集群 如何存数据不清楚要问的是底层数据结构还是持久化存储，底层数据结构就将五种基本类型的底层数据结构，持久化就是说 RDB 和 AOF 举个例子，String，如果存储 int 整形，可以用 long 表示，则用 int 来存储，如果是字符串，则小于等于 44 字节用 embstr 存储，其他情况是 raw。 RDB 和 AOF， 就是一个快照，一个追加日志，可能要问一些详细的过程了，还有刷盘策略等等。看具体想问什么。 讲讲主从复制由于 Redis 具有持久化能力（RDB 和 AOF），为了避免单点故障，可以引入主从模式，主机可以进行读写操作，每次的写操作都会同步数据给从机。主从模式主要是为了减轻主机压力以及容灾恢复。接下来大致介绍一下主从复制的流程： 建立好集群及主从关系后，从机会连接主机，发送 SYNC 命令，主机接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令，之后会向所有从机发送 RDB ，并在发送期间继续记录被执行的写命令，从机接收到后会载入执行，之后的每一个主机的写命令都会发送到从机执行，如果有断线重连会才用增量复制，补全缓冲区中的命令。 主服务器挂了怎么办哨兵模式会进行监控、选主、通知。首先是如何判断主服务器真的挂了，这里分为主观下线和客观下线，如果哨兵节点接受不到主服务器的信号就会认定为其主观下线，但是哨兵也是集群大的方式部署的，如果超过一半节点认为是主观下线就认定其客观下线。之后哨兵leader会从从机中选取一个新的主节点，进行主从故障转移，让原主下的所有从机都作为新的主机的从机，并且通过发布订阅通知客户端，另外会监控原主机的情况，如果原主机重新上线，那么会作为新主的从。 这里可能还会涉及到哨兵leader、选主策略、主从数据不一致的问题。 主服务器选举是怎么做的首先会找优先级最高的从节点，其次找复制进度最靠前的节点，最后通过id排序。 联想分布式算法原理…… ‍ ‍","link":"/post/614-1z6cwp.html"},{"title":"训练历程","text":"我的数据结构和算法知识体系我的算法体系由hello+代码随想录培养…. 相互补充 K神：力扣（LeetCode）全网阅读量最高博主，发表的《图解算法数据结构》已被订阅 27 万本。 本部分目的是巩固并加强对数据结构的全面理解，大学期间也有多的这门课程，但是内容有限，很难成为体系，算是一个基础的巩固，比起直接手撕LeetCode1000题，我感觉基础巩固更重要，重点记录新的理解。 待办： labuladong Cookbook LeetCode HOT 100 ‍","link":"/post/algorithm-system-1wyqpm.html"},{"title":"多个协程打印相关问题","text":"并发编程：多个协程打印​创建三个goroutine，分别输出1 4 7, 2 5 8, 3 6 9, ...... 100， 保证顺序输出1到100​ 1234567891011121314151617181920212223242526272829303132333435363738394041/** * @Author 560463 * @Description //TODO $ 并发：创建三个goroutine，分别输出1 4 7, 2 5 8, 3 6 9, ...... 100， 保证顺序输出1到100, 2种方法 * @Date 2023/10/12 14:36 **/// 实现三个协程并发交替打印数字// 方法一：package mainimport &quot;fmt&quot;var chanDone chan intvar end intvar countA, countB, countC intfunc write(name string, count int, ch, next chan int) { for a := range ch { //fmt.Println(a) count++ fmt.Printf(&quot;协程%s 第%d次打印了%d\\n&quot;, name, count, a) if a &lt; end { next &lt;- a + 1 } else { chanDone &lt;- 0 } }}func main() { ch1, ch2, ch3 := make(chan int, 1), make(chan int, 1), make(chan int, 1) countA, countB, countC = 0, 0, 0 chanDone, end = make(chan int), 100 go write(&quot;A&quot;, countA, ch1, ch2) go write(&quot;B&quot;, countB, ch2, ch3) go write(&quot;C&quot;, countC, ch3, ch1) ch1 &lt;- 1 &lt;-chanDone} ‍ 123456789101112131415161718192021222324252627282930313233343536//方法二：package mainimport &quot;fmt&quot;var wg sync.WaitGroupfunc r(name string, count int, start int, ch1, ch2 chan int) { defer wg.Done() for i := start; i &lt;= 100; { num, ok := &lt;-ch1 if !ok { close(ch2) break } count++ fmt.Printf(&quot;协程%s 第%d次打印了: %d\\n&quot;, name, count, num) i++ ch2 &lt;- i i = i + 2 //如果这样写有个坑：这样写第一次A是打印了1 但是给B的值也是1，虽然后面进行了+3 但是本轮打印时错误的 //ch2 &lt;- i //i = i + 3 }}func main() { chA, chB, chC := make(chan int, 1), make(chan int, 1), make(chan int, 1) countA, countB, countC := 0, 0, 0 wg.Add(3) chA &lt;- 1 go r(&quot;A&quot;, countA, 1, chA, chB) go r(&quot;B&quot;, countB, 2, chB, chC) go r(&quot;C&quot;, countC, 3, chC, chA) wg.Wait()} ‍ 结果： ​​ ​​ ‍ ‍ ​三个协程分别打印100次 cat dog fish​ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( &quot;fmt&quot; &quot;sync&quot;)// 三个协程交替打印 cat dog fishvar repeatCount = 100func main() { // wg 用来防止主协程提前先退出 wg := &amp;sync.WaitGroup{} wg.Add(3) chCat := make(chan struct{}, 1) defer close(chCat) chDog := make(chan struct{}, 1) defer close(chDog) chFish := make(chan struct{}, 1) defer close(chFish) go printAnimal(chCat, chDog, &quot;cat&quot;, wg) go printAnimal(chDog, chFish, &quot;dog&quot;, wg) go printAnimal(chFish, chCat, &quot;fish&quot;, wg) chCat &lt;- struct{}{} wg.Wait()}// wg 需要传指针func printAnimal(in, out chan struct{}, s string, wg *sync.WaitGroup) { count := 0 for { &lt;-in count++ fmt.Printf(&quot;第%d次打印%s\\n&quot;, count, s) out &lt;- struct{}{} if count &gt;= repeatCount { wg.Done() return } }} ‍ ​​","link":"/post/concorded-programming-multiple-corporate-printing-zpbnes.html"},{"title":"领域算法知识体系","text":"领域算法 最近一直有一个概念在脑子中循环：程序设计 = 数据结构 + 算法 基于目前的认知我想把算法分为常规算法思想和领域算法：常规算法思想如：分治、动态规划、贪心、二分、搜索等；本篇则是领域算法。 不论哪种技术栈或者组件都和算法离不开，比如gin的路由基数树、负载均衡各种算法、分布式一致性算法、和加密相关的安全算法、分布式ID雪花算法，因此准备抽一些时间好好整理并学习下这部分的内容，这部分我称之为领域算法，形成一个完整的知识体系，不求多深入、多底层，但求个人程度上的理解,快速形成知识体系。 ‍ ​​ ‍ 重点关注：负载均衡、雪花、一致性以及一点点大数据相关的，希望形成自己的理解","link":"/post/field-algorithm-1sbsuf.html"},{"title":"Goland 快捷键、模板与一些规范","text":"Goland 快捷键、模板与一些规范题记： 快捷键的使用可以大大提高效率，良好的注释对项目后续的开发维护工作也是十分必要。本文档旨在明确项目开发过程中go代码的注释规范，并提供基于goland的注释模板设置指导。便于开发人员快速配置环境，高效、合规开展工作。 规范部分随缘整理….. 我的配置 Go文件采用goland自带的go文件和代码模板 123456789101112/** * @Description //TODO * @Author luommy * @Date ${DATE} ${TIME} **/package ${GO_PACKAGE_NAME}// 我不习惯加这个func main() {} ​​​​ ‍ 方法、结构体、接口注释采用插件实现 ‍ 自定义快捷键与注释模板​自定义快捷键：CTRL+J​ ​​ 添加新建类的注释模板路径：File -&gt; Settings -&gt; File and Code Templates ​​ 添加如下信息： 123456789package ${GO_PACKAGE_NAME}/** * @Description //TODO * @Author luommy * @Date ${DATE} ${TIME} **/func main() {} 添加方法注释模板‍ Live Templates ​ go templates 内置函数‍ 在模板变量中使用的预定义函数有很多都用不到的，感觉并不好用，没啥能用到的场景 Item Description ​lowercaseAndDash(String)​​ 将驼峰字符串转换为小写，并插入连接符作为分隔符。例如,lowercaseAndDash(MyExampleName)​​返回my-example-name​​. ​snakeCase(String)​​ 将驼峰字符串转化为蛇形字符串，例如,snakeCase(fooBar)​​返回foo_bar​​. ​spaceSeparated(String)​​ 将字符串转化为小写并插入空格作为分隔符，例如,spaceSeparated(fooBar)​​returnsfoo bar​​. ​underscoresToCamelCase(String)​​ 将蛇形字符串转化为驼峰字符串. 例如,underscoresToCamelCase(foo_bar)​​返回fooBar​​. ​underscoresToSpaces(sParameterWithSpaces)​​ 将字符串中的下划线替换为空格. 例如,underscoresToSpaces(foo_bar)​​返回foo bar​​. ​camelCase(String)​​ 将字符串转化为驼峰法. 例如,camelCase(my-text-file)​​,camelCase(my text file)​​, 和camelCase(my_text_file)​​均返回myTextFile​​. ​capitalize(String)​​ 将参数的第一个字母大写。 ​capitalizeAndUnderscore(sCamelCaseName)​​ 根据驼峰法分割参数，将各个部分转化为大写，并插入下划线。例如,capitalizeAndUnderscore(FooBar)​​返回FOO_BAR​​. ​classNameComplete()​​ 这个表达式代替了在变量位置完成类名。 ​clipboard()​​ 返回系统剪贴板的内容。 ​complete()​​ 引用代码完成。 ​completeSmart()​​ 调用变量位置的智能类型完成。 ​concat(expressions...)​​ 返回传递给函数的所有字符串作为参数的级联。 ​date(sDate)​​ 以指定的格式返回当前系统日期。如果没有参数，则以默认的系统格式返回当前日期。 ​decapitalize(sName)​​ 用相应的小写字母替换参数的第一个字母。 ​enum(sCompletionString1,sCompletionString2,...)​​ 返回在模板扩展时建议完成的逗号分隔字符串的列表。 ​escapeString(sEscapeString)​​ Escapes the string specified as the parameter. ​expectedType()​​ Returns the expected type of the expression into which the template expands. Makes sense if the template expands in the right part of an assignment, afterreturn​​, etc. ​fileName()​​ 返回当前文件（包括扩展名） ​fileNameWithoutExtension()​​ 返回当前文件（不包括扩展名） ​firstWord(sFirstWord)​​ 返回作为参数传递的字符串的第一个单词。 ​lineNumber()​​ 返回当前行数。 ​substringBefore(String,Delimiter)​​ 删除指定分隔符之后的扩展名，只返回文件名。这对测试文件名是有帮助的，例如,substringBefore($FileName$,&quot;.&quot;)​​returnscomponent-test​​incomponent-test.js​​). ​time(sSystemTime)​​ 以指定的格式返回当前系统时间。 ​timestamp()​​ 返回当前系统时间戳 ​user()​​ 返回当前用户 ‍ ‍ 中英互译插件目前觉得挺好用的 支持自定义快捷键：setting-keymap-plugins 习惯设置Alt+T 一键互译 ​​ 注释插件：Goanno插件市场安装，通过tools进行配置——Goanno Setting ​​​​ 方法、接口、结构体注释模板配置​​ 配置内容如下： 123456789101112131415161718192021222324Normal Method 配置内容：/** @Title ${function_name} @Description ${todo} @Author luommy ${date} @Param ${params} @Return ${return_types} **/interface配置内容// ${interface_name} Interface Method 配置内容// @Title ${function_name} // @Description ${todo} // @Author luommy ${date} // @Param ${params} // @Return ${return_types} Struct配置内容// ${struct_name} Struct Field 不做配置 配置完成点击submit 验证注释 在方法、结构体、接口上 win使用快捷键: ctrl +alt +/​ mac使用快捷键:control + commond + /​ 可自动生成注释 如下截图: ​ AI 插件 CodeGeeX官网 几个重点的功能： 多语言代码之间翻译，无缝转换 注释生成代码/自动补全代码 AI问答","link":"/post/goland-shortcut-key-template-and-some-specifications-z2131hx.html"},{"title":"","text":"Golang 📄 Go典型使用·实例 📑 重学系列 📄 Go经验小记 📄 练习两年半释疑 📄 Go新版本特性 📄 最常用的 Go CLI 命令 📄 重学Go语言 | 如何在Go中使用Context 📑 Go并发编程 📄 Go语言实现的可读性更高的并发神库 🥗 Golang门面担当 📄 GMP模型的知识体系 📄 Go 语言五大日志库 📄 Go语言——延迟函数defer的使用 📄 Go语言——Map的底层介绍及扩缩容机制 📄 Go语言——切片(Slice)的坑 📄 Go语言——内存管理 📑 专项 📄 Gorm框架的思考 📄 Go与操作系统的线程（进程）间通信 📄 Go单机锁与同步原语 📄 深入解析go channel各状态下的操作结果 📄 解密Go协程的栈内存管理 📄 Golang实现延迟队列（DelayQueue） 📄 go channel的应用案例 📑 Gin深入理解 📄 Gin框架流程原理以及上下文、内存的思考 📄 我给 gin 提交了一行代码 - 墨天轮 📄 由Gin路由原理引发的一系列思考 📄 Gin路由设计及源码分析：httprouter路由实现原理 📄 Gin生命周期 📑 Google书签整理 📄 Go Modules 依赖管理，这篇总结的挺全 📄 最全Go select底层原理，一文学透高频用法 📄 剑指 Offer 38. 字符串的排列 📄 阅读破10万的学Go建议，不管初学还是进阶Go都值得一看！ 📍 日常小结 📄 【Golang】来几道题以加强切片知识 📄 goland-IDEOlog 插件 📄 Rob Pike谈Google Go 📄 Go的数组与切片傻傻分不清楚 📄 Go获取IP地址 📄 json字段控制 📄 Go 语言 iota 的神奇力量 📄 日志框架 📄 Go语言的%d,%p,%v等占位符的使用 📄 Go Web开发的五大利器 📄 Go中常见的IO模式 📄 Go常见错误第16篇：any的常见错误和最佳实践 - 掘金 📄 GORM框架 📄 标准库-time包 📄 高阶函数编程Go语言中的函数一等公民 📄 【Golang】怎样优雅的清空切片 📄 Go web项目布局 📄 死锁、活锁、饥饿、自旋锁（Go 语言描述） 📄 2023.3.8小结 📄 《100 Go Mistakes and How to Avoid Them》 📑 进阶篇 📄 Context包源码解读 📄 nethttp库源码解读 📄 Golang 单机锁实现原理 📄 进阶篇之函数篇 📄 优秀后端都应该具备的开发好习惯 📄 进阶篇之结构体篇 📄 Go Channel底层原理 📄 go语言反射的使用 📄 time包 📄 json字段控制 📄 深入浅出Go调度器中的GMP模型 📄 有无缓冲管道 📄 一文让你理解go语言的Context 📄 GO语言实现设计模式【上】 📄 GO语言实现设计模式【下】 📑 框架 📑 Go-zero 📄 玩转 Go 链路追踪 📄 go-zero 是如何追踪你的请求链路 📄 GoFrame学习之路 📑 RPC与GRPC 📄 RPC 📄 grpcurl的使用 📄 grpcui安装使用 ‍","link":"/post/golang-2sensm.html"},{"title":"My Blog ’s Plan","text":"My Blog ’s Plan 早在之前就有过建立自己的博客，但没有坚持下来。现重操旧业，坚持每天输出一篇Blog 整体思路，标签用来关键词联想与提示，或者自成体系的一套内容，分类为专题系列。 ‍ timeline：时间线，结合思源dailynote记录 标签：主要是一些主题性相关的，可能会很杂 例如：十大排序算法Ten-Sorts​​、杂记​​、英语​​、前沿技术​​ 分类： Golang 重学Go（偏基础重新巩固） Golang门面担当（常用的一些底层或者核心） 并发编程（并发相关） 数据结构与算法（偏入门，但是成体系） 架构设计师（面向考试与架构理解） MySQL Redis MQ ELK Docker 分布式 微服务 计算机底层（操作系统、网络、等一些综合性的理解） 🏳️‍🌈 秉持原则: ​ 拒绝无脑CV，深恶痛绝 CSDN 低劣文章，没头没尾，浪费时间 对于容易搜索的到内容有三点：一是要站在巨人的肩膀上总结和理解；二是确实很重点的部分才值得重复做；三自己的新学到内容，可能很粗浅，没有深刻领会，领会后可删除 将精力放在核心上，而不是排版、工具等无意义的点上 详情： A detailed list ‍ ‍","link":"/post/my-blog-content-planning-and-current-plan-z1tjjzq.html"},{"title":"微服务下分库分表的思考","text":"我关于MySQL分库分表的思考 分库分表的这个名词再常见不过了，一开始的理解不够，随着对mysql理解的加深。 关于这个问题目前我的整体前置思路是：Mysql的瓶颈在哪里——InnoDB存储引擎——MySQL单表存储的瓶颈以及瓶颈推演与测试——分库分表，内容不一定绝对，但是思路是完整、有迹可循的。 关联文章：Mysql单表存储数据量瓶颈推演（2000W左右） 目录 什么是分库分表？ 为什么需要分库分表？ 如何分库分表？ 什么时候开始考虑分库分表？ 分库分表会导致哪些问题？如何解决？ 分库分表中间件？ 1. 什么是分库分表分库：就是一个数据库分成多个数据库，部署到不同机器。单体架构下就没有分库分表，比较单一，SOA到微服务的发展中演进的 ​​ 分表：就是一个数据库表分成多个表。 ​​ 2.为什么需要分库分表呢？如果业务量剧增，数据库可能会出现性能瓶颈，这时候我们就需要考虑拆分数据库。从这几方面来看： 磁盘存储（很容易想到，这边便硬件层面的因素） 业务量剧增，MySQL单机磁盘容量会撑爆，拆成多个数据库，磁盘使用率大大降低。 并发连接支撑（这个是mysql本身的瓶颈） 我们知道数据库连接是有限的。在高并发的场景下，大量请求访问数据库，MySQL单机是扛不住的！当前非常火的微服务架构出现，就是为了应对高并发。它把订单、用户、商品等不同模块，拆分成多个应用，并且把单个数据库也拆分成多个不同功能模块的数据库（订单库、用户库、商品库），以分担读写压力。 为什么需要分表？ 数据量太大的话，SQL的查询就会变慢。如果一个查询SQL没命中索引，千百万数据量的表可能会拖垮这个数据库。 即使SQL命中了索引，如果表的数据量超过一千万的话，查询也是会明显变慢的。这是因为索引一般是B+树结构，数据千万级别的话，B+树的高度会增高，查询就变慢啦。 Mysql单表存储数据量瓶颈推演（2000W左右） MySQL的B+树的高度怎么计算的呢？ InnoDB存储引擎最小储存单元是页，一页大小就是16k。B+树叶子存的是数据，内部节点存的是键值+指针。索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而再去数据页中找到需要的数据，B+树结构图如下： ​​ 假设B+树的高度为2的话，即有一个根结点和若干个叶子结点。这棵B+树的存放总记录数为=根结点指针数*单个叶子节点记录行数。 如果一行记录的数据大小为1k，那么单个叶子节点可以存的记录数 =16k/1k =16​ 非叶子节点内存放多少指针呢？我们假设主键ID为bigint类型，长度为8字节(面试官问你int类型，一个int就是32位，4字节)，而指针大小在InnoDB源码中设置为6字节，所以就是 8+6=14 ​​字节，16k/14B =16*1024B/14B = 1170​ 因此，一棵高度为2的B+树，能存放1170 * 16=18720​条这样的数据记录。 同理一棵高度为3​的B+树，能存放1170 *1170 *16 =21902400​，大概可以存放两千万左右的记录。B+树高度一般为1-3层，如果B+到了4层，查询的时候会多查磁盘的次数，SQL就会变慢。 因此单表数据量超过千万-&gt;就需要考虑分表啦。 这个地方从两种角度分析：颗粒度不一样，层面也不一样 1.页的细节角度 16K的页内结构 ​​ ​​ 这种角度： 非叶子节点内指向其他页的数量为 x 叶子节点内能容纳的数据行数为 y B+ 数的层数为 z 页的结构，索引也也不例外，都会有 File Header (38 byte)、Page Header (56 Byte)、Infimum + Supermum（26 byte）、File Trailer（8byte）, 再加上页目录，大概 1k 左右。 我们就当做它就是 1K, 那整个页的大小是 16K, 剩下 15k 用于存数据，在索引页中主要记录的是主键与页号，主键我们假设是 Bigint (8 byte), 而页号也是固定的（4Byte）, 那么索引页中的一条数据的大小=8+4=12byte。15K=15*1024B 所以 非叶子节点内指向其他页的数量x ​=15*1024/12≈1280 行。 叶子节点和非叶子节点的结构是一样的，同理，能放数据的空间也是 15k。 但是叶子节点中存放的是真正的行数据，这个影响的因素就会多很多，比如，字段的类型，字段的数量。每行数据占用空间越大，页中所放的行数量就会越少。 这边我们暂时按一条行数据 1k 来算，那一页就能存下 15 条，Y = 15*1024/1000 ≈15。 算到这边了，是不是心里已经有谱了啊。 Total 总数据行数 根据上述的公式，Total =x^(z-1) *y，已知 x=1280，y=15： 假设 B+ 树是两层，那就是 z = 2， Total = （1280 ^1 ）*15 = 19200 假设 B+ 树是三层，那就是 z = 3， Total = （1280 ^2） *15 = 24576000 （约 2.45kw） ​​ 2.磁盘块角度（上述即是）： ​​ ‍ 3. 如何分库分表 水平即行，垂直即列，一横一竖，横即拆行，竖即拆列 3.1 垂直拆分 ​​ 3.1.1 垂直分库在业务发展初期，业务功能模块比较少，为了快速上线和迭代，往往采用单个数据库来保存数据。数据库架构如下： ​​ 但是随着业务蒸蒸日上，系统功能逐渐完善。这时候，可以按照系统中的不同业务进行拆分，比如拆分成用户库、订单库、积分库、商品库，把它们部署在不同的数据库服务器，这就是垂直分库。 垂直分库，将原来一个单数据库的压力分担到不同的数据库，可以很好应对高并发场景。数据库垂直拆分后的架构如下： ​​ 3.1.2 垂直分表如果一个单表包含了几十列甚至上百列，管理起来很混乱，每次都select *​的话，还占用IO资源。这时候，我们可以将一些不常用的、数据较大或者长度较长的列拆分到另外一张表。 比如一张用户表，它包含user_id、user_name、mobile_no、age、email、nickname、address、user_desc​，如果email、address、user_desc​等字段不常用，我们可以把它拆分到另外一张表，命名为用户详细信息表。这就是垂直分表： ​​ 3.2 水平拆分 3.2.1 水平分库 水平分库是指，将表的数据量切分到不同的数据库服务器上，每个服务器具有相同的库和表，只是表中的数据集合不一样。它可以有效的缓解单机单库的性能瓶颈和压力。 用户库的水平拆分架构如下： ​​ 3.2.2 水平分表如果一个表的数据量太大，可以按照某种规则（如hash取模、range​），把数据切分到多张表去。 一张订单表，按时间range​拆分如下： ​​ 3.3. 水平分库分表策略 分库分表策略一般有几种，使用与不同的场景： range范围 hash取模 range+hash取模混合 3.3.1 range范围range，即范围策略划分表。比如我们可以将表的主键，按照从0~1000万​的划分为一个表，1000~2000万​划分到另外一个表，以此类推。如下图： ​​ 当然，有时候我们也可以按​时间范围来划分，如不同年月的订单放到不同的表，它也是一种range的划分策略。 这种方案的优点： 这种方案有利于扩容，不需要数据迁移。假设数据量增加到5千万，我们只需要水平增加一张表就好啦，之前0~4000万​的数据，不需要迁移。 缺点： 这种方案会有热点问题，因为订单id是一直在增大的，也就是说最近一段时间都是汇聚在一张表里面的。比如最近一个月的订单都在1000万~2000​万之间，平时用户一般都查最近一个月的订单比较多，请求都打到order_1​表啦，这就导致表的数据热点问题。 3.3.2 hash取模hash取模策略：指定的路由key（一般是user_id、订单id作为key）对分表总数进行取模，把数据分散到各个表中。 比如原始订单表信息，我们把它分成4张分表： ​​ 比如id=1，对4取模，就会得到1，就把它放到第1张表，即t_order_0​; id=3，对4取模，就会得到3，就把它放到第3张表，即t_order_2​; 这种方案的优点： hash取模的方式，不会存在明显的热点集中问题。 缺点： 如果一开始按照hash取模分成4个表了，未来某个时候，表数据量又到瓶颈了，需要扩容，这就比较棘手了。比如你从4张表，又扩容成8​张表，那之前id=5​的数据是在（5%4=1​，即第一张表），现在应该放到（5%8=5​，即第5​张表），也就是说历史数据要做迁移了。 3.3.3 range+hash取模混合既然range存在热点数据问题，hash取模扩容迁移数据比较困难，我们可以综合两种方案一起嘛，取之之长，弃之之短。 比较简单的做法就是，在拆分库的时候，我们可以先用range范围方案，比如订单id在04000万的区间，划分为订单库1，id在4000万8000万的数据，划分到订单库2,将来要扩容时，id在8000万~1.2亿的数据，划分到订单库3。然后订单库内，再用hash取模的策略，把不同订单划分到不同的表。 ​​ 4. 什么时候考虑分库分表？前提：能不能切分就不要分，分了会极大的导致系统的复杂性。避免”过度设计”和”过早优化”。 在分库分表之前，不要为分而分，先尽力去做力所能及的事情，例如：升级硬件、升级网络、读写分离、索引优化等等。当数据量达到单表的瓶颈时候，再考虑分库分表。 4.1 什么时候分表？ 如果你的系统处于快速发展时期，如果每天的订单流水都新增几十万，并且，订单表的查询效率明变慢时，就需要规划分库分表了。一般B+树索引高度是2~3层最佳，如果数据量千万级别，可能高度就变4层了，数据量就会明显变慢了。不过业界流传，一般500万数据就要考虑分表了，属于提前考虑，留好空间。 4.2 什么时候分库 这一点我的理解是看业务量，微服务架构下，微服务特别多，或者很多重要的业务要维护高并发高可用的要求，就要分库，比如说重点的业务单体抽取出来单独分库。 业务发展很快，还是多个服务共享一个单体数据库，数据库成为了性能瓶颈，就需要考虑分库了。比如订单、用户等，都可以抽取出来，新搞个应用（其实就是微服务思想），并且拆分数据库（订单库、用户库）。 综合来讲，考虑分库分表的无非以下方面： ① 数据量快速增长，当业务中数据量急速增长时 ② 维护困难时：比如，备份时较为困难，单表太大，备份时需要大量的磁盘IO和网络IO；对一个很大的表进行DDL修改时，MySQL会锁住全表，这个时间会很长，这段时间业务不能访问此表，影响很大。如果使用pt-online-schema-change，使用过程中会创建触发器和影子表，也需要很长的时间。在此操作过程中，都算为风险时间。将数据表拆分，总量减少，有助于降低这个风险；经常访问与更新，就更有可能出现锁等待，将数据切分，用空间换时间，变相降低访问压力。 ③ 业务需求：需要对某些字段垂直拆分，本质上还是因用户增多导致的业务特点发生了变化 举个例子，假如项目一开始设计的用户表如下： 12345id bigint #用户的IDname varchar #用户的名字last_login_time datetime #最近登录时间personal_info text #私人信息..... #其他信息字段 在项目初始阶段，这种设计是满足简单的业务需求的，也方便快速迭代开发。而当业务快速发展时，用户量从10w激增到10亿，用户非常的活跃，每次登录会更新 last_login_name 字段，使得 user 表被不断update，压力很大。 而其他字段：id, name, personal_info 是不变的或很少更新的，此时在业务角度，就要将 last_login_time 拆分出去，新建一个 user_time 表。 personal_info 属性是更新和查询频率较低的，并且text字段占据了太多的空间。这时候，就要对此垂直拆分出 user_ext 表了 ④ 安全性角度：鸡蛋不要放在一个篮子里。在业务层面上垂直切分，将不相关的业务的数据库分隔，因为每个业务的数据量、访问量都不同，不能因为一个业务把数据库搞挂而牵连到其他业务。利用水平切分，当一个数据库出现问题时，不会影响到100%的用户，每个库只承担业务的一部分数据，这样整体的可用性就能提高。 5. 分库分表会导致哪些问题分库分表之后，也会存在一些问题： 事务问题 跨库关联 排序问题 分页问题 分布式ID 数据迁移、扩容问题 5.1 事务问题 分库分表后，假设两个表在不同的数据库，那么本地事务已经无效啦，需要使用分布式事务了。 5.2 跨库关联 跨节点Join的问题：解决这一问题可以分两次查询实现； 冗余处理，反规范化设计： 增加冗余列(复制某一列的数据) 这一点是真的好用 增加派生列(计算总和，平均值..) 表合并(把部分来自不同表的常用列合并成新表) 表分割(把数据拆分为常用和不常用，行拆分是比如订单信息，列拆分比如账户信息&lt;额外的住址之类的并不常用，减少查询压力&gt;) 题中要求是商品信息冗余，所以应该采用&lt;增加冗余列&gt;的方法 5.3 排序问题 跨节点的count,order by,group by以及聚合函数等问题：可以分别在各个节点上得到结果后在应用程序端进行合并。 5.4 分页问题 方案1：在个节点查到对应结果后，在代码端汇聚再分页。 方案2：把分页交给前端，前端传来pageSize和pageNo，在各个数据库节点都执行分页，然后汇聚总数量前端。这样缺点就是会造成空查，如果分页需要排序，也不好搞。 5.5 分布式ID 据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID，或者使用雪花算法生成分布式ID。 UUID: UUID标准形式包含32个16进制数字，分为5段，形式为8-4-4-4-12的32个字符，例如：550e8400-e29b-41d4-a716-446655440000 UUID是主键是最简单的方案，本地生成，性能高，没有网络耗时。但缺点也很明显，由于UUID非常长，会占用大量的存储空间；另外，作为主键建立索引和基于索引进行查询时都会存在性能问题，在InnoDB下，UUID的无序性会引起数据位置频繁变动，导致分页。 雪花算法： Twitter的snowflake算法解决了分布式系统生成全局ID的需求，生成64位的Long型数字，组成部分： 第一位未使用 接下来41位是毫秒级时间戳，41位的长度可以表示69年的时间 5位datacenterId，5位workerId。10位的长度最多支持部署1024个节点 最后12位是毫秒内的计数，12位的计数顺序号支持每个节点每毫秒产生4096个ID序列 ​​ 好处：毫秒数在高位，生成的ID整体上按时间趋势递增；不依赖第三方系统，稳定性和效率较高，理论上QPS约为409.6w/s（1000*2^12），并且整个分布式系统内不会产生ID碰撞；可根据自身业务灵活分配bit位。 不足：强依赖机器时钟，如果时钟回拨，则可能导致生成ID重复。 综上，结合数据库和snowflake的唯一ID方案，可以参考业界较为成熟的解法：Leaf——美团点评分布式ID生成系统，并考虑到了高可用、容灾、分布式下时钟等问题。 数据迁移、扩容问题： 当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。 此外还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过1000W）。 如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。 6. 分库分表中间件目前流行的分库分表中间件比较多： cobar Mycat Sharding-JDBC（当当） Atlas TDDL（淘宝） vitess（谷歌开发的数据库中间件） ​ ​ 参考资料：如何分库分表！ ‍","link":"/post/my-thinking-about-the-mysql-database-table-zmjl3t.html"},{"title":"Nacos相关记录","text":"Nacos配置与使用 Nacos1.X与2.X有差异，目前基本使用2.X版本，也是推荐的版本 Nacos初次尝试…. ‍ ‍ 权限认证🔒开启权限认证： 注意 Nacos是一个内部微服务组件，需要在可信的内部网络中运行，不可暴露在公网环境，防止带来安全风险。 Nacos提供简单的鉴权实现，为防止业务错用的弱鉴权体系，不是防止恶意攻击的强鉴权体系。 如果运行在不可信的网络环境或者有强鉴权诉求，请参考官方简单实现做进行自定义插件开发。 修改nacos配置文件 ——这个时候再访问nacos控制台页面，则会直接报错。 因此，还需要再设置两个属性（数值可随便填） 12nacos.core.auth.server.identity.key=authKeynacos.core.auth.server.identity.value=nacosSecurty 这两个属性是auth的白名单，用于标识来自其他服务器的请求。 添加好这两个属性时页面就能正常访问了。 还需要再其他服务的配置文件中加上如下配置，这也就是服务注册的权限 （修改代码方式）注意：密码不要有特殊符号不然会报错 12spring.cloud.nacos.username=nacospring.cloud.nacos.password=nacos 🤡 此外还需要配置： NACOS_AUTH_TOKEN token 默认:SecretKey012345678901234567890123456789012345678901234567890123456789 ‍","link":"/post/nacos-configuration-and-use-zm1qbo.html"},{"title":"Reverse a String","text":"字符串反转翻转含有中文、数字、英文字母​的字符串 如：&quot;子asdf黑g白hjkl小&quot;​ 1234567891011121314151617181920212223242526272829303132package mainimport &quot;fmt&quot;/** @Title main @Description: 1.rune关键字，从golang源码中看出，它是int32的别名（-2^31 ~ 2^31-1），比起byte（-128～127），可表示更多的字符。 2.由于rune可表示的范围更大，所以能处理一切字符，当然也包括中文字符。在平时计算中文字符，可用rune。 3.因此将字符串转为rune的切片，再进行翻转，完美解决。 @Author luommy 2023-09-22 00:19:14**/func main() { src := &quot;子asdf黑g白hjkl小&quot; // int32 is the set of all signed 32-bit integers. Range: -2147483648 through 2147483647. str := reverse([]rune(src)) fmt.Printf(&quot;%v\\n&quot;, string(str))}/** @Title reverse @Description @Author luommy 2023-09-22 00:12:29 @Param s @Return []rune**/func reverse(s []rune) []rune { for i, j := 0, len(s)-1; i &lt; j; i, j = i+1, j-1 { s[i], s[j] = s[j], s[i] } return s} ‍ 运行结果： ​​","link":"/post/string-reverse-1jimhs.html"}],"tags":[{"name":"timeline","slug":"timeline","link":"/tags/timeline/"},{"name":"领域算法","slug":"领域算法","link":"/tags/%E9%A2%86%E5%9F%9F%E7%AE%97%E6%B3%95/"},{"name":"知识体系","slug":"知识体系","link":"/tags/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"},{"name":"goland技巧","slug":"goland技巧","link":"/tags/goland%E6%8A%80%E5%B7%A7/"},{"name":"Myblog","slug":"Myblog","link":"/tags/Myblog/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"Nacos","slug":"Nacos","link":"/tags/Nacos/"}],"categories":[{"name":"京东到家","slug":"京东到家","link":"/categories/%E4%BA%AC%E4%B8%9C%E5%88%B0%E5%AE%B6/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"算法加练","slug":"算法加练","link":"/categories/%E7%AE%97%E6%B3%95%E5%8A%A0%E7%BB%83/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"MySQL","slug":"MySQL","link":"/categories/MySQL/"},{"name":"并发编程","slug":"算法加练/并发编程","link":"/categories/%E7%AE%97%E6%B3%95%E5%8A%A0%E7%BB%83/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"pages":[]}