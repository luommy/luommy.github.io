{"posts":[{"title":"2023.9.19 DailyNote","text":"2023-09-19 星期二2023.09.19 Tue 🌞 今年已过了 262 天（第 39 周/共 53 周）,距离 2024 年还有 103 天。距离 2023-11-04 高级-架构师考试还有 46 天。🗓️Weather：🌞🌥☁️⛈🌧🌦🌈🌪🌀⚡❄️🔥🥶🌊🌫🏠Location： 中国·广东省🛌Sleep：1：00 → 7：45 希望早日调整好作息时间 ⏰Must-To-Do 第一次发表… 没有早起 🚀️进展 自律：没有进展，依旧六块腹肌，单手五十俯卧撑 英法：菜够，法语真的难学 遇见：无，又是平凡的一天 其他：参加斗地主比赛 🐣Mini-Habits 月计划与反思 每日Golang 数据结构和算法 回顾昨天 每天早起 🧠今日反省思源功能太强大… 已经玩不明白了… 日历配置这个DailyNote template 配置原理又忘记了… 算了… 毕竟只是工具而已 争取每日后续更新一篇博客 日记推送到timeline​tag下 大概一周一次 看心情决定是否发布 随机复习 距离 2024-07-01​ 还剩 285​ 天，加油，你一定行！ 随机复习是一个好习惯，可惜现在笔记内容提炼不够精简，就不放到博客上展示了….","link":"/post/20230919-tuesday-uuzu4.html"},{"title":"命运齿轮","text":"命运齿轮2023.10.14 Sat 🌞 今年已过了 287 天（第 42 周/共 53 周）,距离 2024 年还有 78 天。距离 2023-11-04 高级-架构师考试还有 21 天。🗓️Weather：🌞🌥☁️⛈🌧🌦🌈🌪🌀⚡❄️🔥🥶🌊🌫🏠Location： 中国·广东省🛌Sleep：5.30 → 12 熬了个大夜-深夜思考人生《痛苦面具》 ⏰Must-To-Do ‍ 🚀️进展 自律：周五晚拉满了，游泳0.5h、力量训练1h、骑车10KM、跑步5kM 25min、核心训练0.5h 英法：IOS 播客很好用 遇见：清华经管-混血修勾？？ 其他：努力永远不会错 🐣Mini-Habits 月计划与反思 每日Golang 数据结构和算法 回顾昨天 每天早起 🧠今日反省 我发现很多技术手段，或者思想在某种程度上都是类似的，到一定阶段必然是融汇贯通的。 很多知识会就是会，不会就是不会，如果一些问题有过自己的思考量，即使知识本身的内容记不住，但是这个逻辑关系，逻辑追溯还是很重要的 最近玩且看狼人杀，记忆力好真的很关键，逻辑梳理更是一种能力，需要培养 ✨随缘记随便写点什么吧…. 缓存的分片有用到哈希算法与一致性哈希算法，同等联想到负载均衡的一种策略，也是一致性哈希算法，瞬间有点悟，好多其实都是相通的… ‍","link":"/post/20231014-saturday-zh8hf1.html"},{"title":"","text":"2023-10-21 星期六2023.10.21 Sat 🌞 今年已过了 294 天（第 43 周/共 53 周）,距离 2024 年还有 71 天。距离 2023-11-04 高级-架构师考试还有 14 天。🗓️Weather：🌞🌥☁️⛈🌧🌦🌈🌪🌀⚡❄️🔥🥶🌊🌫🏠Location： 中国·广东省🛌Sleep：2 → 7.30 ；9.30 → 12 ⏰Must-To-Do 周末学习打卡 🚀️进展 自律：马拉松备赛 ； 俄挺和前水平有点小帅 英法：关注了几个英语博主 遇见：三只羊在沈阳开分公司了？？ 其他： 🐣Mini-Habits 月计划与反思 每日Golang 数据结构和算法 回顾昨天 每天早起 🧠今日反省 越来越信因果效应了… 信息差也是一种能力… 早睡早起肯定算一种优点，但真的好难 快速建立知识体系 ✨随缘记随便写点什么吧…. 如果不知道布隆过滤器，那几乎不可能知道布谷鸟过滤器… 如果知道缓存穿透，那几乎必知道布隆过滤器… 百因必有果… 三缓存问题很常见，不必多说： ​​​​ 今天看过一个系统架构分析的实例： 系统使用过程中，由于同样的数据分别存在于数据库和缓存系统中，必然会造成数据同步或数据不一致性的问题。 法一：应用程序读数据时，首先读缓存，当该数据不在缓存时,再读取数据库；应用程序写数据吋，先写缓存，成功后再写数据库；或者先写数据库，再写缓存。 法二： 读数据操作的基本步骤：1.根据key读缓存；2.读取成功则直接返回；3.若key不在缓存中时，根据key (从数据库中读取数据) ；4.读取成功后， (更新缓存中key值) ；5.成功返回。写数据操作的基本步骤：1.根据key值写 (数据库) ；2.成功后 (更新缓存(key值)) ；3.成功返回。 ‍ ‍","link":"/post/20231021-saturday-z1vmbxc.html"},{"title":"2023.8.30","text":"2023.8.30从今天起，要狠狠滴加练，潶櫹潶櫹！！！ ‍","link":"/post/2023830-zy8cbl.html"},{"title":"几个后端的问题","text":"6.14 以下几个简单但并不简单的问题验证下自己的后端能力水平 业务Rpc服务如何理解 什么场景下应用RPC 是远程调用协议，服务之间只需要维持一个通信协议即可，不需要对编程语言有任何限制，也不用关系底层网络协议。多数是用在微服务、分布式场景下。 分布式下rpc如何调用可以通过注册中心+服务发现的方式实现调用，市面上很多组件比如consul、etcd等等都可以实现。 负载均衡策略有哪些 你们公司用的是哪种包括轮询、随机、加权、一致性哈希及最小连接数等。我们用的是轮询方式。 这个最好是有自己实现过的代码。 手写负载均衡、手写缓存中间件…后续再补充 Rpc协议和HTTP协议如何理解，有什么区别 RPC协议是远程调用协议，HTTP是超文本传输协议； RPC多用在微服务分布式和内部调用，HTTP多用在外部api服务； RPC的调用速度快于HTTP，但HTTP的实现要比RPC简单很多。 RPC有什么优势 为什么有这种优势RPC 不要考虑编程语言，服务只需要维持一个通信协议即可；调用速度非常的快；封装了很多方法，比如负载均衡等；适用于分布式微服务场景，内部扩展型较好。 为什么有这种优势不会答，我估计是要深入到socket层面 月百万级数据以上，总共一亿数据如何管理 优化思路如果是这种场景可以根据时间来划分，按月水平分表，这种思路，可以及时清理掉冷数据，如果在业务评估阶段就估计月表的数据量是百万级，且又可能在业务高峰期上升到千万或者亿界别的数据，那么可以考虑多一个月的数据再次分片，按照大小拆分，建议500w数据量拆分一个，虽然单表的数据量在2000w的时候，MySQL也能维持较好的层数，但是考虑到性能等问题，参考阿里巴巴数据库的设计思路，他们在海量数据的业务场景下经验丰富，比较推荐500w拆分一张 另外一种思路是根据用户id来进行hash分片拆分，多个MySQL部署，举个例子通过userid来计算哈希函数，然后和哈希掩码取模，可以快速定位到用户的数据存储在哪一个实例中，比较推荐使用MyCat这种业内比较成熟的数据库分片组件。 按月分表情况下(几十张表），这种情况下如何查某个用户的所有的订单可以加一层设计，比如用Redis的Hash结构，用户的userid作为key，list作为field，value是所有的订单信息的月份、id等，可以快速定位表位置、索引的信息。 12345678910111213141516{ &quot;user_id_1&quot;: { &quot;order_info&quot;: { &quot;2022-01&quot;: [&quot;order_1&quot;, &quot;order_2&quot;], &quot;2022-02&quot;: [&quot;order_3&quot;], &quot;2022-03&quot;: [&quot;order_4&quot;, &quot;order_5&quot;] } }, &quot;user_id_2&quot;: { &quot;order_info&quot;: { &quot;2022-01&quot;: [&quot;order_6&quot;, &quot;order_7&quot;], &quot;2022-02&quot;: [&quot;order_8&quot;], &quot;2022-03&quot;: [&quot;order_9&quot;, &quot;order_10&quot;] } }} 在这个示例中，每个 userid 都是 Hash 表的 key，而对应的 value 是一个包含了 order_info​ 这个 field。order_info​ 是一个内部的 Hash 结构，它使用年月（例如 “2022-01”）作为 field，而对应的值是一个列表，包含该用户在该月份下的所有订单编号。 通过这种设计，你可以快速定位到指定用户的订单信息，并按照不同月份进行索引。例如： 获取某个用户的所有订单：使用 HGETALL user_id_x 命令获取该用户的完整信息，然后再读取其中的 order_info​ 字段即可得到该用户在不同月份下的订单列表。 获取某个用户指定月份的订单信息：使用 HGET user_id_x order_info:YYYY-MM 命令获取对应月份的订单列表。 需要注意的是，为了保证不同月份的订单信息不会相互冲突，每个月份的 field 最好采用类似 “YYYY-MM” 的格式进行命名。 这种结构可以帮助你更好地组织和索引订单信息，同时也提供了快速定位、查询和统计的能力。 可以实现以下快速定位和索引的优势： 快速访问指定用户的订单信息：通过用户的 userid 作为 key，直接从 Redis 中获取对应的 Hash 结构，从而快速获取该用户的订单信息。 快速定位到指定年月的订单列表：在用户的订单信息中，使用年月作为 field，可以直接访问指定年月的订单列表，而无需遍历整个订单信息。 高效添加和删除订单信息：使用 Redis 的 List 结构存储订单列表，可通过头尾插入和删除操作，快速添加和删除订单，而不会影响其他年月的订单列表。 订单状态怎么查（已支付，待支付，待发货这种）设定字段订单状态status，通过上述的redis方案快速在数据库中查询，这里正好使用了Redis，可以设定缓存，但这就涉及到数据库和缓存更新的一致性问题了，写操作先更新数据库再删除缓存，读如果命中则直接返回，没命中则读取后写入缓存的方案可以避免。 如果用热点数据如何定义热点数据可以用 Redis 的 Zset 来给数据进行评分，这里的热点可以以时间、点击量、购买数等等因素综合考量。 订单状态转换如何更新？如何保持同步这个在上面已经说明了，写是先更新数据库再删除缓存，读是命中则返回，没命中则读取后写入缓存保持同步。这里同样需要保证了两步操作同时执行成功，可以用两种方案来保证，一种是重试机制，将操作发送到消息队列中，执行成功则在消息队列中删除该信息，如果失败则重新读取这条消息，超过一定次数则向上游返回报错，第二种方案是订阅MySQL的binlog日志，由于MySQL执行完之后会将操作记录在binlog里，所以可以使用binlog来找到具体的操作，这里推荐使用阿里巴巴的canal组件，他的思想就是模拟了mysql主从的交互协议实现这个功能。 服务器线上问题有排查过吗，怎么定位问题所在，整体链路讲讲，比如504这种问题。结合实际场景和原因进行分析有排查过，首先思路是并不是问题出现了再去排查问题，我们先要设计一套预防方案，如果是常规的报错问题，可以通过日志、链路追踪查询定位到，如果是服务崩溃等信息，可以通过监控报警，比如grafana，包括在CPU、内存负载压力过高的时候可以提前预警人工介入。 真的是线上出现了bug、崩溃、超时等问题，那么整体流程是，先通过链路追踪定位返回错误信息或者崩溃的服务是哪个，查看服务崩溃的日志的具体原因，精确到代码行，如果无法从代码的逻辑角度排查问题，我们要看CPU、内存的使用情况，通过系统监控确定是哪一个环节出问题，然后查看是否是内存泄漏、SQL慢查询、GC异常等问题。 504 是属于 http请求返回超时的问题，举一个实际场景的例子，比如我做过一个音视频合成的例子，之前我调用合成api接口的超时，然后返回给上游的调度服务错误信息，定位到是我服务返回的超时，模拟了当时的请求信息，通过链路追踪，在jager上查看了收到合成api请求的时间耗时过长，解决方案是，最开始合成方是用http的方式返回合成url，后来我们采用grpc 流式传输的方案可以实时返回，在没接收到结束信号时，不断开链接。 502 和 504 区别 502 是网络无法请求，接收到错误的响应； 504 是网络请求，但是接受响应超时； MySQL慢查询有涉及过吗？如果用了索引还是慢查询该怎么办 ？慢查询可以通过 MySQL 的慢查询日志查到，不过默认 MySQL 的慢查询日志是关闭的。 如果用了索引还是慢查询，可以使用 explain 命令来查看 sql 语句的执行计划，可以查看是否正常使用了索引，排查是否存在索引失效的可能。另外排查是否是数据库的参数，比如缓存、连接等待等问题。 数据量过大该如何优化数据量过大可以考虑分库分表了。分库就是根据实际场景将数据分散到多个库，分表是将数据拆分成多个表，防止单表过大。 如何分库分表 垂直拆分：由于前期表的设计没有抽象，所以这时候要根据关系性较强的几个字段对表进行拆分。一种思路是将长度比较大、不常用的信息，移到扩展表。 水平拆分：将一张大表拆分成数据结构相同的几个表，防止单表过大。 这里举个商城的例子来说明，我们可以拆分成订单信息库、用户信息库、商品详情库，每个库中的表的数据量过于庞大，比如超过500万行就可以考虑水平拆分，如果有几个关系性较强的字段，可以垂直拆分建立一张新表，具体根据自己的业务实际场景来进行扩展。 你常用的索引有哪些 结合业务说明 按照类型分类：B+ 数索引，哈希索引，fulltext索引； 按照存储方式分类：聚簇索引和非聚簇索引； 按照使用的列分类：联合索引和单一索引； 按照使用的字段分类：主键索引、唯一索引、前缀索引和普通索引。 常用的是联合索引和主键索引，比如通过id直接查询一条记录的完整信息，我们可以使用主键索引快速定位，再比如联合性比较强的两个字段，可以建立联合索引，比如要查询年龄为x、成绩是y的成员name，可以用（x，y，name）建立联合索引，利用覆盖索引可以减少回表。 什么是聚簇索引，什么是非聚簇索引，它们有什么区别聚簇索引具有唯一性，比如主键就是聚簇索引，如果没有主键会选择唯一且不为NULL的列作为主键索引，如果没有则会生成一个自增id作为主键索引。聚簇索引存放的信息是完整的数据记录，而非聚簇索引只存放聚簇索引信息。如果查询语句使用的是非聚簇索引，且查询的数据不是主键值，会在叶子节点找到主键值后进行回表，如果是主键值就会进行索引覆盖。 主键索引的底层存储结构 大致实现过程B+ 树。B+ 树是由 B 树改进而来的，所有的索引都存放在叶子节点，并构成有序的链表，其实是双向链表，叶子节点的值存放的是数据页，数据页里包含完整的记录，而非叶子节点只存放索引，非叶子节点会作为叶子节点中索引的最大或者最小节点，比如举个例子，根节点存放的索引是 (1、10、19)，那么第二层就可以是 (1、4、7)，(10、13、16)，(19、22、25)，而第三层如果是叶子节点，就会存放完整的索引和数据。并且支持范围查询，由于 MySQL 的 B+ 树底层节点是双向链表，所以范围查询效率很高；B+ 树的非叶子节点只存放索引，可以存放更多的记录，所以相同数据量下，B+ 树更矮胖，减少了 磁盘 IO；B+ 树有大量的冗余节点，在插入和删除时不会发生过多的树结构变化。 非主键索引、联合索引等的存储结构B+ 树。 这些索引在存储数据时有什么区别主键索引的值是完整的数据记录，其他索引存储的值是主键索引，联合索引的key是多个字段，查询的时候按照最左匹配原则。 主键索引的索引信息存在哪里叶子节点 MySQL的数据存在哪里存在磁盘中，如果是 InnoDB 引擎，则会按照三个文件存放，db.opt 存放的是数据库设置的默认字符集和字符校验规则，.frm 文件是存放表的结构信息，比如列、数据类型、索引等，.ibd 是存放数据的内容。 范围查询时主键索引是如何去做的首先通过二分查找定位到边界，然后通过双向链表，开始遍历即可。 什么是索引覆盖索引覆盖是在联合索引是，查询的内容在联合索引的key上就可以查到，避免了回表。比如联合索引（x，y），现在想通过x条件查询y的内容，就可以使用（x，y）避免再次回表。 MySQL用过什么存储引擎常见的是 Innodb、MyISAM、Memory等。现在默认是 InnoDB。 InnoDB有什么特性 存储：存放在 .frm、.ibd文件； 索引：支持聚簇索引和非聚簇索引； 事务：有undo log 和 redo log，支持事务； 故障恢复：有 redo log，支持故障恢复； 锁：支持表级锁和行级锁； 就针对和 MyISAM 的区别聊 事务有什么特性ACID，原子性、隔离性、一致性、持久性。 可重复读是如何做的，如何实现的通过 MVCC 实现的。 MySQL在事务启动后会为事务生成一个 Read View 快照，Read View 会记录当前事务的id、活跃的事务id列表、活跃事务id的最小值、下一个创建的事务id值，MySQL的行数据也会记录最新修改过这一行的事务id，同样会记录该行的上一版本记录的指针，像一个链表一样。当事务A启动后，事务B启动，事务B的活跃事务id列表就是A和B的事务id，现在事务要对一个行数据进行操作，如果活跃事务id列表的最小值比当前行数据记录的最新修改过这一行的事务id值大，说明最新操作该行数据记录的事务已经提交完成，所以可以对该行进行操作，如果大于下一个创建的事务id值，说明这个最新操作该行数据记录的事务是在当前事务A和B启动之后再启动的事务，那么就不可以对这行数据进行操作。之后要分两种情况讨论，如果在活跃的事务id列表之间，说明有其他事务在操作该行，那么不可以对该行操作，会去找该行记录的上一版本指针，如果不在则说明最新操作该行数据记录的事务已经提交，那么可以对该行进行操作，操作了之后，该行记录会更新最新修改这一样的事务id，同样以链表形式将上一版本记录连接起来。 MVCC 是如何做的上面那一段 如果commit 时，数据版本和快照版本不一致该怎么办回滚 如果加锁的话加的什么锁没懂要问啥，如果是问的可重复读里面的幻读问题，那就是间隙锁，如果带有记录的话是 nextkey lock（间隙锁+记录锁），举个例子： 事务A，执行了 for update 语句 当前读，查询大于等于 5 的记录，这时候事务 B，插入了一条 10 的记录，这样事务 A 如果再次查询的话，前后两次查询就会幻读，所以这时候会引入一个 next key lock，锁住 [5, +∞]的记录，（如果是大于 5 那就是间隙锁）。 Redis常用数据类型String、List、Hash、Set、Sort Set。 可以加上 Hyperloglog、Stream、Bitmap、Geospatial index 。 大 key 问题如何解决如果是 Set 结构则可以修改为 Hash，不要一次性全查。可以将大 key 拆分成多个小 key，读取的时候批量读取拼接即可。而且尽量给大 key 设置较长的过期时间，不让其在缓存中淘汰。删除可以用分批次删除或者异步删除的做法，避免阻塞主线程。 用的 Redis 单机还是集群集群 如何存数据不清楚要问的是底层数据结构还是持久化存储，底层数据结构就将五种基本类型的底层数据结构，持久化就是说 RDB 和 AOF 举个例子，String，如果存储 int 整形，可以用 long 表示，则用 int 来存储，如果是字符串，则小于等于 44 字节用 embstr 存储，其他情况是 raw。 RDB 和 AOF， 就是一个快照，一个追加日志，可能要问一些详细的过程了，还有刷盘策略等等。看具体想问什么。 讲讲主从复制由于 Redis 具有持久化能力（RDB 和 AOF），为了避免单点故障，可以引入主从模式，主机可以进行读写操作，每次的写操作都会同步数据给从机。主从模式主要是为了减轻主机压力以及容灾恢复。接下来大致介绍一下主从复制的流程： 建立好集群及主从关系后，从机会连接主机，发送 SYNC 命令，主机接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令，之后会向所有从机发送 RDB ，并在发送期间继续记录被执行的写命令，从机接收到后会载入执行，之后的每一个主机的写命令都会发送到从机执行，如果有断线重连会才用增量复制，补全缓冲区中的命令。 主服务器挂了怎么办哨兵模式会进行监控、选主、通知。首先是如何判断主服务器真的挂了，这里分为主观下线和客观下线，如果哨兵节点接受不到主服务器的信号就会认定为其主观下线，但是哨兵也是集群大的方式部署的，如果超过一半节点认为是主观下线就认定其客观下线。之后哨兵leader会从从机中选取一个新的主节点，进行主从故障转移，让原主下的所有从机都作为新的主机的从机，并且通过发布订阅通知客户端，另外会监控原主机的情况，如果原主机重新上线，那么会作为新主的从。 这里可能还会涉及到哨兵leader、选主策略、主从数据不一致的问题。 主服务器选举是怎么做的首先会找优先级最高的从节点，其次找复制进度最靠前的节点，最后通过id排序。 联想分布式算法原理…… ‍ ‍","link":"/post/614-1z6cwp.html"},{"title":"训练历程","text":"我的数据结构和算法知识体系我的算法体系由hello+代码随想录培养…. 相互补充 K神：力扣（LeetCode）全网阅读量最高博主，发表的《图解算法数据结构》已被订阅 27 万本。 本部分目的是巩固并加强对数据结构的全面理解，大学期间也有多的这门课程，但是内容有限，很难成为体系，算是一个基础的巩固，比起直接手撕LeetCode1000题，我感觉基础巩固更重要，重点记录新的理解。 待办： labuladong Cookbook LeetCode HOT 100 ‍","link":"/post/algorithm-system-1wyqpm.html"},{"title":"多个协程打印相关问题","text":"并发编程：多个协程打印​创建三个goroutine，分别输出1 4 7, 2 5 8, 3 6 9, ...... 100， 保证顺序输出1到100​ 1234567891011121314151617181920212223242526272829303132333435363738394041/** * @Author 560463 * @Description //TODO $ 并发：创建三个goroutine，分别输出1 4 7, 2 5 8, 3 6 9, ...... 100， 保证顺序输出1到100, 2种方法 * @Date 2023/10/12 14:36 **/// 实现三个协程并发交替打印数字// 方法一：package mainimport &quot;fmt&quot;var chanDone chan intvar end intvar countA, countB, countC intfunc write(name string, count int, ch, next chan int) { for a := range ch { //fmt.Println(a) count++ fmt.Printf(&quot;协程%s 第%d次打印了%d\\n&quot;, name, count, a) if a &lt; end { next &lt;- a + 1 } else { chanDone &lt;- 0 } }}func main() { ch1, ch2, ch3 := make(chan int, 1), make(chan int, 1), make(chan int, 1) countA, countB, countC = 0, 0, 0 chanDone, end = make(chan int), 100 go write(&quot;A&quot;, countA, ch1, ch2) go write(&quot;B&quot;, countB, ch2, ch3) go write(&quot;C&quot;, countC, ch3, ch1) ch1 &lt;- 1 &lt;-chanDone} ‍ 123456789101112131415161718192021222324252627282930313233343536//方法二：package mainimport &quot;fmt&quot;var wg sync.WaitGroupfunc r(name string, count int, start int, ch1, ch2 chan int) { defer wg.Done() for i := start; i &lt;= 100; { num, ok := &lt;-ch1 if !ok { close(ch2) break } count++ fmt.Printf(&quot;协程%s 第%d次打印了: %d\\n&quot;, name, count, num) i++ ch2 &lt;- i i = i + 2 //如果这样写有个坑：这样写第一次A是打印了1 但是给B的值也是1，虽然后面进行了+3 但是本轮打印时错误的 //ch2 &lt;- i //i = i + 3 }}func main() { chA, chB, chC := make(chan int, 1), make(chan int, 1), make(chan int, 1) countA, countB, countC := 0, 0, 0 wg.Add(3) chA &lt;- 1 go r(&quot;A&quot;, countA, 1, chA, chB) go r(&quot;B&quot;, countB, 2, chB, chC) go r(&quot;C&quot;, countC, 3, chC, chA) wg.Wait()} ‍ 结果： ​​ ​​ ‍ ‍ ​三个协程分别打印100次 cat dog fish​ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( &quot;fmt&quot; &quot;sync&quot;)// 三个协程交替打印 cat dog fishvar repeatCount = 100func main() { // wg 用来防止主协程提前先退出 wg := &amp;sync.WaitGroup{} wg.Add(3) chCat := make(chan struct{}, 1) defer close(chCat) chDog := make(chan struct{}, 1) defer close(chDog) chFish := make(chan struct{}, 1) defer close(chFish) go printAnimal(chCat, chDog, &quot;cat&quot;, wg) go printAnimal(chDog, chFish, &quot;dog&quot;, wg) go printAnimal(chFish, chCat, &quot;fish&quot;, wg) chCat &lt;- struct{}{} wg.Wait()}// wg 需要传指针func printAnimal(in, out chan struct{}, s string, wg *sync.WaitGroup) { count := 0 for { &lt;-in count++ fmt.Printf(&quot;第%d次打印%s\\n&quot;, count, s) out &lt;- struct{}{} if count &gt;= repeatCount { wg.Done() return } }} ‍ ​​","link":"/post/concorded-programming-multiple-corporate-printing-zpbnes.html"},{"title":"Docker一文通览","text":"Docker通览 通览篇主要是构建基本的认知，本篇从基础概念、应用、核心底层组成，甚至包括一点点个人理解。 Docker基础与应用 官方文档地址:https://www.docker.com/get-started 中文参考手册:https://docker_practice.gitee.io/zh-cn/ 什么是 Docker官方定义 最新官网首页 1234# 1.官方介绍- We have a complete container solution for you - no matter who you are and where you are on your containerization journey.- 翻译: 我们为你提供了一个完整的容器解决方案,不管你是谁,不管你在哪,你都可以开始容器的的旅程。- 官方定义: docker是一个容器技术。 Docker的起源12345Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目 已经超过 5 万 7 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 为什么是Docker 在开发的时候，在本机测试环境可以跑，生产环境跑不起来 这里我们拿java Web应用程序举例，我们一个java Web应用程序涉及很多东西，比如jdk、tomcat、mysql等软件环境。当这些其中某一项版本不一致的时候，可能就会导致应用程序跑不起来这种情况。Docker 则将程序以及使用软件环境直接打包在一起，无论在那个机器上保证了环境一致。 优势1: 一致的运行环境,更轻松的迁移 服务器自己的程序挂了，结果发现是别人程序出了问题把内存吃完了，自己程序因为内存不够就挂了 这种也是一种比较常见的情况，如果你的程序重要性不是特别高的话，公司基本上不可能让你的程序独享一台服务器的，这时候你的服务器就会跟公司其他人的程序共享一台服务器，所以不可避免地就会受到其他程序的干扰，导致自己的程序出现问题。Docker就很好解决了环境隔离的问题，别人程序不会影响到自己的程序。 优势2：对进程进行封装隔离,容器与容器之间互不影响,更高效的利用系统资源 公司要弄一个活动，可能会有大量的流量进来，公司需要再多部署几十台服务器 在没有Docker的情况下，要在几天内部署几十台服务器，这对运维来说是一件非常折磨人的事，而且每台服务器的环境还不一定一样，就会出现各种问题，最后部署地头皮发麻。用Docker的话，我只需要将程序打包到镜像，你要多少台服务，我就给力跑多少容器，极大地提高了部署效率。 优势3: 通过镜像复制N多个环境一致容器 Docker和虚拟机区别 关于Docker与虚拟机的区别，我在网上找到的一张图，非常直观形象地展示出来，话不多说，直接上图。 比较上面两张图，我们发现虚拟机是携带操作系统，本身很小的应用程序却因为携带了操作系统而变得非常大，很笨重。Docker是不携带操作系统的，所以Docker的应用就非常的轻巧。另外在调用宿主机的CPU、磁盘等等这些资源的时候，拿内存举例，虚拟机是利用Hypervisor去虚拟化内存，整个调用过程是虚拟内存-&gt;虚拟物理内存-&gt;真正物理内存，但是Docker是利用Docker Engine去调用宿主的的资源，这时候过程是虚拟内存-&gt;真正物理内存。 传统虚拟机 Docker容器 磁盘占用 几个GB到几十个GB左右 几十MB到几百MB左右 CPU内存占用 虚拟操作系统非常占用CPU和内存 Docker引擎占用极低 启动速度 （从开机到运行项目）几分钟 （从开启容器到运行项目）几秒 安装管理 需要专门的运维技术 安装、管理方便 应用部署 每次部署都费时费力 从第二次部署开始轻松简捷 耦合性 多个应用服务安装到一起，容易互相影响 每个应用服务一个容器，达成隔离 系统依赖 无 需求相同或相似的内核，目前推荐是Linux Docker的安装安装docker(centos7.x) 卸载原始docker 12345678$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装docker依赖 123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 设置docker的yum源 123$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 安装最新版的docker 1$ sudo yum install docker-ce docker-ce-cli containerd.io 指定版本安装docker 123$ yum list docker-ce --showduplicates | sort -r$ sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io$ sudo yum install docker-ce-18.09.5-3.el7 docker-ce-cli-18.09.5-3.el7 containerd.io 启动docker 12$ sudo systemctl enable docker$ sudo systemctl start docker 关闭docker 1$ sudo systemctl stop docker 测试docker安装 1$ sudo docker run hello-world bash安装(通用所有平台) 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，CentOS 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装：执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 的稳定(stable)版本安装在系统中。 12$ curl -fsSL get.docker.com -o get-docker.sh$ sudo sh get-docker.sh --mirror Aliyun 启动docker 12$ sudo systemctl enable docker$ sudo systemctl start docker 创建docker用户组 1$ sudo groupadd docker 将当前用户加入docker组 1$ sudo usermod -aG docker $USER 测试docker安装是否正确 1$ docker run hello-world Docker 的核心架构​​ ​镜像:​ 一个镜像代表一个应用环境,他是一个只读的文件,如 mysql镜像,tomcat镜像,nginx镜像等 ​容器:​ 镜像每次运行之后就是产生一个容器,就是正在运行的镜像,特点就是可读可写 ​仓库:​用来存放镜像的位置,类似于maven仓库,也是镜像下载和上传的位置 ​dockerFile:​docker生成镜像配置文件,用来书写自定义镜像的一些配置 ​tar:​一个对镜像打包的文件,日后可以还原成镜像 ​​ Docker 配置阿里镜像加速服务docker 运行流程 docker配置阿里云镜像加速 访问阿里云登录自己账号查看docker镜像加速服务 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'{ &quot;registry-mirrors&quot;: [&quot;https://lz2nib3q.mirror.aliyuncs.com&quot;]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker 验证docker的镜像加速是否生效 1234567[root@localhost ~]# docker info .......... 127.0.0.0/8 Registry Mirrors: 'https://lz2nib3q.mirror.aliyuncs.com/' Live Restore Enabled: false Product License: Community Engine Docker的入门应用docker 的第一个程序 docker run hello-world 12345678910111213141516171819202122[root@localhost ~]# docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 常用命令启动命令启动docker 1systemctl start docker 关闭docker 1systemctl stop docker 重启docker 1systemctl restart docker docker设置随服务启动而自启动 1systemctl enable docker 辅助命令1234# 1.安装完成辅助命令 docker version -------------------------- 查看docker的信息 docker info -------------------------- 查看更详细的信息 docker --help -------------------------- 帮助命令 Images 镜像命令12345678910111213141516171819202122232425262728293031# 1.查看本机中所有镜像 docker images -------------------------- 列出本地所有镜像 -a 列出所有镜像（包含中间映像层） -q 只显示镜像id# 2.搜索镜像 docker search [options] 镜像名 ------------------- 去dockerhub上查询当前镜像 -s 指定值 列出收藏数不少于指定值的镜像 --no-trunc 显示完整的镜像信息# 3.从仓库下载镜像/拉取仓库镜像到本地 docker pull 镜像名[:TAG|@DIGEST] ----------------- 下载镜像# 4.删除镜像 docker rmi 镜像名 -------------------------- 删除镜像 -f 强制删除 如果删除多个镜像用空格隔开 删除全部镜像 -a 意思为显示全部, -q 意思为只显示ID docker rmi -f $(docker images -aq)# 5.加载本地件tar，恢复为镜像 docker load -i 本地文件 与docker save对应 docker load -i hello.tar# 6.保存镜像为本地文件（打包镜像）** docker save -o 镜像保存位置与名字 镜像名/镜像ID 与docker load对应 docker save -o hello.tar hello-world# 7.上传镜像到docker hub docker push hello:V1 search: ​​ ​docker 安装镜像时如果不指定安装的版本默认最新版本​ Contrainer 容器命令12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# 1.运行容器 docker run 镜像名 -------------------------- 镜像名新建并启动容器 --name 别名为容器起一个名字 -d, --detach 启动守护式容器（在后台启动容器） -p 映射端口号：原始端口号 指定端口号启动 -v, --volume list 给容器挂载数据卷 --name string 指定容器名称 -e, --env list 设置容器环境变量 -i, --interactive 以交互模式运行容器，通常与 -t 同时使用 -m, --memory bytes 容器内存上限 -t, --tty 为容器重新分配一个伪输入终端，通常与 -i 同时使用 -w, --workdir string 指定工作目录 例：docker run -it --name myTomcat -p 8888:8080 tomcat docker run -d --name myTomcat -P tomcat 常用换行的方式： docker run -dit \\ -v $PWD/ql/config:/ql/config \\ -p 5600:5600 \\ --name qinglong \\ --hostname qinglong \\ --restart unless-stopped \\ whyour/qinglong:2.11.3# 2.查看运行的容器 docker ps -------------------------- 列出所有正在运行的容器 -a 正在运行的和历史运行过的容器（已经停止）# 4.删除容器 docker rm -f 容器id和容器名 docker rm -f $(docker ps -aq) -------------------------- 删除所有容器# 5.查看容器内进程 docker top 容器id或者容器名 ------------------ 查看容器内的进程# 6.查看查看容器内部细节 docker inspect 容器id ------------------ 查看容器内部细节# 7.查看容器的运行日志 docker logs [OPTIONS] 容器id或容器名 ------------------ 查看容器日志 -t 加入时间戳 -f 跟随最新的日志打印 --tail 数字 显示最后多少条# 8.进入容器内部 docker exec [options] 容器id 容器内命令 ------------------ 进入容器执行命令 -i 以交互模式运行容器，通常与-t一起使用 -t 分配一个伪终端 shell窗口 bash 常用：docker exec -it redis sh 或者使用docker attach 容器名/容器ID【 不常用 】---没有使用过....# 9.容器和宿主机之间复制文件 docker cp 文件|目录 容器id:容器路径 ----------------- 将宿主机复制到容器内部 docker cp 容器id:容器内资源路径 宿主机目录路径 ----------------- 将容器内资源拷贝到主机上# 10.数据卷(volum)实现与宿主机共享目录 docker run -v 宿主机的路径|任意别名:/容器内的路径 镜像名 注意: 1.如果是宿主机路径必须是绝对路径,宿主机目录会覆盖容器内目录内容 2.如果是别名则会在docker运行容器时自动在宿主机中创建一个目录,并将容器目录文件复制到宿主机中# 11.打包镜像 docker save 镜像名 -o 名称.tar# 12.载入镜像 docker load -i 名称.tar# 13.容器打包成新的镜像 docker commit -m &quot;描述信息&quot; -a &quot;作者信息&quot; （容器id或者名称）打包的镜像名称:标签 补充： 123456789101112# 1.开机自启 docker update --restart=always 容器Id/容器名# 2.更换容器名字 docker rename 容器ID/容器名字 新容器名字# 3.查看docker磁盘 docker system df# 4.查看容器占用内存 docker stats 容器名/容器ID docker stats redis 查看docker磁盘占用 ​​ ​SIZE​（大小）：表示Docker系统中各个部分（镜像、容器、卷、构建缓存）所占用的总磁盘空间大小，以字节为单位。 ​RECLAIMABLE​（可回收大小）：表示可以通过清理或删除不再使用的资源来释放的磁盘空间大小，同样以字节为单位。 docker save 与docker export区别： docker export需要指定容器(container)，不能像docker save那样指定镜像(image)或容器(container)都可以。 docker save保存的是镜像（image），docker export保存的是容器（container）； docker load用来载入镜像包，docker import用来载入容器包，但两者都会恢复为镜像； docker load不能对载入的镜像重命名，而docker import可以为镜像指定新名称。 docker save的应用场景是，如果你的应用是使用docker-compose.yml编排的多个镜像组合，但你要部署的客户服务器并不能连外网。这时，你可以使用docker save将用到的镜像打个包，然后拷贝到客户服务器上使用docker load载入 。—这一点​***深有体会*** docker export的应用场景主要用来制作基础镜像，比如你从一个ubuntu镜像启动一个容器，然后安装一些软件和进行一些设置后，使用docker export保存为一个基础镜像。然后，把这个镜像分发给其他人使用，比如作为基础的开发环境。—这个确实没有应用过 docker的镜像原理镜像是什么？ 镜像是一种轻量级的，可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时所需的库、环境变量和配置文件。 为什么一个镜像会那么大？ 镜像就是花卷 UnionFS（联合文件系统）: Union文件系统是一种分层，轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。Union文件系统是Docker镜像的基础。这种文件系统特性:就是一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 。 Docker镜像原理 docker的镜像实际是由一层一层的文件系统组成。 bootfs（boot file system）主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统。在docker镜像的最底层就是bootfs。这一层与Linux/Unix 系统是一样的，包含boot加载器（bootloader）和内核（kernel）。当boot加载完,后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时会卸载bootfs。 rootfs（root file system），在bootfs之上，包含的就是典型的linux系统中的/dev，/proc，/bin，/etc等标准的目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu/CentOS等等。 我们平时安装进虚拟机的centos都有1到几个GB，为什么docker这里才200MB？对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令，工具，和程序库就可以了，因为底层直接使用Host的Kernal，自己只需要提供rootfs就行了。由此可见不同的linux发行版，他们的bootfs是一致的，rootfs会有差别。因此不同的发行版可以共用bootfs。 为什么docker镜像要采用这种分层结构呢? 最大的一个好处就是资源共享 比如：有多个镜像都是从相同的base镜像构建而来的，那么宿主机只需在磁盘中保存一份base镜像。同时内存中也只需要加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。Docker镜像都是只读的。当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称为容器层，容器层之下都叫镜像层。 Docker安装常用服务安装mysql12345678910111213141516171819202122232425262728# 1.拉取mysql镜像到本地 docker pull mysql:tag (tag不加默认最新版本) # 2.运行mysql服务 docker run --name mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:tag --没有暴露外部端口外部不能连接 docker run --name mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:tag --没有暴露外部端口# 3.进入mysql容器 docker exec -it 容器名称|容器id bash# 4.外部查看mysql日志 docker logs 容器名称|容器id# 5.使用自定义配置参数 docker run --name mysql -v /root/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -d mysql:tag# 6.将容器数据位置与宿主机位置挂载保证数据安全 docker run --name mysql -v /root/mysql/data:/var/lib/mysql -v /root/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:tag# 7.通过其他客户端访问 如在window系统|macos系统使用客户端工具访问 # 8.将mysql数据库备份为sql文件 docker exec mysql|容器id sh -c 'exec mysqldump --all-databases -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &gt; /root/all-databases.sql --导出全部数据 docker exec mysql sh -c 'exec mysqldump --databases 库表 -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &gt; /root/all-databases.sql --导出指定库数据 docker exec mysql sh -c 'exec mysqldump --no-data --databases 库表 -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &gt; /root/all-databases.sql --导出指定库数据不要数据# 9.执行sql文件到mysql中 docker exec -i mysql sh -c 'exec mysql -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &lt; /root/xxx.sql 安装Redis服务12345678910111213141516171819202122232425262728# 1.在docker hub搜索redis镜像 docker search redis# 2.拉取redis镜像到本地 docker pull redis# 3.启动redis服务运行容器 docker run --name redis -d redis:tag (没有暴露外部端口) docker run --name redis -p 6379:6379 -d redis:tag (暴露外部宿主机端口为6379进行连接) # 4.查看启动日志 docker logs -t -f 容器id|容器名称# 5.进入容器内部查看 docker exec -it 容器id|名称 bash # 6.加载外部自定义配置启动redis容器 默认情况下redis官方镜像中没有redis.conf配置文件 需要去官网下载指定版本的配置文件 1. wget http://download.redis.io/releases/redis-5.0.8.tar.gz 下载官方安装包 2. 将官方安装包中配置文件进行复制到宿主机指定目录中如 /root/redis/redis.conf文件 3. 修改需要自定义的配置 bind 0.0.0.0 开启远程权限 appenonly yes 开启aof持久化 4. 加载配置启动 docker run --name redis -v /root/redis:/usr/local/etc/redis -p 6379:6379 -d redis redis-server /usr/local/etc/redis/redis.conf # 7.将数据目录挂在到本地保证数据安全 docker run --name redis -v /root/redis/data:/data -v /root/redis/redis.conf:/usr/local/etc/redis/redis.conf -p 6379:6379 -d redis redis-server /usr/local/etc/redis/redis.conf 安装Nginx123456789101112131415161718192021222324252627# 1.在docker hub搜索nginx docker search nginx# 2.拉取nginx镜像到本地 [root@localhost ~]# docker pull nginx Using default tag: latest latest: Pulling from library/nginx afb6ec6fdc1c: Pull complete b90c53a0b692: Pull complete 11fa52a0fdc0: Pull complete Digest: sha256:30dfa439718a17baafefadf16c5e7c9d0a1cde97b4fd84f63b69e13513be7097 Status: Downloaded newer image for nginx:latest docker.io/library/nginx:latest# 3.启动nginx容器 docker run -p 80:80 --name nginx01 -d nginx# 4.进入容器 docker exec -it nginx01 /bin/bash 查找目录: whereis nginx 配置文件: /etc/nginx/nginx.conf# 5.复制配置文件到宿主机 docker cp nginx01(容器id|容器名称):/etc/nginx/nginx.conf 宿主机名录# 6.挂在nginx配置以及html到宿主机外部 docker run --name nginx02 -v /root/nginx/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/html:/usr/share/nginx/html -p 80:80 -d nginx 安装Tomcat123456789101112131415# 1.在docker hub搜索tomcat docker search tomcat# 2.下载tomcat镜像 docker pull tomcat# 3.运行tomcat镜像 docker run -p 8080:8080 -d --name mytomcat tomcat# 4.进入tomcat容器 docker exec -it mytomcat /bin/bash# 5.将webapps目录挂载在外部 docker run -p 8080:8080 -v /root/webapps:/usr/local/tomcat/webapps -d --name mytomcat tomcat 安装MongoDB数据库12345678910111213141516171819# 1.运行mongDB docker run -d -p 27017:27017 --name mymongo mongo ---无须权限 docker logs -f mymongo --查看mongo运行日志# 2.进入mongodb容器 docker exec -it mymongo /bin/bash 直接执行mongo命令进行操作# 3.常见具有权限的容器 docker run --name mymongo -p 27017:27017 -d mongo --auth# 4.进入容器配置用户名密码 mongo use admin 选择admin库 db.createUser({user:&quot;root&quot;,pwd:&quot;root&quot;,roles:[{role:'root',db:'admin'}]}) //创建用户,此用户创建成功,则后续操作都需要用户认证 exit# 5.将mongoDB中数据目录映射到宿主机中 docker run -d -p 27017:27017 -v /root/mongo/data:/data/db --name mymongo mongo 安装ElasticSearch 注意:​调高JVM线程数限制数量 拉取镜像运行elasticsearch123456# 1.dockerhub 拉取镜像 docker pull elasticsearch:6.4.2# 2.查看docker镜像 docker images# 3.运行docker镜像 docker run -p 9200:9200 -p 9300:9300 elasticsearch:6.4.2 启动出现如下错误 预先配置123456789# 1.在centos虚拟机中，修改配置sysctl.conf vim /etc/sysctl.conf# 2.加入如下配置 vm.max_map_count=262144 # 3.启用配置 sysctl -p 注：这一步是为了防止启动容器时，报出如下错误： bootstrap checks failed max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 启动EleasticSearch容器1234# 0.复制容器中data目录到宿主机中 docker cp 容器id:/usr/share/share/elasticsearch/data /root/es# 1.运行ES容器 指定jvm内存大小并指定ik分词器位置 docker run -d --name es -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=&quot;-Xms128m -Xmx128m&quot; -v /root/es/plugins:/usr/share/elasticsearch/plugins -v /root/es/data:/usr/share/elasticsearch/data elasticsearch:6.4.2 安装IK分词器123456789101112131415161718192021222324252627# 1.下载对应版本的IK分词器 wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.4.2/elasticsearch-analysis-ik-6.4.2.zip# 2.解压到plugins文件夹中 yum install -y unzip unzip -d ik elasticsearch-analysis-ik-6.4.2.zip# 3.添加自定义扩展词和停用词 cd plugins/elasticsearch/config vim IKAnalyzer.cfg.xml &lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=&quot;ext_dict&quot;&gt;ext_dict.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;ext_stopwords.dic&lt;/entry&gt; &lt;/properties&gt;# 4.在ik分词器目录下config目录中创建ext_dict.dic文件 编码一定要为UTF-8才能生效 vim ext_dict.dic 加入扩展词即可# 5. 在ik分词器目录下config目录中创建ext_stopword.dic文件 vim ext_stopwords.dic 加入停用词即可# 6.重启容器生效 docker restart 容器id# 7.将此容器提交成为一个新的镜像 docker commit -a=&quot;xiaochen&quot; -m=&quot;es with IKAnalyzer&quot; 容器id xiaochen/elasticsearch:6.4.2 安装Kibana12345# 1.下载kibana镜像到本地 docker pull kibana:6.4.2# 2.启动kibana容器 docker run -d --name kibana -e ELASTICSEARCH_URL=http://10.15.0.3:9200 -p 5601:5601 kibana:6.4.2 Docker中出现如下错误解决方案12[root@localhost ~]# docker search mysql 或者 docker pull 这些命令无法使用Error response from daemon: Get https://index.docker.io/v1/search?q=mysql&amp;n=25: x509: certificate has expired or is not yet valid 注意:这个错误的原因在于是系统的时间和docker hub时间不一致,需要做系统时间与网络时间同步 1234567# 1.安装时间同步 sudo yum -y install ntp ntpdate# 2.同步时间 sudo ntpdate cn.pool.ntp.org# 3.查看本机时间 date# 4.从新测试 Dockerfile什么是DockerfileDockerfile可以认为是Docker镜像的描述文件，是由一系列命令和参数构成的脚本。主要作用是用来构建docker镜像的构建文件。 ​​ 通过架构图可以看出通过DockerFile可以直接构建镜像 Dockerfile解析过程 Dockerfile的保留命令官方说明:https://docs.docker.com/engine/reference/builder/ 保留字 作用 FROM 当前镜像是基于哪个镜像的 第一个指令必须是FROM MAINTAINER 镜像维护者的姓名和邮箱地址 RUN 构建镜像时需要运行的指令 EXPOSE 当前容器对外暴露出的端口号 WORKDIR 指定在创建容器后，终端默认登录进来的工作目录，一个落脚点 ENV 用来在构建镜像过程中设置环境变量 ADD 将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar包 COPY 类似于ADD，拷贝文件和目录到镜像中​将从构建上下文目录中&lt;原路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置 VOLUME 容器数据卷，用于数据保存和持久化工作 CMD 指定一个容器启动时要运行的命令​Dockerfile中可以有多个CMD指令，但只有最后一个生效，CMD会被docker run之后的参数替换 ENTRYPOINT 指定一个容器启动时要运行的命令​ENTRYPOINT的目的和CMD一样，都是在指定容器启动程序及其参数 FROM 命令 基于那个镜像进行构建新的镜像,在构建时会自动从docker hub拉取base镜像 必须作为Dockerfile的第一个指令出现 语法: 123FROM &lt;image&gt;FROM &lt;image&gt;[:&lt;tag&gt;] 使用版本不写为latestFROM &lt;image&gt;[@&lt;digest&gt;] 使用摘要 MAINTAINER 命令 镜像维护者的姓名和邮箱地址[废弃] 语法: 1MAINTAINER &lt;name&gt; RUN 命令 RUN指令将在当前映像之上的新层中执行任何命令并提交结果。生成的提交映像将用于Dockerfile中的下一步 语法: 12345RUN &lt;command&gt; (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows)RUN echo helloRUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form)RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;] EXPOSE 命令 用来指定构建的镜像在运行为容器时对外暴露的端口 语法: 12EXPOSE 80/tcp 如果没有显示指定则默认暴露都是tcpEXPOSE 80/udp CMD 命令 用来为启动的容器指定执行的命令,在Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。 注意: Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。 语法: 123CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec form, this is the preferred form)CMD [&quot;param1&quot;,&quot;param2&quot;] (as default parameters to ENTRYPOINT)CMD command param1 param2 (shell form) WORKDIR 命令 用来为Dockerfile中的任何RUN、CMD、ENTRYPOINT、COPY和ADD指令设置工作目录。如果WORKDIR不存在，即使它没有在任何后续Dockerfile指令中使用，它也将被创建。 语法: 123456WORKDIR /path/to/workdirWORKDIR /aWORKDIR bWORKDIR c`注意:WORKDIR指令可以在Dockerfile中多次使用。如果提供了相对路径，则该路径将与先前WORKDIR指令的路径相对` ENV 命令 用来为构建镜像设置环境变量。这个值将出现在构建阶段中所有后续指令的环境中。 语法： 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key&gt;=&lt;value&gt; ... ADD 命令 用来从context上下文复制新文件、目录或远程文件url，并将它们添加到位于指定路径的映像文件系统中。 语法: 12345ADD hom* /mydir/ 通配符添加多个文件ADD hom?.txt /mydir/ 通配符添加ADD test.txt relativeDir/ 可以指定相对路径ADD test.txt /absoluteDir/ 也可以指定绝对路径ADD url COPY 命令 用来将context目录中指定文件复制到镜像的指定目录中 语法: 12COPY src destCOPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] VOLUME 命令 用来定义容器运行时可以挂在到宿主机的目录 语法: 1VOLUME [&quot;/data&quot;] ENTRYPOINT命令 用来指定容器启动时执行命令和CMD类似 语法: 12 [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]ENTRYPOINT command param1 param2 ENTRYPOINT指令，往往用于设置容器启动后的第一个命令，这对一个容器来说往往是固定的。CMD指令，往往用于设置容器启动的第一个命令的默认参数，这对一个容器来说可以是变化的。 ENTRYPOINT命令Dockerfile构建springboot项目部署准备springboot可运行项目 将可运行项目放入linux虚拟机中 编写Dockerfile123456FROM openjdk:8WORKDIR /emsADD ems.jar /emsEXPOSE 8989ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;]CMD [&quot;ems.jar&quot;] 构建镜像1[root@localhost ems]# docker build -t ems . 运行镜像1[root@localhost ems]# docker run -p 8989:8989 ems 访问项目1http://10.15.0.8:8989/ems/login.html 高级网络配置说明当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。 同时，Docker 随机分配一个本地未占用的私有网段（在 RFC1918 中定义）中的一个地址给 docker0 接口。比如典型的 172.17.42.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。 当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。 查看网络信息1# docker network ls 创建一个网桥1# docker network create -d bridge 网桥名称 删除一个网桥1# docker network rm 网桥名称 容器之前使用网络通信12# 1.查询当前网络配置- docker network ls 1234NETWORK ID NAME DRIVER SCOPE8e424e5936b7 bridge bridge local17d974db02da docker_gwbridge bridge locald6c326e433f7 host host local 12# 2.创建桥接网络- docker network create -d bridge info 12345678[root@centos ~]# docker network create -d bridge info6e4aaebff79b1df43a064e0e8fdab08f52d64ce34db78dd5184ce7aaaf550a2f[root@centos ~]# docker network lsNETWORK ID NAME DRIVER SCOPE8e424e5936b7 bridge bridge local17d974db02da docker_gwbridge bridge locald6c326e433f7 host host local6e4aaebff79b info bridge local 1234# 3.启动容器指定使用网桥- docker run -d -p 8890:80 --name nginx001 --network info nginx - docker run -d -p 8891:80 --name nginx002 --network info nginx `注意:一旦指定网桥后--name指定名字就是主机名,多个容器指定在同一个网桥时,可以在任意一个容器中使用主机名与容器进行互通` 12345678910111213141516[root@centos ~]# docker run -d -p 8890:80 --name nginx001 --network info nginx c315bcc94e9ddaa36eb6c6f16ca51592b1ac8bf1ecfe9d8f01d892f3f10825fe[root@centos ~]# docker run -d -p 8891:80 --name nginx002 --network info nginxf8682db35dd7fb4395f90edb38df7cad71bbfaba71b6a4c6e2a3a525cb73c2a5[root@centos ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf8682db35dd7 nginx &quot;/docker-entrypoint.…&quot; 3 seconds ago Up 2 seconds 0.0.0.0:8891-&gt;80/tcp nginx002c315bcc94e9d nginx &quot;/docker-entrypoint.…&quot; 7 minutes ago Up 7 minutes 0.0.0.0:8890-&gt;80/tcp nginx001b63169d43792 mysql:5.7.19 &quot;docker-entrypoint.s…&quot; 7 minutes ago Up 7 minutes 3306/tcp mysql_mysql.1.s75qe5kkpwwttyf0wrjvd2cda[root@centos ~]# docker exec -it f8682db35dd7 /bin/bashroot@f8682db35dd7:/# curl http://nginx001&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;..... 高级数据卷配置说明数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性： 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。 创建数据卷12[root@centos ~]# docker volume create my-volmy-vol 查看数据卷123456789101112[root@centos ~]# docker volume inspect my-vol [ { &quot;CreatedAt&quot;: &quot;2020-11-25T11:43:56+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: {}, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Options&quot;: {}, &quot;Scope&quot;: &quot;local&quot; }] 挂载数据卷1234567891011121314[root@centos ~]# docker run -d -P --name web -v my-vol:/usr/share/nginx/html nginx[root@centos ~]# docker inspect web &quot;Mounts&quot;: [ { &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;z&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; } ], 删除数据卷1docker volume rm my-vol Docker Compose简介Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。 其代码目前在 https://github.com/docker/compose 上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 安装与卸载1.linux 在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。例如，在 Linux 64 位系统上直接下载对应的二进制包。 12$ sudo curl -L https://github.com/docker/compose/releases/download/1.25.5/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose 2.macos、window Compose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。Docker Desktop for Mac/Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 3.bash命令补全1$ curl -L https://raw.githubusercontent.com/docker/compose/1.25.5/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose 4.卸载 如果是二进制包方式安装的，删除二进制文件即可。 1$ sudo rm /usr/local/bin/docker-compose 5.测试安装成功12$ docker-compose --version docker-compose version 1.25.5, build 4667896b docker compose使用1# 1.相关概念 首先介绍几个术语。 服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元。∂一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。 1# 2.场景 最常见的项目是 web 网站，该项目应该包含 web 应用和缓存。 springboot应用 mysql服务 redis服务 elasticsearch服务 ……. 12# 3.docker-compose模板- 参考文档:https://docker_practice.gitee.io/zh-cn/compose/compose_file.html 12345678910111213141516171819202122232425262728293031version: &quot;3.0&quot;services: mysqldb: image: mysql:5.7.19 container_name: mysql ports: - &quot;3306:3306&quot; volumes: - /root/mysql/conf:/etc/mysql/conf.d - /root/mysql/logs:/logs - /root/mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: root networks: - ems depends_on: - redis redis: image: redis:4.0.14 container_name: redis ports: - &quot;6379:6379&quot; networks: - ems volumes: - /root/redis/data:/data command: redis-server networks: ems: 12# 4.通过docker-compose运行一组容器- 参考文档:https://docker_practice.gitee.io/zh-cn/compose/commands.html 12[root@centos ~]# docker-compose up //前台启动一组服务[root@centos ~]# docker-compose up -d //后台启动一组服务 docker-compose 模板文件模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。 默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。 123456789version: &quot;3&quot;services: webapp: image: examples/web ports: - &quot;80:80&quot; volumes: - &quot;/data&quot; 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。 如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中重复设置。 下面分别介绍各个指令的用法。 build指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 12345version: '3'services: webapp: build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。 123456789version: '3'services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 command覆盖容器启动后默认执行的命令。 1command: echo &quot;hello world&quot; container_name指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 1container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 depends_on解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web 1234567891011121314version: '3'services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。 env_file从文件中获取环境变量，可以为单独的文件路径或列表。 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 123456env_file: .envenv_file: - ./common.env - ./apps/web.env - /opt/secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 12# common.env: Set development environmentPROG_ENV=development environment设置环境变量。你可以使用数组或字典两种格式。 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。 1234567environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV=development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 1y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF healthcheck通过命令检查容器是否健康运行。 12345healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 1m30s timeout: 10s retries: 3 image指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 123image: ubuntuimage: orchardup/postgresqlimage: a4bc65fd networks配置容器连接的网络。 1234567891011version: &quot;3&quot;services: some-service: networks: - some-network - other-networknetworks: some-network: other-network: ports暴露端口信息。 使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 12345ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; *注意：当使用 ​HOST:CONTAINER*​ * 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 ​YAML*​ * 会自动解析 ​xx:yy​ * 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 sysctls配置容器内核参数。 1234567sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits指定容器的 ulimits 限制值。 例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 12345ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes数据卷所挂载路径设置。可以设置为宿主机路径(HOST:CONTAINER)或者数据卷名称(VOLUME:CONTAINER)，并且可以设置访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 1234volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 如果路径为数据卷名称，必须在文件中配置数据卷。 12345678910version: &quot;3&quot;services: my_src: image: mysql:8.0 volumes: - mysql_data:/var/lib/mysqlvolumes: mysql_data: docker-compose 常用命令1. 命令对象与格式对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。 执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。 docker-compose 命令的基本的使用格式是 1docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...] 2. 命令选项 -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --x-networking 使用 Docker 的可拔插网络后端特性 --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 3.命令使用说明up格式为 docker-compose up [options] [SERVICE...]。 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 链接的服务都将会被自动启动，除非已经处于运行状态。 可以说，大部分时候都可以直接通过该命令来启动一个项目。 默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。 当通过 Ctrl-C 停止命令时，所有容器将会停止。 如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。 默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容 down 此命令将会停止 up 命令所启动的容器，并移除网络 exec 进入指定的容器。 ps格式为 docker-compose ps [options] [SERVICE...]。 列出项目中目前的所有容器。 选项： -q 只打印容器的 ID 信息。 restart格式为 docker-compose restart [options] [SERVICE...]。 重启项目中的服务。 选项： -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm格式为 docker-compose rm [options] [SERVICE...]。 删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 选项： -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 start格式为 docker-compose start [SERVICE...]。 启动已经存在的服务容器。 stop格式为 docker-compose stop [options] [SERVICE...]。 停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top查看各个服务容器内运行的进程。 unpause格式为 docker-compose unpause [SERVICE...]。 恢复处于暂停状态中的服务。 可视化管理工具安装Portainer官方安装说明：https://www.portainer.io/installation/ 123456789[root@ubuntu1804 ~]#docker pull portainer/portainer[root@ubuntu1804 ~]#docker volume create portainer_dataportainer_data[root@ubuntu1804 ~]#docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer20db26b67b791648c2ef6aee444a5226a9c897ebcf0160050e722dbf4a4906e3[root@ubuntu1804 ~]#docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES20db26b67b79 portainer/portainer &quot;/portainer&quot; 5 seconds ago Up 4 seconds 0.0.0.0:8000-&gt;8000/tcp, 0.0.0.0:9000-&gt;9000/tcp portainer 登录和使用Portainer 用浏览器访问：http://localhost:9000 ​ 使用过程… Docker 核心原理从表层来看docker的组成部分是由：仓库、镜像、容器三个部分组成，这是基础层面的体现 犹如MySQL事务的特性：ACID（原子性、一致性、隔离性、持久性）但是维持ACID背后的机制/原理是什么？ 答： 持久性是通过 redo log （重做日志）来保证的； 原子性是通过 undo log（回滚日志） 来保证的； 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的； 一致性则是通过持久性+原子性+隔离性来保证； 那么类推docker的三个组成部分或者三个核心概念背后的三个原理是什么支持的？ 答：Namespace、Cgroups、rootfs。 （联想：既然docker中的技术是参考Linux内核实现的，那么这其中究竟有多少联系？） Namespace，做隔离，让进程只能看到Namespace中的世界； Cgroups，做限制，让这个“世界”围着一个看不见的墙。 rootfs，做文件系统，rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。 注意此处 Linux Namespace 不要和 k8s Namespace 概念混淆： Linux Namespace 机制：用于资源和视图隔离，使宿主机看不到容器内的资源，容器也看不到其他容器内的资源，实现不同应用的视图隔离，避免干扰 k8s Namespace 机制：就是用户资源的隔离，为了便于管理 k8s 自身的资源 Namespace本质就是一个障眼法，进入容器后ps看到不同的pid，其实就是namespace的幻化，本质上容器就是一个运行的进程，其它的进程实际是pid为1的子进程，namespace提供了许多种的障眼法。 ​ namespace本质是怎么建立的？ 每一次创建容器的时候本质是Linux系统的fork的调用，在fork调用时会传入一些参数，这个会对Linux内核进行控制生成新的namespace rootfs本质是根文件系统，挂载在容器根目录上，为容器提供隔离后执行环境的文件系统，即容器镜像。 容器的rootfs由三部分组成，1：只读层、2：可读写层、3：init层 只读层:都以增量的方式分别包含了操作系统的一部分。 可读写：就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用 docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub 上，供其他人使用；而与此同时，原先的只读层里的内容则不会有任何变化。这，就是增量 rootfs 的好处。 Init 层：是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。 Cgroups 虽然容器内的第 1 号进程在“障眼法”的干扰下只能看到容器里的情况，但是宿主机上，它作为第 100 号进程与其他所有进程之间依然是平等的竞争关系。这就意味着，虽然第 100 号进程表面上被隔离了起来，但是它所能够使用到的资源（比如 CPU、内存），却是可以随时被宿主机上的其他进程（或者其他容器）占用的。当然，这个 100 号进程自己也可能把所有资源吃光。这些情况，显然都不是一个“沙盒”应该表现出来的合理行为。 而 Linux Cgroups 就是 Linux 内核中用来为进程设置资源限制的一个重要功能。 Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。此外，Cgroups 还能够对进程进行优先级设置、审计，以及将进程挂起和恢复等操作。 参考： 容器基础之三大基石","link":"/post/docker-z1rrgi5.html"},{"title":"Goland 快捷键、模板与一些规范","text":"Goland 快捷键、模板与一些规范题记： 快捷键的使用可以大大提高效率，良好的注释对项目后续的开发维护工作也是十分必要。本文档旨在明确项目开发过程中go代码的注释规范，并提供基于goland的注释模板设置指导。便于开发人员快速配置环境，高效、合规开展工作。 规范部分随缘整理….. 我的配置 Go文件采用goland自带的go文件和代码模板 123456789101112/** * @Description //TODO * @Author luommy * @Date ${DATE} ${TIME} **/package ${GO_PACKAGE_NAME}// 我不习惯加这个func main() {} ​​​​ ‍ 方法、结构体、接口注释采用插件实现 ‍ 自定义快捷键与注释模板​自定义快捷键：CTRL+J​ ​​ 添加新建类的注释模板路径：File -&gt; Settings -&gt; File and Code Templates ​​ 添加如下信息： 123456789package ${GO_PACKAGE_NAME}/** * @Description //TODO * @Author luommy * @Date ${DATE} ${TIME} **/func main() {} 添加方法注释模板‍ Live Templates ​ go templates 内置函数‍ 在模板变量中使用的预定义函数有很多都用不到的，感觉并不好用，没啥能用到的场景 Item Description ​lowercaseAndDash(String)​​ 将驼峰字符串转换为小写，并插入连接符作为分隔符。例如,lowercaseAndDash(MyExampleName)​​返回my-example-name​​. ​snakeCase(String)​​ 将驼峰字符串转化为蛇形字符串，例如,snakeCase(fooBar)​​返回foo_bar​​. ​spaceSeparated(String)​​ 将字符串转化为小写并插入空格作为分隔符，例如,spaceSeparated(fooBar)​​returnsfoo bar​​. ​underscoresToCamelCase(String)​​ 将蛇形字符串转化为驼峰字符串. 例如,underscoresToCamelCase(foo_bar)​​返回fooBar​​. ​underscoresToSpaces(sParameterWithSpaces)​​ 将字符串中的下划线替换为空格. 例如,underscoresToSpaces(foo_bar)​​返回foo bar​​. ​camelCase(String)​​ 将字符串转化为驼峰法. 例如,camelCase(my-text-file)​​,camelCase(my text file)​​, 和camelCase(my_text_file)​​均返回myTextFile​​. ​capitalize(String)​​ 将参数的第一个字母大写。 ​capitalizeAndUnderscore(sCamelCaseName)​​ 根据驼峰法分割参数，将各个部分转化为大写，并插入下划线。例如,capitalizeAndUnderscore(FooBar)​​返回FOO_BAR​​. ​classNameComplete()​​ 这个表达式代替了在变量位置完成类名。 ​clipboard()​​ 返回系统剪贴板的内容。 ​complete()​​ 引用代码完成。 ​completeSmart()​​ 调用变量位置的智能类型完成。 ​concat(expressions...)​​ 返回传递给函数的所有字符串作为参数的级联。 ​date(sDate)​​ 以指定的格式返回当前系统日期。如果没有参数，则以默认的系统格式返回当前日期。 ​decapitalize(sName)​​ 用相应的小写字母替换参数的第一个字母。 ​enum(sCompletionString1,sCompletionString2,...)​​ 返回在模板扩展时建议完成的逗号分隔字符串的列表。 ​escapeString(sEscapeString)​​ Escapes the string specified as the parameter. ​expectedType()​​ Returns the expected type of the expression into which the template expands. Makes sense if the template expands in the right part of an assignment, afterreturn​​, etc. ​fileName()​​ 返回当前文件（包括扩展名） ​fileNameWithoutExtension()​​ 返回当前文件（不包括扩展名） ​firstWord(sFirstWord)​​ 返回作为参数传递的字符串的第一个单词。 ​lineNumber()​​ 返回当前行数。 ​substringBefore(String,Delimiter)​​ 删除指定分隔符之后的扩展名，只返回文件名。这对测试文件名是有帮助的，例如,substringBefore($FileName$,&quot;.&quot;)​​returnscomponent-test​​incomponent-test.js​​). ​time(sSystemTime)​​ 以指定的格式返回当前系统时间。 ​timestamp()​​ 返回当前系统时间戳 ​user()​​ 返回当前用户 ‍ ‍ 中英互译插件目前觉得挺好用的 支持自定义快捷键：setting-keymap-plugins 习惯设置Alt+T 一键互译 ​​ 注释插件：Goanno插件市场安装，通过tools进行配置——Goanno Setting ​​​​ 方法、接口、结构体注释模板配置​​ 配置内容如下： 123456789101112131415161718192021222324Normal Method 配置内容：/** @Title ${function_name} @Description ${todo} @Author luommy ${date} @Param ${params} @Return ${return_types} **/interface配置内容// ${interface_name} Interface Method 配置内容// @Title ${function_name} // @Description ${todo} // @Author luommy ${date} // @Param ${params} // @Return ${return_types} Struct配置内容// ${struct_name} Struct Field 不做配置 配置完成点击submit 验证注释 在方法、结构体、接口上 win使用快捷键: ctrl +alt +/​ mac使用快捷键:control + commond + /​ 可自动生成注释 如下截图: ​ AI 插件 CodeGeeX官网 几个重点的功能： 多语言代码之间翻译，无缝转换 注释生成代码/自动补全代码 AI问答","link":"/post/goland-shortcut-key-template-and-some-specifications-z2131hx.html"},{"title":"领域算法知识体系","text":"领域算法 最近一直有一个概念在脑子中循环：程序设计 = 数据结构 + 算法 基于目前的认知我想把算法分为常规算法思想和领域算法：常规算法思想如：分治、动态规划、贪心、二分、搜索等；本篇则是领域算法。 不论哪种技术栈或者组件都和算法离不开，比如gin的路由基数树、负载均衡各种算法、分布式一致性算法、和加密相关的安全算法、分布式ID雪花算法，因此准备抽一些时间好好整理并学习下这部分的内容，这部分我称之为领域算法，形成一个完整的知识体系，不求多深入、多底层，但求个人程度上的理解,快速形成知识体系。 ‍ ​​ ‍ 重点关注：负载均衡、雪花、一致性以及一点点大数据相关的，希望形成自己的理解","link":"/post/field-algorithm-1sbsuf.html"},{"title":"","text":"Golang 📄 Go典型使用·实例 📑 重学系列 📄 Go经验小记 📄 练习两年半释疑 📄 Go新版本特性 📄 最常用的 Go CLI 命令 📄 重学Go语言 | 如何在Go中使用Context 📑 Go并发编程 📄 Go语言实现的可读性更高的并发神库 🥗 Golang门面担当 📄 GMP模型的知识体系 📄 Go 语言五大日志库 📄 Go语言——延迟函数defer的使用 📄 Go语言——Map的底层介绍及扩缩容机制 📄 Go语言——切片(Slice)的坑 📄 Go语言——内存管理 📑 专项 📄 Gorm框架的思考 📄 Go与操作系统的线程（进程）间通信 📄 Go单机锁与同步原语 📄 深入解析go channel各状态下的操作结果 📄 解密Go协程的栈内存管理 📄 Golang实现延迟队列（DelayQueue） 📄 go channel的应用案例 📑 Gin深入理解 📄 Gin框架流程原理以及上下文、内存的思考 📄 我给 gin 提交了一行代码 - 墨天轮 📄 由Gin路由原理引发的一系列思考 📄 Gin路由设计及源码分析：httprouter路由实现原理 📄 Gin生命周期 📑 Google书签整理 📄 Go Modules 依赖管理，这篇总结的挺全 📄 最全Go select底层原理，一文学透高频用法 📄 剑指 Offer 38. 字符串的排列 📄 阅读破10万的学Go建议，不管初学还是进阶Go都值得一看！ 📍 日常小结 📄 【Golang】来几道题以加强切片知识 📄 goland-IDEOlog 插件 📄 Rob Pike谈Google Go 📄 Go的数组与切片傻傻分不清楚 📄 Go获取IP地址 📄 json字段控制 📄 Go 语言 iota 的神奇力量 📄 日志框架 📄 Go语言的%d,%p,%v等占位符的使用 📄 Go Web开发的五大利器 📄 Go中常见的IO模式 📄 Go常见错误第16篇：any的常见错误和最佳实践 - 掘金 📄 GORM框架 📄 标准库-time包 📄 高阶函数编程Go语言中的函数一等公民 📄 【Golang】怎样优雅的清空切片 📄 Go web项目布局 📄 死锁、活锁、饥饿、自旋锁（Go 语言描述） 📄 2023.3.8小结 📄 《100 Go Mistakes and How to Avoid Them》 📑 进阶篇 📄 Context包源码解读 📄 nethttp库源码解读 📄 Golang 单机锁实现原理 📄 进阶篇之函数篇 📄 优秀后端都应该具备的开发好习惯 📄 进阶篇之结构体篇 📄 Go Channel底层原理 📄 go语言反射的使用 📄 time包 📄 json字段控制 📄 深入浅出Go调度器中的GMP模型 📄 有无缓冲管道 📄 一文让你理解go语言的Context 📄 GO语言实现设计模式【上】 📄 GO语言实现设计模式【下】 📑 框架 📑 Go-zero 📄 玩转 Go 链路追踪 📄 go-zero 是如何追踪你的请求链路 📄 GoFrame学习之路 📑 RPC与GRPC 📄 RPC 📄 grpcurl的使用 📄 grpcui安装使用 ‍","link":"/post/golang-2sensm.html"},{"title":"高并发设计思考体系","text":"高并发设计思考体系 读了苏三的博客，进一步对高并发设计整体的思考多了许多 。 在原文章上加入一些自己了理解和新的认识。 “ 高并发不会是区别大厂、小厂工程师的标准，却是 检验技术实力的一道关。” 如何设计一个​高并发系统 ？ 瞬间联想秒杀系统？50W QPS？数据库、缓存、消息队列、分布式服务如何演进的？ 这个问题真的可以无限无限难，这个问题也是激发我学习的动力，后续会花一部分时间专研这部分，本文章目的是扩展下高并发设计的解决思路，即总纲。 对于高并发的设计理念有了比较系统的理解与认识，尤其是对于某些架构方面的认识，越来越觉得高并发、微服务、分布式这些获取比较庞大知识体系其实是相互共存的，懂了一方面理解另一方面也会更加容器，也更容易形成知识体系。 本部分与 Go并发编程 直接联系，当然了并发编程不一定局限于某种语言，思想和实践方式都有比较类似之处。 ‍ 关联文章： 并发编程的业务场景 参考文章： 苏三博客 并发设计解决宏图​​ 从前端——后端——运维 每一个步骤和环节都有着处理的方式，眼界瞬间就提升了，不是因为你是后端，局限于后端的部分，或者是前端。 解决思路1 页面静态化对于高并发系统的页面功能，我们必须要做静态化​设计。 如果并发访问系统的用户非常多，每次用户访问页面的时候，都通过服务器动态渲染，会导致服务端承受过大的压力，而导致页面无法正常加载的情况发生。 使用Freemarker​或Velocity​模板引擎，实现页面静态化功能。 以商城官网首页为例，我们可以在Job​中，每隔一段时间，查询出所有需要在首页展示的数据，汇总到一起，使用模板引擎生成到html文件当中。 然后将该html​文件，通过shell​脚本，自动同步到前端页面相关的服务器上。 有一说一这部分是 前端 的部分工作，并不了解，问了几个前端的朋友也没有了解过的，可能大厂的前端才可能用? 不得而知。 2 CDN加速虽说页面静态化可以提升网站网页的访问速度，但还不够，因为用户分布在全国各地，有些人在北京，有些人在成都，有些人在深圳，地域相差很远，他们访问网站的网速各不相同。 如何才能让用户最快访问到活动页面呢？ 这就需要使用CDN，它的全称是Content Delivery Network，即内容分发网络。 ​ 使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。 CDN加速的基本原理是：将网站的静态内容（如图片、CSS、JavaScript文件等）复制并存储到分布在全球各地的服务器节点上。 ——当用户请求访问网站时，CDN系统会根据用户的地理位置，自动将内容分发给离用户最近的服务器，从而实现快速访问。 国内常见的CDN提供商有阿里云CDN、腾讯云CDN、百度云加速等，它们提供了全球分布的节点服务器，为全球范围内的网站加速服务。 这个东西在大学期间就有所耳闻，其实也很好理解。 3 缓存在高并发的系统中，缓存​可以说是必不可少的技术之一。 目前缓存有两种： 基于应用服务器的内存缓存，也就是我们说的二级缓存。 使用缓存中间件，比如：Redis、Memcached等，这种是分布式缓存。 这两种缓存各有优缺点。 二级缓存的性能更好，但因为是基于应用服务器内存的缓存，如果系统部署到了多个服务器节点，可能会存在数据不一致的情况。 而Redis或Memcached虽说性能上比不上二级缓存，但它们是分布式缓存，避免多个服务器节点数据不一致的问题。 缓存的用法一般是这样的：使用缓存之后，可以减轻访问数据库的压力，显著的提升系统的性能。 有些业务场景，甚至会分布式缓存和二级缓存一起使用。 比如获取商品分类数据，流程如下：​ 不过引入缓存，虽说给我们的系统性能带来了提升，但同时也给我们带来了一些新的问题，比如：《数据库和缓存双向数据库一致性问题》、《缓存穿透、击穿和雪崩问题》等。要结合实际业务场景，切记不要为了缓存而缓存。 4 异步有时候，我们在高并发系统当中，某些接口的业务逻辑，没必要都同步执行。 比如有个用户请求接口中，需要做业务操作，发站内通知，和记录操作日志。为了实现起来比较方便，通常我们会将这些逻辑放在接口中同步执行，势必会对接口性能造成一定的影响。 接口内部流程图如下： 这个接口表面上看起来没有问题，但如果你仔细梳理一下业务逻辑，会发现只有业务操作才是核心逻辑，其他的功能都是非核心逻辑。 在这里有个原则就是：核心逻辑可以同步执行，同步写库。非核心逻辑，可以异步执行，异步写库。 上面这个例子中，发站内通知和用户操作日志功能，对实时性要求不高，即使晚点写库，用户无非是晚点收到站内通知，或者运营晚点看到用户操作日志，对业务影响不大，所以完全可以异步处理。 通常异步主要有两种：多线程 和 mq。 这部分内容在项目中经常能用到，比如一个OA系统在同步业务处理的时候需要把业务内容同步给邮箱让用户知晓，但这个同步的过程不是核心业务，也就是晚点通知、早点通知都是无所谓的，不影响系统的功能。 4.1 线程池使用线程池改造之后，接口逻辑如下： 发站内通知和用户操作日志功能，被提交到了两个单独的线程池中。 这样接口中重点关注的是业务操作，把其他的逻辑交给线程异步执行，这样改造之后，让接口性能瞬间提升了。 但使用线程池有个小问题就是：如果服务器重启了，或者是需要被执行的功能出现异常了，无法重试，会丢数据。 那么这个问题该怎么办呢？ =&gt;这个问题：我联想到了幂等性、MQ 、持久化等方面。比较肤浅的思路就是将需要被执行的任务持久化到磁盘或者数据库中，当任务执行失败或服务器重启之后，可以重新读取任务，并进行重试。也许后续会更新…. 4.2 mq使用mq改造之后，接口逻辑如下： 对于发站内通知和用户操作日志功能，在接口中并没真正实现，它只发送了mq消息到mq服务器。然后由mq消费者消费消息时，才真正的执行这两个功能。 这样改造之后，接口性能同样提升了，因为发送mq消息速度是很快的，我们只需关注业务操作的代码即可。 思路非常合理 5 多线程处理在高并发系统当中，用户的请求量很大。 假如我们现在用mq处理业务逻辑。 一下子有大量的用户请求，产生了大量的mq消息，保存到了mq服务器。 而mq的消费者，消费速度很慢。 =》可能会导致大量的消息积压问题。 从而严重影响数据的实时性。 我们需要对消息的消费者做优化。 最快的方式是使用多线程​消费消息，比如：改成线程池消费消息。 当然核心线程数、最大线程数、队列大小 和 线程回收时间，一定要做成配置的，后面可以根据实际情况动态调整。 这样改造之后，我们可以快速解决消息积压问题。 除此之外，在很多数据导入场景，用多线程导入数据，可以提升效率。 温馨提醒一下：使用多线程消费消息，可能会出现消息的顺序问题。如果你的业务场景中，需要保证消息的顺序，则要用其他的方式解决问题。 ‍ 这部分其实就是多线程处理业务了，不但业务开了线程池，同时的消息消费的处理也开线程池来处理 ‍ 6 分库分表有时候，高并发系统的吞吐量受限的不是别的，而是数据库。 当系统发展到一定的阶段，用户并发量大，会有大量的数据库请求，需要占用大量的数据库连接，同时会带来磁盘IO的性能瓶颈问题。 此外，随着用户数量越来越多，产生的数据也越来越多，一张表有可能存不下。由于数据量太大，sql语句查询数据时，即使走了索引也会非常耗时。 这时该怎么办呢？ 答：需要做分库分表​。 如下图所示： 图中将用户库拆分成了三个库，每个库都包含了四张用户表。 如果有用户请求过来的时候，先根据用户id路由到其中一个用户库，然后再定位到某张表。 路由的算法挺多的： 根据id取模，比如：id=7，有4张表，则7%4=3，模为3，路由到用户表3。 给id指定一个区间范围，比如：id的值是0-10万，则数据存在用户表0，id的值是10-20万，则数据存在用户表1。 一致性hash算法 分库分表主要有两个方向：垂直​和水平​。 说实话垂直方向（即业务方向）更简单。 在水平方向（即数据方向）上，分库和分表的作用，其实是有区别的，不能混为一谈。 分库：是为了解决数据库连接资源不足问题，和磁盘IO的性能瓶颈问题。 分表：是为了解决单表数据量太大，sql语句查询数据时，即使走了索引也非常耗时问题。此外还可以解决消耗cpu资源问题。 分库分表：可以解决 数据库连接资源不足、磁盘IO的性能瓶颈、检索数据耗时 和 消耗cpu资源等问题。 如果在有些业务场景中，用户并发量很大，但是需要保存的数据量很少，这时可以只分库，不分表。 如果在有些业务场景中，用户并发量不大，但是需要保存的数量很多，这时可以只分表，不分库。 如果在有些业务场景中，用户并发量大，并且需要保存的数量也很多时，可以分库分表。 关于分库分表更详细的内容，苏三里面讲的更深入《阿里二面：为什么分库分表？》 同时也关联我之前分库分表的思考：微服务下分库分表的思考 7 池化技术其实不光是高并发系统，为了性能考虑，有些低并发的系统，也在使用池化技术​，比如：数据库连接池、线程池等。 池化技术是多例设计模式​的一个体现。 我们都知道创建​和销毁​数据库连接是非常耗时耗资源的操作。 如果每次用户请求，都需要创建一个新的数据库连接，势必会影响程序的性能。 为了提升性能，我们可以创建一批数据库连接，保存到内存中的某个集合中，缓存起来。 这样的话，如果下次有需要用数据库连接的时候，就能直接从集合中获取，不用再额外创建数据库连接，这样处理将会给我们提升系统性能。当然用完之后，需要及时归还。 目前常用的数据库连接池有：Druid、C3P0、hikari和DBCP等。 8 读写分离不知道你有没有听说过二八原则​，在一个系统当中可能有80%是读数据请求，另外20%是写数据请求。 不过这个比例也不是绝对的。 我想告诉大家的是，一般的系统读数据请求会远远大于写数据请求。 如果读数据请求和写数据请求，都访问同一个数据库，可能会相互抢占数据库连接，相互影响。 我们都知道，一个数据库的数据库连接数量是有限，是非常宝贵的资源，不能因为读数据请求，影响到写数据请求吧？ 这就需要对数据库做读写分离​了。 于是，就出现了主从读写分离架构：考虑刚开始用户量还没那么大，选择的是一主一从的架构，也就是常说的一个master​，一个slave​。 所有的写数据请求，都指向主库。一旦主库写完数据之后，立马异步同步给从库。这样所有的读数据请求，就能及时从从库中获取到数据了（除非网络有延迟）。 但这里有个问题就是：如果用户量确实有些大，如果master挂了，升级slave为master，将所有读写请求都指向新master。 但此时，如果这个新master根本扛不住所有的读写请求，该怎么办？ 这就需要一主多从的架构了：上图中我列的是一主两从，如果master挂了，可以选择从库1或从库2中的一个，升级为新master。假如我们在这里升级从库1为新master，则原来的从库2就变成了新master的的slave了。 调整之后的架构图如下：这样就能解决上面的问题了。 除此之外，如果查询请求量再增大，我们还可以将架构升级为一主三从、一主四从…一主N从等。 9 索引在高并发的系统当中，用户经常需要查询数据，对数据库增加索引​，是必不可少的一个环节。 尤其是表中数据非常多时，加了索引，跟没加索引，执行同一条sql语句，查询相同的数据，耗时可能会相差N个数量级。 虽说索引能够提升SQL语句的查询速度，但索引也不是越多越好。 在insert数据时，需要给索引分配额外的资源，对insert的性能有一定的损耗。 我们要根据实际业务场景来决定创建哪些索引，索引少了，影响查询速度，索引多了，影响写入速度。 很多时候，我们需要经常对索引做优化。 可以将多个单个索引，改成一个联合索引。 删除不要索引。 使用explain关键字，查询SQL语句的执行计划，看看哪些走了索引，哪些没有走索引。 要注意索引失效的一些场景。 必要时可以使用force index来强制查询sql走某个索引。 如果你想进一步了解explain的详细用法，可以看看我的另一篇文章《explain | 索引优化的这把绝世好剑，你真的会用吗？》。 如果你想进一步了解哪些情况下索引会失效，可以看看我的另一篇文章《聊聊索引失效的10种场景，太坑了》。 这一部分涉及到了： 索引失效 索引优化 10 批处理有时候，我们需要从指定的用户集合中，查询出有哪些是在数据库中已经存在的。 实现代码可以这样写： 123456789public List&lt;User&gt; queryUser(List&lt;User&gt; searchList) { if (CollectionUtils.isEmpty(searchList)) { return Collections.emptyList(); } List&lt;User&gt; result = Lists.newArrayList(); searchList.forEach(user -&gt; result.add(userMapper.getUserById(user.getId()))); return result;} 这里如果有50个用户，则需要循环50次，去查询数据库。我们都知道，每查询一次数据库，就是一次远程调用。 如果查询50次数据库，就有50次远程调用，这是非常耗时的操作。 那么，我们如何优化呢？ 答：批处理​。 具体代码如下： 1234567public List&lt;User&gt; queryUser(List&lt;User&gt; searchList) { if (CollectionUtils.isEmpty(searchList)) { return Collections.emptyList(); } List&lt;Long&gt; ids = searchList.stream().map(User::getId).collect(Collectors.toList()); return userMapper.getUserByIds(ids);} 提供一个根据用户id集合批量查询​用户的接口，只远程调用一次，就能查询出所有的数据。 这里有个需要注意的地方是：id集合的大小要做限制，最好一次不要请求太多的数据。要根据实际情况而定，建议控制每次请求的记录条数在500以内。 12345678910111213func queryUsers(searchList []User) []User { if len(searchList) == 0 { return []User{} } var ids []int for _, user := range searchList { ids = append(ids, user.ID) } return getUserByIDList(ids)} 这种批处理的方式还是看业务应用场景比较好理解 11 集群系统部署的服务器节点，可能会down机，比如：服务器的磁盘坏了，或者操作系统出现内存不足问题。 为了保证系统的高可用，我们需要部署多个节点，构成一个集群​，防止因为部分服务器节点挂了，导致系统的整个服务不可用的情况发生。 集群有很多种： 应用服务器集群 数据库集群 中间件集群 文件服务器集群 我们以中间件Redis​为例。 在高并发系统中，用户的数据量非常庞大时，比如用户的缓存数据总共大小有40G，一个服务器节点只有16G的内存。 这样需要部署3台服务器节点。 该业务场景，使用普通的master/slave模式，或者使用哨兵模式都行不通。 40G的数据，不能只保存到一台服务器节点，需要均分到3个master服务器节点上，一个master服务器节点保存13.3G的数据。 当有用户请求过来的时候，先经过路由，根据用户的id或者ip，每次都访问指定的服务器节点。这用就构成了一个集群。 但这样有风险，为了防止其中一个master服务器节点挂掉，导致部分用户的缓存访问不了，还需要对数据做备份。 这样每一个master，都需要有一个slave，做数据备份。 如果master挂了，可以将slave升级为新的master，而不影响用户的正常使用。 本质还是结合了主从的思想，这里有个问题，一个节点就代表一个服务器吗？ 12 负载均衡如果我们的系统部署到了多台服务器节点。那么哪些用户的请求，访问节点a，哪些用户的请求，访问节点b，哪些用户的请求，访问节点c？ 我们需要某种机制，将用户的请求，转发到具体的服务器节点上。 这就需要使用负载均衡​机制了。 在linux下有Nginx​、LVS​、Haproxy​等服务可以提供负载均衡服务。 在SpringCloud微服务架构中，大部分使用的负载均衡组件就是Ribbon​、OpenFegin​或SpringCloud Loadbalancer​。 硬件方面，可以使用F5​实现负载均衡。它可以基于交换机实现负载均衡，性能更好，但是价格更贵一些。 常用的负载均衡策略有： ​轮询​：每个请求按时间顺序逐一分配到不同的服务器节点，如果服务器节点down掉，能自动剔除。 ​weight权重​：weight代表权重默认为1，权重越高，服务器节点被分配到的概率越大。weight和访问比率成正比，用于服务器节点性能不均的情况。 ​ip hash​：每个请求按访问ip的hash结果分配, 这样每个访客固定访问同一个服务器节点，它是解诀Session共享的问题的解决方案之一。 ​最少连接数​：把请求转发给连接数较少的服务器节点。轮询算法是把请求平均的转发给各个服务器节点，使它们的负载大致相同；但有些请求占用的时间很长，会导致其所在的服务器节点负载较高。这时least_conn方式就可以达到更好的负载均衡效果。 ​最短响应时间​：按服务器节点的响应时间来分配请求，响应时间短的服务器节点优先被分配。 从划分大类上还可以分为动态负载均衡、静态负载均衡；动态负载均衡考虑服务器当前状态，静态不考虑 13 限流对于高并发系统，为了保证系统的稳定性，需要对用户的请求量做限流​。 特别是秒杀系统中，如果不做任何限制，绝大部分商品可能是被机器抢到，而非正常的用户，有点不太公平。 所以，我们有必要识别这些非法请求，做一些限制。那么，我们该如何现在这些非法请求呢？ 目前有两种常用的限流方式： 基于nginx限流 基于redis限流 13.1 对同一用户限流为了防止某个用户，请求接口次数过于频繁，可以只针对该用户做限制。限制同一个用户id，比如每分钟只能请求5次接口。 13.2 对同一ip限流有时候只对某个用户限流是不够的，有些高手可以模拟多个用户请求，这种nginx就没法识别了。 这时需要加同一ip限流功能。限制同一个ip，比如每分钟只能请求5次接口。 但这种限流方式可能会有误杀的情况，比如同一个公司或网吧的出口ip是相同的，如果里面有多个正常用户同时发起请求，有些用户可能会被限制住。 13.3 对接口限流别以为限制了用户和ip就万事大吉，有些高手甚至可以使用代理，每次都请求都换一个ip。 这时可以限制请求的接口总次数。在高并发场景下，这种限制对于系统的稳定性是非常有必要的。但可能由于有些非法请求次数太多，达到了该接口的请求上限，而影响其他的正常用户访问该接口。看起来有点得不偿失。 13.4 加验证码相对于上面三种方式，加验证码的方式可能更精准一些，同样能限制用户的访问频次，但好处是不会存在误杀的情况。 ​通常情况下，用户在请求之前，需要先输入验证码。用户发起请求之后，服务端会去校验该验证码是否正确。只有正确才允许进行下一步操作，否则直接返回，并且提示验证码错误。 此外，验证码一般是一次性的，同一个验证码只允许使用一次，不允许重复使用。 普通验证码，由于生成的数字或者图案比较简单，可能会被破解。优点是生成速度比较快，缺点是有安全隐患。 还有一个验证码叫做：移动滑块​​，它生成速度比较慢，但比较安全，是目前各大互联网公司的首选。 限流应用很常见 14 服务降级前面已经说过，对于高并发系统，为了保证系统的稳定性，需要做限流。 但光做限流还不够。 我们需要合理利用服务器资源，保留核心的功能，将部分非核心的功能，我们可以选择屏蔽或者下线掉。 我们需要做服务降级​。 我们在设计高并发系统时，可以预留一些服务降级的开关。 比如在秒杀系统中，核心的功能是商品的秒杀，对于商品的评论功能，可以暂时屏蔽掉。 在服务端的分布式配置中心，比如：apollo中，可以增加一个开关，配置是否展示评论功能，默认是true。 前端页面通过服务器的接口，获取到该配置参数。 如果需要暂时屏蔽商品评论功能，可以将apollo中的参数设置成false。 此外，我们在设计高并发系统时，还可以预留一些兜底方案。 比如某个分类查询接口，要从redis中获取分类数据，返回给用户。但如果那一条redis挂了，则查询数据失败。 这时候，我们可以增加一个兜底方案。 如果从redis中获取不到数据，则从apollo中获取一份默认的分类数据。 目前使用较多的熔断降级中间件是：Hystrix​ 和 Sentinel​。 Hystrix是Netflix开源的熔断降级组件。 Sentinel是阿里中间件团队开源的一款不光具有熔断降级功能，同时还支持系统负载保护的组件。 二者的区别如下图所示： 降级确实了解的不多 15 故障转移在高并发的系统当中，同一时间有大量的用户访问系统。 如果某一个应用服务器节点处于假死状态，比如CPU使用率100%了，用户的请求没办法及时处理，导致大量用户出现请求超时的情况。 如果这种情况下，不做任何处理，可能会影响系统中部分用户的正常使用。 这时我们需要建立故障转移​机制。 当检测到经常接口超时，或者CPU打满，或者内存溢出的情况，能够自动重启那台服务器节点上的应用。 在SpringCloud微服务当中，可以使用Ribbon​做负载均衡器。 Ribbon是Spring Cloud中的一个负载均衡器组件，它可以检测服务的可用性，并根据一定规则将请求分发至不同的服务节点。在使用Ribbon时，需要注意以下几个方面： 设置请求超时时间，当请求超时时，Ribbon会自动将请求转发到其他可用的服务上。 设置服务的健康检查，Ribbon会自动检测服务的可用性，并将请求转发至可用的服务上。 此外，还需要使用Hystrix​做熔断处理。 Hystrix是SpringCloud中的一个熔断器组件，它可以自动地监测所有通过它调用的服务，并在服务出现故障时自动切换到备用服务。在使用Hystrix时，需要注意以下几个方面： 设置断路器的阈值，当故障率超过一定阈值后，断路器会自动切换到备用服务上。 设置服务的超时时间，如果服务在指定的时间内无法返回结果，断路器会自动切换到备用服务上。到其他的能够正常使用的服务器节点上。 16 异地多活有些高并发系统，为了保证系统的稳定性，不只部署在一个机房当中。 为了防止机房断电，或者某些不可逆的因素，比如：发生地震，导致机房挂了。 需要把系统部署到多个机房。 我们之前的游戏登录系统，就部署到了深圳、天津和成都，这三个机房。 这三个机房都有用户的流量，其中深圳机房占了40%，天津机房占了30%，成都机房占了30%。 如果其中的某个机房突然挂了，流量会被自动分配到另外两个机房当中，不会影响用户的正常使用。 这就需要使用异地多活​​架构了。 用户请求先经过第三方的DNS服务器解析，然后该用户请求到达路由服务器，部署在云服务器上。 路由服务器，根据一定的算法，会将该用户请求分配到具体的机房。 问题也来了：异地多活的难度是多个机房需要做数据同步，如何保证数据的一致性？ 这个好像是多数据中心的问题，是否可以参考多集群下的数据同步，缓存同步同理。比如，通常一个mysql集群有一主多从构成。用户的数据都是写入主库Master，Master将数据写入到本地二进制日志binary log中。从库Slave启动一个IO线程(I/O Thread)从主从同步binlog，写入到本地的relay log中，同时slave还会启动一个SQL Thread，读取本地的relay log，写入到本地，从而实现数据同步。 17 压测高并发系统，在上线之前，必须要做的一件事是做压力测试​。 我们先要预估一下生产环境的请求量，然后对系统做压力测试，之后评估系统需要部署多少个服务器节点。 比如预估有10000的qps，一个服务器节点最大支持1000pqs，这样我们需要部署10个服务器节点。 但假如只部署10个服务器节点，万一突增了一些新的用户请求，服务器可能会扛不住压力。 因此，部署的服务器节点，需要把预估用户请求量的多一些，比如：按3倍的用户请求量来计算。 这样我们需要部署30个服务器节点。 压力测试的结果跟环境有关，在dev环境或者test环境，只能压测一个大概的趋势。 想要更真实的数据，我们需要在pre环境，或者跟生产环境相同配置的专门的压测环境中，进行压力测试。 目前市面上做压力测试的工具有很多，比如开源的有：Jemter、LoaderRunnder、Locust等等。 收费的有：阿里自研的云压测工具PTS。 18 监控监控系统！ 为了出现系统或者SQL问题时，能够让我们及时发现，我们需要对系统做监控。 目前业界使用比较多的开源监控系统是：Prometheus​。 它提供了 监控​ 和 预警​ 的功能。 架构图如下：​ 我们可以用它监控如下信息： 接口响应时间 调用第三方服务耗时 慢查询sql耗时 cpu使用情况 内存使用情况 磁盘使用情况 数据库使用情况 等等······ 它的界面大概长这样子： 可以看到mysql当前qps，活跃线程数，连接数，缓存池的大小等信息。 如果发现数据量连接池占用太多，对接口的性能肯定会有影响。 这时可能是代码中开启了连接忘了关，或者并发量太大了导致的，需要做进一步排查和系统优化。 截图中只是它一小部分功能，如果你想了解更多功能，可以访问 Prometheus的官网 其实，高并发的系统中，还需要考虑安全问题，比如： 遇到用户不断变化ip刷接口怎办？ 遇到用户大量访问缓存中不存在的数据，导致缓存雪崩怎么办？ 如果用户发起ddos攻击怎么办？ 用户并发量突增，导致服务器扛不住了，如何动态扩容？ promethues+grafana 搭建起来确实可以监测很多方面的数据，服务器运行、数据库运行等等均可以很直观的展现，很利于微服务下的项目管控。 ‍","link":"/post/high-combined-design-thinking-system-11vul.html"},{"title":"My Blog ’s Plan","text":"My Blog ’s Plan 早在之前就有过建立自己的博客，但没有坚持下来。现重操旧业，坚持每天输出一篇Blog 整体思路，标签用来关键词联想与提示，或者自成体系的一套内容，分类为专题系列。 ‍ timeline：时间线，结合思源dailynote记录 标签：主要是一些主题性相关的，可能会很杂 例如：十大排序算法Ten-Sorts​​、杂记​​、英语​​、前沿技术​​ 分类： Golang 重学Go（偏基础重新巩固） Golang门面担当（常用的一些底层或者核心） 并发编程（并发相关） 数据结构与算法（偏入门，但是成体系） 架构设计师（面向考试与架构理解） MySQL Redis MQ ELK Docker 分布式 微服务 计算机底层（操作系统、网络、等一些综合性的理解） 🏳️‍🌈 秉持原则: ​ 拒绝无脑CV，深恶痛绝 CSDN 低劣文章，没头没尾，浪费时间 对于容易搜索的到内容有三点：一是要站在巨人的肩膀上总结和理解；二是确实很重点的部分才值得重复做；三自己的新学到内容，可能很粗浅，没有深刻领会，领会后可删除 将精力放在核心上，而不是排版、工具等无意义的点上 详情： A detailed list ‍ ‍","link":"/post/my-blog-content-planning-and-current-plan-z1tjjzq.html"},{"title":"微服务下分库分表的思考","text":"微服务下分库分表的思考 分库分表的这个名词再常见不过了，一开始的理解不够，随着对mysql理解的加深。 关于这个问题目前我的整体前置思路是：Mysql的瓶颈在哪里——InnoDB存储引擎——MySQL单表存储的瓶颈以及瓶颈推演与测试——分库分表，内容不一定绝对，但是思路是完整、有迹可循的。 关联文章：Mysql单表存储数据量瓶颈推演（2000W左右） 目录 什么是分库分表？ 为什么需要分库分表？ 如何分库分表？ 什么时候开始考虑分库分表？ 分库分表会导致哪些问题？如何解决？ 分库分表中间件？ PS: 这里有个小插曲，关于分区的问题，这一点我是在架构师考试备考（数据库）中遇到的问题，mysql为什么好像从来没有听说分区的相关内容，经查资料才了解到数据库按理说是支持分区的，所谓的是将一个表按照一定规则水平划分成多个子表，每个子表存储一部分数据。分区是针对单个表的，个人理解上是物理上可能跨磁盘、跨系统，但本质上还是一张逻辑表，主要的目的是提高查询效率和管理大型表的数据，减少索引长度和IO操作等问题。MySQL不支持分区，但是可以通过其他方式来实现分区的功能。比如，可以通过应用程序来实现分区的功能，或者使用其他数据库管理系统，比如Oracle、SQL Server等，它们都支持分区。MySQL不支持分区是由于历史原因、成本问题和性能问题所致。追根揭底还是技术栈范围扩大后，很多概念是宏观的，很难保证一致性。比如说只聊数据库，会聊关系模式、关系代数、-（前面这些都是关系数据库讲的，我只用Redis的话谈什么这些）数据库设计、聊数据库优化技术，这些东西太过宏观，像是“基础”可我本质上还是觉得完全就不是一类东西，只能算是时代的眼泪，曾经的思想参考。 1. 什么是分库分表分库：就是一个数据库分成多个数据库，部署到不同机器。单体架构下就没有分库分表，比较单一，SOA到微服务的发展中演进的 ​​ 分表：就是一个数据库表分成多个表。 ​​ 2.为什么需要分库分表呢？如果业务量剧增，数据库可能会出现性能瓶颈，这时候我们就需要考虑拆分数据库。从这几方面来看： 磁盘存储（很容易想到，这边便硬件层面的因素） 业务量剧增，MySQL单机磁盘容量会撑爆，拆成多个数据库，磁盘使用率大大降低。 并发连接支撑（这个是mysql本身的瓶颈） 我们知道数据库连接是有限的。在高并发的场景下，大量请求访问数据库，MySQL单机是扛不住的！当前非常火的微服务架构出现，就是为了应对高并发。它把订单、用户、商品等不同模块，拆分成多个应用，并且把单个数据库也拆分成多个不同功能模块的数据库（订单库、用户库、商品库），以分担读写压力。 为什么需要分表？ 数据量太大的话，SQL的查询就会变慢。如果一个查询SQL没命中索引，千百万数据量的表可能会拖垮这个数据库。 即使SQL命中了索引，如果表的数据量超过一千万的话，查询也是会明显变慢的。这是因为索引一般是B+树结构，数据千万级别的话，B+树的高度会增高，查询就变慢啦。 Mysql单表存储数据量瓶颈推演（2000W左右） MySQL的B+树的高度怎么计算的呢？ InnoDB存储引擎最小储存单元是页，一页大小就是16k。B+树叶子存的是数据，内部节点存的是键值+指针。索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而再去数据页中找到需要的数据，B+树结构图如下： ​​ 假设B+树的高度为2的话，即有一个根结点和若干个叶子结点。这棵B+树的存放总记录数为=根结点指针数*单个叶子节点记录行数。 如果一行记录的数据大小为1k，那么单个叶子节点可以存的记录数 =16k/1k =16​ 非叶子节点内存放多少指针呢？我们假设主键ID为bigint类型，长度为8字节(面试官问你int类型，一个int就是32位，4字节)，而指针大小在InnoDB源码中设置为6字节，所以就是 8+6=14 ​​字节，16k/14B =16*1024B/14B = 1170​ 因此，一棵高度为2的B+树，能存放1170 * 16=18720​条这样的数据记录。 同理一棵高度为3​的B+树，能存放1170 *1170 *16 =21902400​，大概可以存放两千万左右的记录。B+树高度一般为1-3层，如果B+到了4层，查询的时候会多查磁盘的次数，SQL就会变慢。 因此单表数据量超过千万-&gt;就需要考虑分表啦。 这个地方从两种角度分析：颗粒度不一样，层面也不一样 1.页的细节角度 16K的页内结构 ​​ ​​ 这种角度： 非叶子节点内指向其他页的数量为 x 叶子节点内能容纳的数据行数为 y B+ 数的层数为 z 页的结构，索引也也不例外，都会有 File Header (38 byte)、Page Header (56 Byte)、Infimum + Supermum（26 byte）、File Trailer（8byte）, 再加上页目录，大概 1k 左右。 我们就当做它就是 1K, 那整个页的大小是 16K, 剩下 15k 用于存数据，在索引页中主要记录的是主键与页号，主键我们假设是 Bigint (8 byte), 而页号也是固定的（4Byte）, 那么索引页中的一条数据的大小=8+4=12byte。15K=15*1024B 所以 非叶子节点内指向其他页的数量x ​=15*1024/12≈1280 行。 叶子节点和非叶子节点的结构是一样的，同理，能放数据的空间也是 15k。 但是叶子节点中存放的是真正的行数据，这个影响的因素就会多很多，比如，字段的类型，字段的数量。每行数据占用空间越大，页中所放的行数量就会越少。 这边我们暂时按一条行数据 1k 来算，那一页就能存下 15 条，Y = 15*1024/1000 ≈15。 算到这边了，是不是心里已经有谱了啊。 Total 总数据行数 根据上述的公式，Total =x^(z-1) *y，已知 x=1280，y=15： 假设 B+ 树是两层，那就是 z = 2， Total = （1280 ^1 ）*15 = 19200 假设 B+ 树是三层，那就是 z = 3， Total = （1280 ^2） *15 = 24576000 （约 2.45kw） ​​ 2.磁盘块角度（上述即是）： ​​ ‍ 3. 如何分库分表 水平即行，垂直即列，一横一竖，横即拆行，竖即拆列 3.1 垂直拆分​​ 3.1.1 垂直分库在业务发展初期，业务功能模块比较少，为了快速上线和迭代，往往采用单个数据库来保存数据。数据库架构如下： ​​ 但是随着业务蒸蒸日上，系统功能逐渐完善。这时候，可以按照系统中的不同业务进行拆分，比如拆分成用户库、订单库、积分库、商品库，把它们部署在不同的数据库服务器，这就是垂直分库。 垂直分库，将原来一个单数据库的压力分担到不同的数据库，可以很好应对高并发场景。数据库垂直拆分后的架构如下： ​​ 3.1.2 垂直分表如果一个单表包含了几十列甚至上百列，管理起来很混乱，每次都select *​的话，还占用IO资源。这时候，我们可以将一些不常用的、数据较大或者长度较长的列拆分到另外一张表。 比如一张用户表，它包含user_id、user_name、mobile_no、age、email、nickname、address、user_desc​，如果email、address、user_desc​等字段不常用，我们可以把它拆分到另外一张表，命名为用户详细信息表。这就是垂直分表： ​​ 3.2 水平拆分3.2.1 水平分库水平分库是指，将表的数据量切分到不同的数据库服务器上，每个服务器具有相同的库和表，只是表中的数据集合不一样。它可以有效的缓解单机单库的性能瓶颈和压力。 用户库的水平拆分架构如下： ​​ 3.2.2 水平分表如果一个表的数据量太大，可以按照某种规则（如hash取模、range​），把数据切分到多张表去。 一张订单表，按时间range​拆分如下： ​​ 3.3. 水平分库分表策略分库分表策略一般有几种，使用与不同的场景： range范围 hash取模 range+hash取模混合 3.3.1 range范围range，即范围策略划分表。比如我们可以将表的主键，按照从0~1000万​的划分为一个表，1000~2000万​划分到另外一个表，以此类推。如下图： ​​ 当然，有时候我们也可以按​时间范围来划分，如不同年月的订单放到不同的表，它也是一种range的划分策略。 这种方案的优点： 这种方案有利于扩容，不需要数据迁移。假设数据量增加到5千万，我们只需要水平增加一张表就好啦，之前0~4000万​的数据，不需要迁移。 缺点： 这种方案会有热点问题，因为订单id是一直在增大的，也就是说最近一段时间都是汇聚在一张表里面的。比如最近一个月的订单都在1000万~2000​万之间，平时用户一般都查最近一个月的订单比较多，请求都打到order_1​表啦，这就导致表的数据热点问题。 3.3.2 hash取模hash取模策略：指定的路由key（一般是user_id、订单id作为key）对分表总数进行取模，把数据分散到各个表中。 比如原始订单表信息，我们把它分成4张分表： ​​ 比如id=1，对4取模，就会得到1，就把它放到第1张表，即t_order_0​; id=3，对4取模，就会得到3，就把它放到第3张表，即t_order_2​; 这种方案的优点： hash取模的方式，不会存在明显的热点集中问题。 缺点： 如果一开始按照hash取模分成4个表了，未来某个时候，表数据量又到瓶颈了，需要扩容，这就比较棘手了。比如你从4张表，又扩容成8​张表，那之前id=5​的数据是在（5%4=1​，即第一张表），现在应该放到（5%8=5​，即第5​张表），也就是说历史数据要做迁移了。 3.3.3 range+hash取模混合既然range存在热点数据问题，hash取模扩容迁移数据比较困难，我们可以综合两种方案一起嘛，取之之长，弃之之短。 比较简单的做法就是，在拆分库的时候，我们可以先用range范围方案，比如订单id在04000万的区间，划分为订单库1，id在4000万8000万的数据，划分到订单库2,将来要扩容时，id在8000万~1.2亿的数据，划分到订单库3。然后订单库内，再用hash取模的策略，把不同订单划分到不同的表。 ​​ 4. 什么时候考虑分库分表？前提：能不能切分就不要分，分了会极大的导致系统的复杂性。避免”过度设计”和”过早优化”。 在分库分表之前，不要为分而分，先尽力去做力所能及的事情，例如：升级硬件、升级网络、读写分离、索引优化等等。当数据量达到单表的瓶颈时候，再考虑分库分表。 4.1 什么时候分表？ 如果你的系统处于快速发展时期，如果每天的订单流水都新增几十万，并且，订单表的查询效率明变慢时，就需要规划分库分表了。一般B+树索引高度是2~3层最佳，如果数据量千万级别，可能高度就变4层了，数据量就会明显变慢了。不过业界流传，一般500万数据就要考虑分表了，属于提前考虑，留好空间。 4.2 什么时候分库 这一点我的理解是看业务量，微服务架构下，微服务特别多，或者很多重要的业务要维护高并发高可用的要求，就要分库，比如说重点的业务单体抽取出来单独分库。 业务发展很快，还是多个服务共享一个单体数据库，数据库成为了性能瓶颈，就需要考虑分库了。比如订单、用户等，都可以抽取出来，新搞个应用（其实就是微服务思想），并且拆分数据库（订单库、用户库）。 综合来讲，考虑分库分表的无非以下方面： ① 数据量快速增长，当业务中数据量急速增长时 ② 维护困难时：比如，备份时较为困难，单表太大，备份时需要大量的磁盘IO和网络IO；对一个很大的表进行DDL修改时，MySQL会锁住全表，这个时间会很长，这段时间业务不能访问此表，影响很大。如果使用pt-online-schema-change，使用过程中会创建触发器和影子表，也需要很长的时间。在此操作过程中，都算为风险时间。将数据表拆分，总量减少，有助于降低这个风险；经常访问与更新，就更有可能出现锁等待，将数据切分，用空间换时间，变相降低访问压力。 ③ 业务需求：需要对某些字段垂直拆分，本质上还是因用户增多导致的业务特点发生了变化 举个例子，假如项目一开始设计的用户表如下： 12345id bigint #用户的IDname varchar #用户的名字last_login_time datetime #最近登录时间personal_info text #私人信息..... #其他信息字段 在项目初始阶段，这种设计是满足简单的业务需求的，也方便快速迭代开发。而当业务快速发展时，用户量从10w激增到10亿，用户非常的活跃，每次登录会更新 last_login_name 字段，使得 user 表被不断update，压力很大。 而其他字段：id, name, personal_info 是不变的或很少更新的，此时在业务角度，就要将 last_login_time 拆分出去，新建一个 user_time 表。 personal_info 属性是更新和查询频率较低的，并且text字段占据了太多的空间。这时候，就要对此垂直拆分出 user_ext 表了 ④ 安全性角度：鸡蛋不要放在一个篮子里。在业务层面上垂直切分，将不相关的业务的数据库分隔，因为每个业务的数据量、访问量都不同，不能因为一个业务把数据库搞挂而牵连到其他业务。利用水平切分，当一个数据库出现问题时，不会影响到100%的用户，每个库只承担业务的一部分数据，这样整体的可用性就能提高。 5. 分库分表会导致哪些问题分库分表之后，也会存在一些问题： 事务问题 跨库关联 排序问题 分页问题 分布式ID 数据迁移、扩容问题 5.1 事务问题 分库分表后，假设两个表在不同的数据库，那么本地事务已经无效啦，需要使用分布式事务了。 5.2 跨库关联 跨节点Join的问题：解决这一问题可以分两次查询实现； 冗余处理，反规范化设计： 增加冗余列(复制某一列的数据) 这一点是真的好用 增加派生列(计算总和，平均值..) 表合并(把部分来自不同表的常用列合并成新表) 表分割(把数据拆分为常用和不常用，行拆分是比如订单信息，列拆分比如账户信息&lt;额外的住址之类的并不常用，减少查询压力&gt;) 题中要求是商品信息冗余，所以应该采用&lt;增加冗余列&gt;的方法 5.3 排序问题 跨节点的count,order by,group by以及聚合函数等问题：可以分别在各个节点上得到结果后在应用程序端进行合并。 5.4 分页问题 方案1：在个节点查到对应结果后，在代码端汇聚再分页。 方案2：把分页交给前端，前端传来pageSize和pageNo，在各个数据库节点都执行分页，然后汇聚总数量前端。这样缺点就是会造成空查，如果分页需要排序，也不好搞。 5.5 分布式ID 据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID，或者使用雪花算法生成分布式ID。 UUID: UUID标准形式包含32个16进制数字，分为5段，形式为8-4-4-4-12的32个字符，例如：550e8400-e29b-41d4-a716-446655440000 UUID是主键是最简单的方案，本地生成，性能高，没有网络耗时。但缺点也很明显，由于UUID非常长，会占用大量的存储空间；另外，作为主键建立索引和基于索引进行查询时都会存在性能问题，在InnoDB下，UUID的无序性会引起数据位置频繁变动，导致分页。 雪花算法： Twitter的snowflake算法解决了分布式系统生成全局ID的需求，生成64位的Long型数字，组成部分： 第一位未使用 接下来41位是毫秒级时间戳，41位的长度可以表示69年的时间 5位datacenterId，5位workerId。10位的长度最多支持部署1024个节点 最后12位是毫秒内的计数，12位的计数顺序号支持每个节点每毫秒产生4096个ID序列 ​​ 好处：毫秒数在高位，生成的ID整体上按时间趋势递增；不依赖第三方系统，稳定性和效率较高，理论上QPS约为409.6w/s（1000*2^12），并且整个分布式系统内不会产生ID碰撞；可根据自身业务灵活分配bit位。 不足：强依赖机器时钟，如果时钟回拨，则可能导致生成ID重复。 综上，结合数据库和snowflake的唯一ID方案，可以参考业界较为成熟的解法：Leaf——美团点评分布式ID生成系统，并考虑到了高可用、容灾、分布式下时钟等问题。 数据迁移、扩容问题： 当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。 此外还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过1000W）。 如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。 6. 分库分表中间件目前流行的分库分表中间件比较多： cobar Mycat Sharding-JDBC（当当） Atlas TDDL（淘宝） vitess（谷歌开发的数据库中间件） ​ ​ 参考资料：如何分库分表！ ‍","link":"/post/my-thinking-about-the-mysql-database-table-zmjl3t.html"},{"title":"Nacos相关记录","text":"Nacos相关记录 Nacos1.X与2.X有差异，目前基本使用2.X版本，也是推荐的版本 Nacos初次尝试…. ‍ ‍ 权限认证🔒开启权限认证： 注意 Nacos是一个内部微服务组件，需要在可信的内部网络中运行，不可暴露在公网环境，防止带来安全风险。 Nacos提供简单的鉴权实现，为防止业务错用的弱鉴权体系，不是防止恶意攻击的强鉴权体系。 如果运行在不可信的网络环境或者有强鉴权诉求，请参考官方简单实现做进行自定义插件开发。 修改nacos配置文件 ——这个时候再访问nacos控制台页面，则会直接报错。 因此，还需要再设置两个属性（数值可随便填） 12nacos.core.auth.server.identity.key=authKeynacos.core.auth.server.identity.value=nacosSecurty 这两个属性是auth的白名单，用于标识来自其他服务器的请求。 添加好这两个属性时页面就能正常访问了。 还需要再其他服务的配置文件中加上如下配置，这也就是服务注册的权限 （修改代码方式）注意：密码不要有特殊符号不然会报错 12spring.cloud.nacos.username=nacospring.cloud.nacos.password=nacos 🤡 此外还需要配置： NACOS_AUTH_TOKEN token 默认:SecretKey012345678901234567890123456789012345678901234567890123456789 ‍","link":"/post/nacos-configuration-and-use-zm1qbo.html"},{"title":"Reverse a String","text":"字符串反转翻转含有中文、数字、英文字母​的字符串 如：&quot;子asdf黑g白hjkl小&quot;​ 1234567891011121314151617181920212223242526272829303132package mainimport &quot;fmt&quot;/** @Title main @Description: 1.rune关键字，从golang源码中看出，它是int32的别名（-2^31 ~ 2^31-1），比起byte（-128～127），可表示更多的字符。 2.由于rune可表示的范围更大，所以能处理一切字符，当然也包括中文字符。在平时计算中文字符，可用rune。 3.因此将字符串转为rune的切片，再进行翻转，完美解决。 @Author luommy 2023-09-22 00:19:14**/func main() { src := &quot;子asdf黑g白hjkl小&quot; // int32 is the set of all signed 32-bit integers. Range: -2147483648 through 2147483647. str := reverse([]rune(src)) fmt.Printf(&quot;%v\\n&quot;, string(str))}/** @Title reverse @Description @Author luommy 2023-09-22 00:12:29 @Param s @Return []rune**/func reverse(s []rune) []rune { for i, j := 0, len(s)-1; i &lt; j; i, j = i+1, j-1 { s[i], s[j] = s[j], s[i] } return s} ‍ 运行结果： ​​","link":"/post/string-reverse-1jimhs.html"}],"tags":[{"name":"timeline","slug":"timeline","link":"/tags/timeline/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"goland技巧","slug":"goland技巧","link":"/tags/goland%E6%8A%80%E5%B7%A7/"},{"name":"领域算法","slug":"领域算法","link":"/tags/%E9%A2%86%E5%9F%9F%E7%AE%97%E6%B3%95/"},{"name":"知识体系","slug":"知识体系","link":"/tags/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"},{"name":"高并发","slug":"高并发","link":"/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"},{"name":"Myblog","slug":"Myblog","link":"/tags/Myblog/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"nacos","slug":"nacos","link":"/tags/nacos/"}],"categories":[{"name":"京东到家","slug":"京东到家","link":"/categories/%E4%BA%AC%E4%B8%9C%E5%88%B0%E5%AE%B6/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"算法加练","slug":"算法加练","link":"/categories/%E7%AE%97%E6%B3%95%E5%8A%A0%E7%BB%83/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"知识体系","slug":"知识体系","link":"/categories/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"},{"name":"并发编程","slug":"算法加练/并发编程","link":"/categories/%E7%AE%97%E6%B3%95%E5%8A%A0%E7%BB%83/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"MySQL","slug":"MySQL","link":"/categories/MySQL/"}],"pages":[]}