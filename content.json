{"posts":[{"title":"2023.9.19 DailyNote","text":"2023-09-19 星期二2023.09.19 Tue 🌞 今年已过了 262 天（第 39 周/共 53 周）,距离 2024 年还有 103 天。距离 2023-11-04 高级-架构师考试还有 46 天。🗓️Weather：🌞🌥☁️⛈🌧🌦🌈🌪🌀⚡❄️🔥🥶🌊🌫🏠Location： 中国·广东省🛌Sleep：1：00 → 7：45 希望早日调整好作息时间 ⏰Must-To-Do 第一次发表… 没有早起 🚀️进展 自律：没有进展，依旧六块腹肌，单手五十俯卧撑 英法：菜够，法语真的难学 遇见：无，又是平凡的一天 其他：参加斗地主比赛 🐣Mini-Habits 月计划与反思 每日Golang 数据结构和算法 回顾昨天 每天早起 🧠今日反省思源功能太强大… 已经玩不明白了… 日历配置这个DailyNote template 配置原理又忘记了… 算了… 毕竟只是工具而已 争取每日后续更新一篇博客 日记推送到timeline​tag下 大概一周一次 看心情决定是否发布 随机复习 距离 2024-07-01​ 还剩 285​ 天，加油，你一定行！ 随机复习是一个好习惯，可惜现在笔记内容提炼不够精简，就不放到博客上展示了….","link":"/post/20230919-tuesday-uuzu4.html"},{"title":"命运齿轮","text":"命运齿轮2023.10.14 Sat 🌞 今年已过了 287 天（第 42 周/共 53 周）,距离 2024 年还有 78 天。距离 2023-11-04 高级-架构师考试还有 21 天。🗓️Weather：🌞🌥☁️⛈🌧🌦🌈🌪🌀⚡❄️🔥🥶🌊🌫🏠Location： 中国·广东省🛌Sleep：5.30 → 12 熬了个大夜-深夜思考人生《痛苦面具》 ⏰Must-To-Do ‍ 🚀️进展 自律：周五晚拉满了，游泳0.5h、力量训练1h、骑车10KM、跑步5kM 25min、核心训练0.5h 英法：IOS 播客很好用 遇见：清华经管-混血修勾？？ 其他：努力永远不会错 🐣Mini-Habits 月计划与反思 每日Golang 数据结构和算法 回顾昨天 每天早起 🧠今日反省 我发现很多技术手段，或者思想在某种程度上都是类似的，到一定阶段必然是融汇贯通的。 很多知识会就是会，不会就是不会，如果一些问题有过自己的思考量，即使知识本身的内容记不住，但是这个逻辑关系，逻辑追溯还是很重要的 最近玩且看狼人杀，记忆力好真的很关键，逻辑梳理更是一种能力，需要培养 ✨随缘记随便写点什么吧…. 缓存的分片有用到哈希算法与一致性哈希算法，同等联想到负载均衡的一种策略，也是一致性哈希算法，瞬间有点悟，好多其实都是相通的… ‍","link":"/post/20231014-saturday-zh8hf1.html"},{"title":"","text":"2023-10-21 星期六2023.10.21 Sat 🌞 今年已过了 294 天（第 43 周/共 53 周）,距离 2024 年还有 71 天。距离 2023-11-04 高级-架构师考试还有 14 天。🗓️Weather：🌞🌥☁️⛈🌧🌦🌈🌪🌀⚡❄️🔥🥶🌊🌫🏠Location： 中国·广东省🛌Sleep：2 → 7.30 ；9.30 → 12 ⏰Must-To-Do 周末学习打卡 🚀️进展 自律：马拉松备赛 ； 俄挺和前水平有点小帅 英法：关注了几个英语博主 遇见：三只羊在沈阳开分公司了？？ 其他： 🐣Mini-Habits 月计划与反思 每日Golang 数据结构和算法 回顾昨天 每天早起 🧠今日反省 越来越信因果效应了… 信息差也是一种能力… 早睡早起肯定算一种优点，但真的好难 快速建立知识体系 ✨随缘记随便写点什么吧…. 如果不知道布隆过滤器，那几乎不可能知道布谷鸟过滤器… 如果知道缓存穿透，那几乎必知道布隆过滤器… 百因必有果… 三缓存问题很常见，不必多说： ​​​​ 今天看过一个系统架构分析的实例： 系统使用过程中，由于同样的数据分别存在于数据库和缓存系统中，必然会造成数据同步或数据不一致性的问题。 法一：应用程序读数据时，首先读缓存，当该数据不在缓存时,再读取数据库；应用程序写数据吋，先写缓存，成功后再写数据库；或者先写数据库，再写缓存。 法二： 读数据操作的基本步骤：1.根据key读缓存；2.读取成功则直接返回；3.若key不在缓存中时，根据key (从数据库中读取数据) ；4.读取成功后， (更新缓存中key值) ；5.成功返回。写数据操作的基本步骤：1.根据key值写 (数据库) ；2.成功后 (更新缓存(key值)) ；3.成功返回。 ‍ ‍","link":"/post/20231021-saturday-z1vmbxc.html"},{"title":"2023.8.30","text":"2023.8.30从今天起，要狠狠滴加练，潶櫹潶櫹！！！ ‍","link":"/post/2023830-zy8cbl.html"},{"title":"几个后端的问题","text":"6.14 以下几个简单但并不简单的问题验证下自己的后端能力水平 业务Rpc服务如何理解 什么场景下应用RPC 是远程调用协议，服务之间只需要维持一个通信协议即可，不需要对编程语言有任何限制，也不用关系底层网络协议。多数是用在微服务、分布式场景下。 分布式下rpc如何调用可以通过注册中心+服务发现的方式实现调用，市面上很多组件比如consul、etcd等等都可以实现。 负载均衡策略有哪些 你们公司用的是哪种包括轮询、随机、加权、一致性哈希及最小连接数等。我们用的是轮询方式。 这个最好是有自己实现过的代码。 手写负载均衡、手写缓存中间件…后续再补充 Rpc协议和HTTP协议如何理解，有什么区别 RPC协议是远程调用协议，HTTP是超文本传输协议； RPC多用在微服务分布式和内部调用，HTTP多用在外部api服务； RPC的调用速度快于HTTP，但HTTP的实现要比RPC简单很多。 RPC有什么优势 为什么有这种优势RPC 不要考虑编程语言，服务只需要维持一个通信协议即可；调用速度非常的快；封装了很多方法，比如负载均衡等；适用于分布式微服务场景，内部扩展型较好。 为什么有这种优势不会答，我估计是要深入到socket层面 月百万级数据以上，总共一亿数据如何管理 优化思路如果是这种场景可以根据时间来划分，按月水平分表，这种思路，可以及时清理掉冷数据，如果在业务评估阶段就估计月表的数据量是百万级，且又可能在业务高峰期上升到千万或者亿界别的数据，那么可以考虑多一个月的数据再次分片，按照大小拆分，建议500w数据量拆分一个，虽然单表的数据量在2000w的时候，MySQL也能维持较好的层数，但是考虑到性能等问题，参考阿里巴巴数据库的设计思路，他们在海量数据的业务场景下经验丰富，比较推荐500w拆分一张 另外一种思路是根据用户id来进行hash分片拆分，多个MySQL部署，举个例子通过userid来计算哈希函数，然后和哈希掩码取模，可以快速定位到用户的数据存储在哪一个实例中，比较推荐使用MyCat这种业内比较成熟的数据库分片组件。 按月分表情况下(几十张表），这种情况下如何查某个用户的所有的订单可以加一层设计，比如用Redis的Hash结构，用户的userid作为key，list作为field，value是所有的订单信息的月份、id等，可以快速定位表位置、索引的信息。 12345678910111213141516{ &quot;user_id_1&quot;: { &quot;order_info&quot;: { &quot;2022-01&quot;: [&quot;order_1&quot;, &quot;order_2&quot;], &quot;2022-02&quot;: [&quot;order_3&quot;], &quot;2022-03&quot;: [&quot;order_4&quot;, &quot;order_5&quot;] } }, &quot;user_id_2&quot;: { &quot;order_info&quot;: { &quot;2022-01&quot;: [&quot;order_6&quot;, &quot;order_7&quot;], &quot;2022-02&quot;: [&quot;order_8&quot;], &quot;2022-03&quot;: [&quot;order_9&quot;, &quot;order_10&quot;] } }} 在这个示例中，每个 userid 都是 Hash 表的 key，而对应的 value 是一个包含了 order_info​ 这个 field。order_info​ 是一个内部的 Hash 结构，它使用年月（例如 “2022-01”）作为 field，而对应的值是一个列表，包含该用户在该月份下的所有订单编号。 通过这种设计，你可以快速定位到指定用户的订单信息，并按照不同月份进行索引。例如： 获取某个用户的所有订单：使用 HGETALL user_id_x 命令获取该用户的完整信息，然后再读取其中的 order_info​ 字段即可得到该用户在不同月份下的订单列表。 获取某个用户指定月份的订单信息：使用 HGET user_id_x order_info:YYYY-MM 命令获取对应月份的订单列表。 需要注意的是，为了保证不同月份的订单信息不会相互冲突，每个月份的 field 最好采用类似 “YYYY-MM” 的格式进行命名。 这种结构可以帮助你更好地组织和索引订单信息，同时也提供了快速定位、查询和统计的能力。 可以实现以下快速定位和索引的优势： 快速访问指定用户的订单信息：通过用户的 userid 作为 key，直接从 Redis 中获取对应的 Hash 结构，从而快速获取该用户的订单信息。 快速定位到指定年月的订单列表：在用户的订单信息中，使用年月作为 field，可以直接访问指定年月的订单列表，而无需遍历整个订单信息。 高效添加和删除订单信息：使用 Redis 的 List 结构存储订单列表，可通过头尾插入和删除操作，快速添加和删除订单，而不会影响其他年月的订单列表。 订单状态怎么查（已支付，待支付，待发货这种）设定字段订单状态status，通过上述的redis方案快速在数据库中查询，这里正好使用了Redis，可以设定缓存，但这就涉及到数据库和缓存更新的一致性问题了，写操作先更新数据库再删除缓存，读如果命中则直接返回，没命中则读取后写入缓存的方案可以避免。 如果用热点数据如何定义热点数据可以用 Redis 的 Zset 来给数据进行评分，这里的热点可以以时间、点击量、购买数等等因素综合考量。 订单状态转换如何更新？如何保持同步这个在上面已经说明了，写是先更新数据库再删除缓存，读是命中则返回，没命中则读取后写入缓存保持同步。这里同样需要保证了两步操作同时执行成功，可以用两种方案来保证，一种是重试机制，将操作发送到消息队列中，执行成功则在消息队列中删除该信息，如果失败则重新读取这条消息，超过一定次数则向上游返回报错，第二种方案是订阅MySQL的binlog日志，由于MySQL执行完之后会将操作记录在binlog里，所以可以使用binlog来找到具体的操作，这里推荐使用阿里巴巴的canal组件，他的思想就是模拟了mysql主从的交互协议实现这个功能。 服务器线上问题有排查过吗，怎么定位问题所在，整体链路讲讲，比如504这种问题。结合实际场景和原因进行分析有排查过，首先思路是并不是问题出现了再去排查问题，我们先要设计一套预防方案，如果是常规的报错问题，可以通过日志、链路追踪查询定位到，如果是服务崩溃等信息，可以通过监控报警，比如grafana，包括在CPU、内存负载压力过高的时候可以提前预警人工介入。 真的是线上出现了bug、崩溃、超时等问题，那么整体流程是，先通过链路追踪定位返回错误信息或者崩溃的服务是哪个，查看服务崩溃的日志的具体原因，精确到代码行，如果无法从代码的逻辑角度排查问题，我们要看CPU、内存的使用情况，通过系统监控确定是哪一个环节出问题，然后查看是否是内存泄漏、SQL慢查询、GC异常等问题。 504 是属于 http请求返回超时的问题，举一个实际场景的例子，比如我做过一个音视频合成的例子，之前我调用合成api接口的超时，然后返回给上游的调度服务错误信息，定位到是我服务返回的超时，模拟了当时的请求信息，通过链路追踪，在jager上查看了收到合成api请求的时间耗时过长，解决方案是，最开始合成方是用http的方式返回合成url，后来我们采用grpc 流式传输的方案可以实时返回，在没接收到结束信号时，不断开链接。 502 和 504 区别 502 是网络无法请求，接收到错误的响应； 504 是网络请求，但是接受响应超时； MySQL慢查询有涉及过吗？如果用了索引还是慢查询该怎么办 ？慢查询可以通过 MySQL 的慢查询日志查到，不过默认 MySQL 的慢查询日志是关闭的。 如果用了索引还是慢查询，可以使用 explain 命令来查看 sql 语句的执行计划，可以查看是否正常使用了索引，排查是否存在索引失效的可能。另外排查是否是数据库的参数，比如缓存、连接等待等问题。 数据量过大该如何优化数据量过大可以考虑分库分表了。分库就是根据实际场景将数据分散到多个库，分表是将数据拆分成多个表，防止单表过大。 如何分库分表 垂直拆分：由于前期表的设计没有抽象，所以这时候要根据关系性较强的几个字段对表进行拆分。一种思路是将长度比较大、不常用的信息，移到扩展表。 水平拆分：将一张大表拆分成数据结构相同的几个表，防止单表过大。 这里举个商城的例子来说明，我们可以拆分成订单信息库、用户信息库、商品详情库，每个库中的表的数据量过于庞大，比如超过500万行就可以考虑水平拆分，如果有几个关系性较强的字段，可以垂直拆分建立一张新表，具体根据自己的业务实际场景来进行扩展。 你常用的索引有哪些 结合业务说明 按照类型分类：B+ 数索引，哈希索引，fulltext索引； 按照存储方式分类：聚簇索引和非聚簇索引； 按照使用的列分类：联合索引和单一索引； 按照使用的字段分类：主键索引、唯一索引、前缀索引和普通索引。 常用的是联合索引和主键索引，比如通过id直接查询一条记录的完整信息，我们可以使用主键索引快速定位，再比如联合性比较强的两个字段，可以建立联合索引，比如要查询年龄为x、成绩是y的成员name，可以用（x，y，name）建立联合索引，利用覆盖索引可以减少回表。 什么是聚簇索引，什么是非聚簇索引，它们有什么区别聚簇索引具有唯一性，比如主键就是聚簇索引，如果没有主键会选择唯一且不为NULL的列作为主键索引，如果没有则会生成一个自增id作为主键索引。聚簇索引存放的信息是完整的数据记录，而非聚簇索引只存放聚簇索引信息。如果查询语句使用的是非聚簇索引，且查询的数据不是主键值，会在叶子节点找到主键值后进行回表，如果是主键值就会进行索引覆盖。 主键索引的底层存储结构 大致实现过程B+ 树。B+ 树是由 B 树改进而来的，所有的索引都存放在叶子节点，并构成有序的链表，其实是双向链表，叶子节点的值存放的是数据页，数据页里包含完整的记录，而非叶子节点只存放索引，非叶子节点会作为叶子节点中索引的最大或者最小节点，比如举个例子，根节点存放的索引是 (1、10、19)，那么第二层就可以是 (1、4、7)，(10、13、16)，(19、22、25)，而第三层如果是叶子节点，就会存放完整的索引和数据。并且支持范围查询，由于 MySQL 的 B+ 树底层节点是双向链表，所以范围查询效率很高；B+ 树的非叶子节点只存放索引，可以存放更多的记录，所以相同数据量下，B+ 树更矮胖，减少了 磁盘 IO；B+ 树有大量的冗余节点，在插入和删除时不会发生过多的树结构变化。 非主键索引、联合索引等的存储结构B+ 树。 这些索引在存储数据时有什么区别主键索引的值是完整的数据记录，其他索引存储的值是主键索引，联合索引的key是多个字段，查询的时候按照最左匹配原则。 主键索引的索引信息存在哪里叶子节点 MySQL的数据存在哪里存在磁盘中，如果是 InnoDB 引擎，则会按照三个文件存放，db.opt 存放的是数据库设置的默认字符集和字符校验规则，.frm 文件是存放表的结构信息，比如列、数据类型、索引等，.ibd 是存放数据的内容。 范围查询时主键索引是如何去做的首先通过二分查找定位到边界，然后通过双向链表，开始遍历即可。 什么是索引覆盖索引覆盖是在联合索引是，查询的内容在联合索引的key上就可以查到，避免了回表。比如联合索引（x，y），现在想通过x条件查询y的内容，就可以使用（x，y）避免再次回表。 MySQL用过什么存储引擎常见的是 Innodb、MyISAM、Memory等。现在默认是 InnoDB。 InnoDB有什么特性 存储：存放在 .frm、.ibd文件； 索引：支持聚簇索引和非聚簇索引； 事务：有undo log 和 redo log，支持事务； 故障恢复：有 redo log，支持故障恢复； 锁：支持表级锁和行级锁； 就针对和 MyISAM 的区别聊 事务有什么特性ACID，原子性、隔离性、一致性、持久性。 可重复读是如何做的，如何实现的通过 MVCC 实现的。 MySQL在事务启动后会为事务生成一个 Read View 快照，Read View 会记录当前事务的id、活跃的事务id列表、活跃事务id的最小值、下一个创建的事务id值，MySQL的行数据也会记录最新修改过这一行的事务id，同样会记录该行的上一版本记录的指针，像一个链表一样。当事务A启动后，事务B启动，事务B的活跃事务id列表就是A和B的事务id，现在事务要对一个行数据进行操作，如果活跃事务id列表的最小值比当前行数据记录的最新修改过这一行的事务id值大，说明最新操作该行数据记录的事务已经提交完成，所以可以对该行进行操作，如果大于下一个创建的事务id值，说明这个最新操作该行数据记录的事务是在当前事务A和B启动之后再启动的事务，那么就不可以对这行数据进行操作。之后要分两种情况讨论，如果在活跃的事务id列表之间，说明有其他事务在操作该行，那么不可以对该行操作，会去找该行记录的上一版本指针，如果不在则说明最新操作该行数据记录的事务已经提交，那么可以对该行进行操作，操作了之后，该行记录会更新最新修改这一样的事务id，同样以链表形式将上一版本记录连接起来。 MVCC 是如何做的上面那一段 如果commit 时，数据版本和快照版本不一致该怎么办回滚 如果加锁的话加的什么锁没懂要问啥，如果是问的可重复读里面的幻读问题，那就是间隙锁，如果带有记录的话是 nextkey lock（间隙锁+记录锁），举个例子： 事务A，执行了 for update 语句 当前读，查询大于等于 5 的记录，这时候事务 B，插入了一条 10 的记录，这样事务 A 如果再次查询的话，前后两次查询就会幻读，所以这时候会引入一个 next key lock，锁住 [5, +∞]的记录，（如果是大于 5 那就是间隙锁）。 Redis常用数据类型String、List、Hash、Set、Sort Set。 可以加上 Hyperloglog、Stream、Bitmap、Geospatial index 。 大 key 问题如何解决如果是 Set 结构则可以修改为 Hash，不要一次性全查。可以将大 key 拆分成多个小 key，读取的时候批量读取拼接即可。而且尽量给大 key 设置较长的过期时间，不让其在缓存中淘汰。删除可以用分批次删除或者异步删除的做法，避免阻塞主线程。 用的 Redis 单机还是集群集群 如何存数据不清楚要问的是底层数据结构还是持久化存储，底层数据结构就将五种基本类型的底层数据结构，持久化就是说 RDB 和 AOF 举个例子，String，如果存储 int 整形，可以用 long 表示，则用 int 来存储，如果是字符串，则小于等于 44 字节用 embstr 存储，其他情况是 raw。 RDB 和 AOF， 就是一个快照，一个追加日志，可能要问一些详细的过程了，还有刷盘策略等等。看具体想问什么。 讲讲主从复制由于 Redis 具有持久化能力（RDB 和 AOF），为了避免单点故障，可以引入主从模式，主机可以进行读写操作，每次的写操作都会同步数据给从机。主从模式主要是为了减轻主机压力以及容灾恢复。接下来大致介绍一下主从复制的流程： 建立好集群及主从关系后，从机会连接主机，发送 SYNC 命令，主机接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令，之后会向所有从机发送 RDB ，并在发送期间继续记录被执行的写命令，从机接收到后会载入执行，之后的每一个主机的写命令都会发送到从机执行，如果有断线重连会才用增量复制，补全缓冲区中的命令。 主服务器挂了怎么办哨兵模式会进行监控、选主、通知。首先是如何判断主服务器真的挂了，这里分为主观下线和客观下线，如果哨兵节点接受不到主服务器的信号就会认定为其主观下线，但是哨兵也是集群大的方式部署的，如果超过一半节点认为是主观下线就认定其客观下线。之后哨兵leader会从从机中选取一个新的主节点，进行主从故障转移，让原主下的所有从机都作为新的主机的从机，并且通过发布订阅通知客户端，另外会监控原主机的情况，如果原主机重新上线，那么会作为新主的从。 这里可能还会涉及到哨兵leader、选主策略、主从数据不一致的问题。 主服务器选举是怎么做的首先会找优先级最高的从节点，其次找复制进度最靠前的节点，最后通过id排序。 联想分布式算法原理…… ‍ ‍","link":"/post/614-1z6cwp.html"},{"title":"训练历程","text":"我的数据结构和算法知识体系我的算法体系由hello+代码随想录培养…. 相互补充 K神：力扣（LeetCode）全网阅读量最高博主，发表的《图解算法数据结构》已被订阅 27 万本。 本部分目的是巩固并加强对数据结构的全面理解，大学期间也有多的这门课程，但是内容有限，很难成为体系，算是一个基础的巩固，比起直接手撕LeetCode1000题，我感觉基础巩固更重要，重点记录新的理解。 待办： labuladong Cookbook LeetCode HOT 100 ‍","link":"/post/algorithm-system-1wyqpm.html"},{"title":"多个协程打印相关问题","text":"并发编程：多个协程打印​创建三个goroutine，分别输出1 4 7, 2 5 8, 3 6 9, ...... 100， 保证顺序输出1到100​ 1234567891011121314151617181920212223242526272829303132333435363738394041/** * @Author 560463 * @Description //TODO $ 并发：创建三个goroutine，分别输出1 4 7, 2 5 8, 3 6 9, ...... 100， 保证顺序输出1到100, 2种方法 * @Date 2023/10/12 14:36 **/// 实现三个协程并发交替打印数字// 方法一：package mainimport &quot;fmt&quot;var chanDone chan intvar end intvar countA, countB, countC intfunc write(name string, count int, ch, next chan int) { for a := range ch { //fmt.Println(a) count++ fmt.Printf(&quot;协程%s 第%d次打印了%d\\n&quot;, name, count, a) if a &lt; end { next &lt;- a + 1 } else { chanDone &lt;- 0 } }}func main() { ch1, ch2, ch3 := make(chan int, 1), make(chan int, 1), make(chan int, 1) countA, countB, countC = 0, 0, 0 chanDone, end = make(chan int), 100 go write(&quot;A&quot;, countA, ch1, ch2) go write(&quot;B&quot;, countB, ch2, ch3) go write(&quot;C&quot;, countC, ch3, ch1) ch1 &lt;- 1 &lt;-chanDone} ‍ 123456789101112131415161718192021222324252627282930313233343536//方法二：package mainimport &quot;fmt&quot;var wg sync.WaitGroupfunc r(name string, count int, start int, ch1, ch2 chan int) { defer wg.Done() for i := start; i &lt;= 100; { num, ok := &lt;-ch1 if !ok { close(ch2) break } count++ fmt.Printf(&quot;协程%s 第%d次打印了: %d\\n&quot;, name, count, num) i++ ch2 &lt;- i i = i + 2 //如果这样写有个坑：这样写第一次A是打印了1 但是给B的值也是1，虽然后面进行了+3 但是本轮打印时错误的 //ch2 &lt;- i //i = i + 3 }}func main() { chA, chB, chC := make(chan int, 1), make(chan int, 1), make(chan int, 1) countA, countB, countC := 0, 0, 0 wg.Add(3) chA &lt;- 1 go r(&quot;A&quot;, countA, 1, chA, chB) go r(&quot;B&quot;, countB, 2, chB, chC) go r(&quot;C&quot;, countC, 3, chC, chA) wg.Wait()} ‍ 结果： ​​ ​​ ‍ ‍ ​三个协程分别打印100次 cat dog fish​ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( &quot;fmt&quot; &quot;sync&quot;)// 三个协程交替打印 cat dog fishvar repeatCount = 100func main() { // wg 用来防止主协程提前先退出 wg := &amp;sync.WaitGroup{} wg.Add(3) chCat := make(chan struct{}, 1) defer close(chCat) chDog := make(chan struct{}, 1) defer close(chDog) chFish := make(chan struct{}, 1) defer close(chFish) go printAnimal(chCat, chDog, &quot;cat&quot;, wg) go printAnimal(chDog, chFish, &quot;dog&quot;, wg) go printAnimal(chFish, chCat, &quot;fish&quot;, wg) chCat &lt;- struct{}{} wg.Wait()}// wg 需要传指针func printAnimal(in, out chan struct{}, s string, wg *sync.WaitGroup) { count := 0 for { &lt;-in count++ fmt.Printf(&quot;第%d次打印%s\\n&quot;, count, s) out &lt;- struct{}{} if count &gt;= repeatCount { wg.Done() return } }} ‍ ​​","link":"/post/concorded-programming-multiple-corporate-printing-zpbnes.html"},{"title":"领域算法知识体系","text":"领域算法 最近一直有一个概念在脑子中循环：程序设计 = 数据结构 + 算法 基于目前的认知我想把算法分为常规算法思想和领域算法：常规算法思想如：分治、动态规划、贪心、二分、搜索等；本篇则是领域算法。 不论哪种技术栈或者组件都和算法离不开，比如gin的路由基数树、负载均衡各种算法、分布式一致性算法、和加密相关的安全算法、分布式ID雪花算法，因此准备抽一些时间好好整理并学习下这部分的内容，这部分我称之为领域算法，形成一个完整的知识体系，不求多深入、多底层，但求个人程度上的理解,快速形成知识体系。 ‍ ​​ ‍ 重点关注：负载均衡、雪花、一致性以及一点点大数据相关的，希望形成自己的理解","link":"/post/field-algorithm-1sbsuf.html"},{"title":"Goland 快捷键、模板与一些规范","text":"Goland 快捷键、模板与一些规范题记： 快捷键的使用可以大大提高效率，良好的注释对项目后续的开发维护工作也是十分必要。本文档旨在明确项目开发过程中go代码的注释规范，并提供基于goland的注释模板设置指导。便于开发人员快速配置环境，高效、合规开展工作。 规范部分随缘整理….. 我的配置 Go文件采用goland自带的go文件和代码模板 123456789101112/** * @Description //TODO * @Author luommy * @Date ${DATE} ${TIME} **/package ${GO_PACKAGE_NAME}// 我不习惯加这个func main() {} ​​​​ ‍ 方法、结构体、接口注释采用插件实现 ‍ 自定义快捷键与注释模板​自定义快捷键：CTRL+J​ ​​ 添加新建类的注释模板路径：File -&gt; Settings -&gt; File and Code Templates ​​ 添加如下信息： 123456789package ${GO_PACKAGE_NAME}/** * @Description //TODO * @Author luommy * @Date ${DATE} ${TIME} **/func main() {} 添加方法注释模板‍ Live Templates ​ go templates 内置函数‍ 在模板变量中使用的预定义函数有很多都用不到的，感觉并不好用，没啥能用到的场景 Item Description ​lowercaseAndDash(String)​​ 将驼峰字符串转换为小写，并插入连接符作为分隔符。例如,lowercaseAndDash(MyExampleName)​​返回my-example-name​​. ​snakeCase(String)​​ 将驼峰字符串转化为蛇形字符串，例如,snakeCase(fooBar)​​返回foo_bar​​. ​spaceSeparated(String)​​ 将字符串转化为小写并插入空格作为分隔符，例如,spaceSeparated(fooBar)​​returnsfoo bar​​. ​underscoresToCamelCase(String)​​ 将蛇形字符串转化为驼峰字符串. 例如,underscoresToCamelCase(foo_bar)​​返回fooBar​​. ​underscoresToSpaces(sParameterWithSpaces)​​ 将字符串中的下划线替换为空格. 例如,underscoresToSpaces(foo_bar)​​返回foo bar​​. ​camelCase(String)​​ 将字符串转化为驼峰法. 例如,camelCase(my-text-file)​​,camelCase(my text file)​​, 和camelCase(my_text_file)​​均返回myTextFile​​. ​capitalize(String)​​ 将参数的第一个字母大写。 ​capitalizeAndUnderscore(sCamelCaseName)​​ 根据驼峰法分割参数，将各个部分转化为大写，并插入下划线。例如,capitalizeAndUnderscore(FooBar)​​返回FOO_BAR​​. ​classNameComplete()​​ 这个表达式代替了在变量位置完成类名。 ​clipboard()​​ 返回系统剪贴板的内容。 ​complete()​​ 引用代码完成。 ​completeSmart()​​ 调用变量位置的智能类型完成。 ​concat(expressions...)​​ 返回传递给函数的所有字符串作为参数的级联。 ​date(sDate)​​ 以指定的格式返回当前系统日期。如果没有参数，则以默认的系统格式返回当前日期。 ​decapitalize(sName)​​ 用相应的小写字母替换参数的第一个字母。 ​enum(sCompletionString1,sCompletionString2,...)​​ 返回在模板扩展时建议完成的逗号分隔字符串的列表。 ​escapeString(sEscapeString)​​ Escapes the string specified as the parameter. ​expectedType()​​ Returns the expected type of the expression into which the template expands. Makes sense if the template expands in the right part of an assignment, afterreturn​​, etc. ​fileName()​​ 返回当前文件（包括扩展名） ​fileNameWithoutExtension()​​ 返回当前文件（不包括扩展名） ​firstWord(sFirstWord)​​ 返回作为参数传递的字符串的第一个单词。 ​lineNumber()​​ 返回当前行数。 ​substringBefore(String,Delimiter)​​ 删除指定分隔符之后的扩展名，只返回文件名。这对测试文件名是有帮助的，例如,substringBefore($FileName$,&quot;.&quot;)​​returnscomponent-test​​incomponent-test.js​​). ​time(sSystemTime)​​ 以指定的格式返回当前系统时间。 ​timestamp()​​ 返回当前系统时间戳 ​user()​​ 返回当前用户 ‍ ‍ 中英互译插件目前觉得挺好用的 支持自定义快捷键：setting-keymap-plugins 习惯设置Alt+T 一键互译 ​​ 注释插件：Goanno插件市场安装，通过tools进行配置——Goanno Setting ​​​​ 方法、接口、结构体注释模板配置​​ 配置内容如下： 123456789101112131415161718192021222324Normal Method 配置内容：/** @Title ${function_name} @Description ${todo} @Author luommy ${date} @Param ${params} @Return ${return_types} **/interface配置内容// ${interface_name} Interface Method 配置内容// @Title ${function_name} // @Description ${todo} // @Author luommy ${date} // @Param ${params} // @Return ${return_types} Struct配置内容// ${struct_name} Struct Field 不做配置 配置完成点击submit 验证注释 在方法、结构体、接口上 win使用快捷键: ctrl +alt +/​ mac使用快捷键:control + commond + /​ 可自动生成注释 如下截图: ​ AI 插件 CodeGeeX官网 几个重点的功能： 多语言代码之间翻译，无缝转换 注释生成代码/自动补全代码 AI问答","link":"/post/goland-shortcut-key-template-and-some-specifications-z2131hx.html"},{"title":"","text":"Golang 📄 Go典型使用·实例 📑 重学系列 📄 Go经验小记 📄 练习两年半释疑 📄 Go新版本特性 📄 最常用的 Go CLI 命令 📄 重学Go语言 | 如何在Go中使用Context 📑 Go并发编程 📄 Go语言实现的可读性更高的并发神库 🥗 Golang门面担当 📄 GMP模型的知识体系 📄 Go 语言五大日志库 📄 Go语言——延迟函数defer的使用 📄 Go语言——Map的底层介绍及扩缩容机制 📄 Go语言——切片(Slice)的坑 📄 Go语言——内存管理 📑 专项 📄 Gorm框架的思考 📄 Go与操作系统的线程（进程）间通信 📄 Go单机锁与同步原语 📄 深入解析go channel各状态下的操作结果 📄 解密Go协程的栈内存管理 📄 Golang实现延迟队列（DelayQueue） 📄 go channel的应用案例 📑 Gin深入理解 📄 Gin框架流程原理以及上下文、内存的思考 📄 我给 gin 提交了一行代码 - 墨天轮 📄 由Gin路由原理引发的一系列思考 📄 Gin路由设计及源码分析：httprouter路由实现原理 📄 Gin生命周期 📑 Google书签整理 📄 Go Modules 依赖管理，这篇总结的挺全 📄 最全Go select底层原理，一文学透高频用法 📄 剑指 Offer 38. 字符串的排列 📄 阅读破10万的学Go建议，不管初学还是进阶Go都值得一看！ 📍 日常小结 📄 【Golang】来几道题以加强切片知识 📄 goland-IDEOlog 插件 📄 Rob Pike谈Google Go 📄 Go的数组与切片傻傻分不清楚 📄 Go获取IP地址 📄 json字段控制 📄 Go 语言 iota 的神奇力量 📄 日志框架 📄 Go语言的%d,%p,%v等占位符的使用 📄 Go Web开发的五大利器 📄 Go中常见的IO模式 📄 Go常见错误第16篇：any的常见错误和最佳实践 - 掘金 📄 GORM框架 📄 标准库-time包 📄 高阶函数编程Go语言中的函数一等公民 📄 【Golang】怎样优雅的清空切片 📄 Go web项目布局 📄 死锁、活锁、饥饿、自旋锁（Go 语言描述） 📄 2023.3.8小结 📄 《100 Go Mistakes and How to Avoid Them》 📑 进阶篇 📄 Context包源码解读 📄 nethttp库源码解读 📄 Golang 单机锁实现原理 📄 进阶篇之函数篇 📄 优秀后端都应该具备的开发好习惯 📄 进阶篇之结构体篇 📄 Go Channel底层原理 📄 go语言反射的使用 📄 time包 📄 json字段控制 📄 深入浅出Go调度器中的GMP模型 📄 有无缓冲管道 📄 一文让你理解go语言的Context 📄 GO语言实现设计模式【上】 📄 GO语言实现设计模式【下】 📑 框架 📑 Go-zero 📄 玩转 Go 链路追踪 📄 go-zero 是如何追踪你的请求链路 📄 GoFrame学习之路 📑 RPC与GRPC 📄 RPC 📄 grpcurl的使用 📄 grpcui安装使用 ‍","link":"/post/golang-2sensm.html"},{"title":"高并发设计思考体系","text":"高并发设计思考体系 读了苏三的博客，进一步对高并发设计整体的思考多了许多 。 在原文章上加入一些自己了理解和新的认识。 “ 高并发不会是区别大厂、小厂工程师的标准，却是 检验技术实力的一道关。” 如何设计一个​高并发系统 ？ 瞬间联想秒杀系统？50W QPS？数据库、缓存、消息队列、分布式服务如何演进的？ 这个问题真的可以无限无限难，这个问题也是激发我学习的动力，后续会花一部分时间专研这部分，本文章目的是扩展下高并发设计的解决思路，即总纲。 对于高并发的设计理念有了比较系统的理解与认识，尤其是对于某些架构方面的认识，越来越觉得高并发、微服务、分布式这些获取比较庞大知识体系其实是相互共存的，懂了一方面理解另一方面也会更加容器，也更容易形成知识体系。 本部分与 Go并发编程 直接联系，当然了并发编程不一定局限于某种语言，思想和实践方式都有比较类似之处。 ‍ 关联文章： 并发编程的业务场景 参考文章： 苏三博客 并发设计解决宏图​​ 从前端——后端——运维 每一个步骤和环节都有着处理的方式，眼界瞬间就提升了，不是因为你是后端，局限于后端的部分，或者是前端。 解决思路1 页面静态化对于高并发系统的页面功能，我们必须要做静态化​设计。 如果并发访问系统的用户非常多，每次用户访问页面的时候，都通过服务器动态渲染，会导致服务端承受过大的压力，而导致页面无法正常加载的情况发生。 使用Freemarker​或Velocity​模板引擎，实现页面静态化功能。 以商城官网首页为例，我们可以在Job​中，每隔一段时间，查询出所有需要在首页展示的数据，汇总到一起，使用模板引擎生成到html文件当中。 然后将该html​文件，通过shell​脚本，自动同步到前端页面相关的服务器上。 有一说一这部分是 前端 的部分工作，并不了解，问了几个前端的朋友也没有了解过的，可能大厂的前端才可能用? 不得而知。 2 CDN加速虽说页面静态化可以提升网站网页的访问速度，但还不够，因为用户分布在全国各地，有些人在北京，有些人在成都，有些人在深圳，地域相差很远，他们访问网站的网速各不相同。 如何才能让用户最快访问到活动页面呢？ 这就需要使用CDN，它的全称是Content Delivery Network，即内容分发网络。 ​ 使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。 CDN加速的基本原理是：将网站的静态内容（如图片、CSS、JavaScript文件等）复制并存储到分布在全球各地的服务器节点上。 ——当用户请求访问网站时，CDN系统会根据用户的地理位置，自动将内容分发给离用户最近的服务器，从而实现快速访问。 国内常见的CDN提供商有阿里云CDN、腾讯云CDN、百度云加速等，它们提供了全球分布的节点服务器，为全球范围内的网站加速服务。 这个东西在大学期间就有所耳闻，其实也很好理解。 3 缓存在高并发的系统中，缓存​可以说是必不可少的技术之一。 目前缓存有两种： 基于应用服务器的内存缓存，也就是我们说的二级缓存。 使用缓存中间件，比如：Redis、Memcached等，这种是分布式缓存。 这两种缓存各有优缺点。 二级缓存的性能更好，但因为是基于应用服务器内存的缓存，如果系统部署到了多个服务器节点，可能会存在数据不一致的情况。 而Redis或Memcached虽说性能上比不上二级缓存，但它们是分布式缓存，避免多个服务器节点数据不一致的问题。 缓存的用法一般是这样的：使用缓存之后，可以减轻访问数据库的压力，显著的提升系统的性能。 有些业务场景，甚至会分布式缓存和二级缓存一起使用。 比如获取商品分类数据，流程如下：​ 不过引入缓存，虽说给我们的系统性能带来了提升，但同时也给我们带来了一些新的问题，比如：《数据库和缓存双向数据库一致性问题》、《缓存穿透、击穿和雪崩问题》等。要结合实际业务场景，切记不要为了缓存而缓存。 4 异步有时候，我们在高并发系统当中，某些接口的业务逻辑，没必要都同步执行。 比如有个用户请求接口中，需要做业务操作，发站内通知，和记录操作日志。为了实现起来比较方便，通常我们会将这些逻辑放在接口中同步执行，势必会对接口性能造成一定的影响。 接口内部流程图如下： 这个接口表面上看起来没有问题，但如果你仔细梳理一下业务逻辑，会发现只有业务操作才是核心逻辑，其他的功能都是非核心逻辑。 在这里有个原则就是：核心逻辑可以同步执行，同步写库。非核心逻辑，可以异步执行，异步写库。 上面这个例子中，发站内通知和用户操作日志功能，对实时性要求不高，即使晚点写库，用户无非是晚点收到站内通知，或者运营晚点看到用户操作日志，对业务影响不大，所以完全可以异步处理。 通常异步主要有两种：多线程 和 mq。 这部分内容在项目中经常能用到，比如一个OA系统在同步业务处理的时候需要把业务内容同步给邮箱让用户知晓，但这个同步的过程不是核心业务，也就是晚点通知、早点通知都是无所谓的，不影响系统的功能。 4.1 线程池使用线程池改造之后，接口逻辑如下： 发站内通知和用户操作日志功能，被提交到了两个单独的线程池中。 这样接口中重点关注的是业务操作，把其他的逻辑交给线程异步执行，这样改造之后，让接口性能瞬间提升了。 但使用线程池有个小问题就是：如果服务器重启了，或者是需要被执行的功能出现异常了，无法重试，会丢数据。 那么这个问题该怎么办呢？ =&gt;这个问题：我联想到了幂等性、MQ 、持久化等方面。比较肤浅的思路就是将需要被执行的任务持久化到磁盘或者数据库中，当任务执行失败或服务器重启之后，可以重新读取任务，并进行重试。也许后续会更新…. 4.2 mq使用mq改造之后，接口逻辑如下： 对于发站内通知和用户操作日志功能，在接口中并没真正实现，它只发送了mq消息到mq服务器。然后由mq消费者消费消息时，才真正的执行这两个功能。 这样改造之后，接口性能同样提升了，因为发送mq消息速度是很快的，我们只需关注业务操作的代码即可。 思路非常合理 5 多线程处理在高并发系统当中，用户的请求量很大。 假如我们现在用mq处理业务逻辑。 一下子有大量的用户请求，产生了大量的mq消息，保存到了mq服务器。 而mq的消费者，消费速度很慢。 =》可能会导致大量的消息积压问题。 从而严重影响数据的实时性。 我们需要对消息的消费者做优化。 最快的方式是使用多线程​消费消息，比如：改成线程池消费消息。 当然核心线程数、最大线程数、队列大小 和 线程回收时间，一定要做成配置的，后面可以根据实际情况动态调整。 这样改造之后，我们可以快速解决消息积压问题。 除此之外，在很多数据导入场景，用多线程导入数据，可以提升效率。 温馨提醒一下：使用多线程消费消息，可能会出现消息的顺序问题。如果你的业务场景中，需要保证消息的顺序，则要用其他的方式解决问题。 ‍ 这部分其实就是多线程处理业务了，不但业务开了线程池，同时的消息消费的处理也开线程池来处理 ‍ 6 分库分表有时候，高并发系统的吞吐量受限的不是别的，而是数据库。 当系统发展到一定的阶段，用户并发量大，会有大量的数据库请求，需要占用大量的数据库连接，同时会带来磁盘IO的性能瓶颈问题。 此外，随着用户数量越来越多，产生的数据也越来越多，一张表有可能存不下。由于数据量太大，sql语句查询数据时，即使走了索引也会非常耗时。 这时该怎么办呢？ 答：需要做分库分表​。 如下图所示： 图中将用户库拆分成了三个库，每个库都包含了四张用户表。 如果有用户请求过来的时候，先根据用户id路由到其中一个用户库，然后再定位到某张表。 路由的算法挺多的： 根据id取模，比如：id=7，有4张表，则7%4=3，模为3，路由到用户表3。 给id指定一个区间范围，比如：id的值是0-10万，则数据存在用户表0，id的值是10-20万，则数据存在用户表1。 一致性hash算法 分库分表主要有两个方向：垂直​和水平​。 说实话垂直方向（即业务方向）更简单。 在水平方向（即数据方向）上，分库和分表的作用，其实是有区别的，不能混为一谈。 分库：是为了解决数据库连接资源不足问题，和磁盘IO的性能瓶颈问题。 分表：是为了解决单表数据量太大，sql语句查询数据时，即使走了索引也非常耗时问题。此外还可以解决消耗cpu资源问题。 分库分表：可以解决 数据库连接资源不足、磁盘IO的性能瓶颈、检索数据耗时 和 消耗cpu资源等问题。 如果在有些业务场景中，用户并发量很大，但是需要保存的数据量很少，这时可以只分库，不分表。 如果在有些业务场景中，用户并发量不大，但是需要保存的数量很多，这时可以只分表，不分库。 如果在有些业务场景中，用户并发量大，并且需要保存的数量也很多时，可以分库分表。 关于分库分表更详细的内容，苏三里面讲的更深入《阿里二面：为什么分库分表？》 同时也关联我之前分库分表的思考：微服务下分库分表的思考 7 池化技术其实不光是高并发系统，为了性能考虑，有些低并发的系统，也在使用池化技术​，比如：数据库连接池、线程池等。 池化技术是多例设计模式​的一个体现。 我们都知道创建​和销毁​数据库连接是非常耗时耗资源的操作。 如果每次用户请求，都需要创建一个新的数据库连接，势必会影响程序的性能。 为了提升性能，我们可以创建一批数据库连接，保存到内存中的某个集合中，缓存起来。 这样的话，如果下次有需要用数据库连接的时候，就能直接从集合中获取，不用再额外创建数据库连接，这样处理将会给我们提升系统性能。当然用完之后，需要及时归还。 目前常用的数据库连接池有：Druid、C3P0、hikari和DBCP等。 8 读写分离不知道你有没有听说过二八原则​，在一个系统当中可能有80%是读数据请求，另外20%是写数据请求。 不过这个比例也不是绝对的。 我想告诉大家的是，一般的系统读数据请求会远远大于写数据请求。 如果读数据请求和写数据请求，都访问同一个数据库，可能会相互抢占数据库连接，相互影响。 我们都知道，一个数据库的数据库连接数量是有限，是非常宝贵的资源，不能因为读数据请求，影响到写数据请求吧？ 这就需要对数据库做读写分离​了。 于是，就出现了主从读写分离架构：考虑刚开始用户量还没那么大，选择的是一主一从的架构，也就是常说的一个master​，一个slave​。 所有的写数据请求，都指向主库。一旦主库写完数据之后，立马异步同步给从库。这样所有的读数据请求，就能及时从从库中获取到数据了（除非网络有延迟）。 但这里有个问题就是：如果用户量确实有些大，如果master挂了，升级slave为master，将所有读写请求都指向新master。 但此时，如果这个新master根本扛不住所有的读写请求，该怎么办？ 这就需要一主多从的架构了：上图中我列的是一主两从，如果master挂了，可以选择从库1或从库2中的一个，升级为新master。假如我们在这里升级从库1为新master，则原来的从库2就变成了新master的的slave了。 调整之后的架构图如下：这样就能解决上面的问题了。 除此之外，如果查询请求量再增大，我们还可以将架构升级为一主三从、一主四从…一主N从等。 9 索引在高并发的系统当中，用户经常需要查询数据，对数据库增加索引​，是必不可少的一个环节。 尤其是表中数据非常多时，加了索引，跟没加索引，执行同一条sql语句，查询相同的数据，耗时可能会相差N个数量级。 虽说索引能够提升SQL语句的查询速度，但索引也不是越多越好。 在insert数据时，需要给索引分配额外的资源，对insert的性能有一定的损耗。 我们要根据实际业务场景来决定创建哪些索引，索引少了，影响查询速度，索引多了，影响写入速度。 很多时候，我们需要经常对索引做优化。 可以将多个单个索引，改成一个联合索引。 删除不要索引。 使用explain关键字，查询SQL语句的执行计划，看看哪些走了索引，哪些没有走索引。 要注意索引失效的一些场景。 必要时可以使用force index来强制查询sql走某个索引。 如果你想进一步了解explain的详细用法，可以看看我的另一篇文章《explain | 索引优化的这把绝世好剑，你真的会用吗？》。 如果你想进一步了解哪些情况下索引会失效，可以看看我的另一篇文章《聊聊索引失效的10种场景，太坑了》。 这一部分涉及到了： 索引失效 索引优化 10 批处理有时候，我们需要从指定的用户集合中，查询出有哪些是在数据库中已经存在的。 实现代码可以这样写： 123456789public List&lt;User&gt; queryUser(List&lt;User&gt; searchList) { if (CollectionUtils.isEmpty(searchList)) { return Collections.emptyList(); } List&lt;User&gt; result = Lists.newArrayList(); searchList.forEach(user -&gt; result.add(userMapper.getUserById(user.getId()))); return result;} 这里如果有50个用户，则需要循环50次，去查询数据库。我们都知道，每查询一次数据库，就是一次远程调用。 如果查询50次数据库，就有50次远程调用，这是非常耗时的操作。 那么，我们如何优化呢？ 答：批处理​。 具体代码如下： 1234567public List&lt;User&gt; queryUser(List&lt;User&gt; searchList) { if (CollectionUtils.isEmpty(searchList)) { return Collections.emptyList(); } List&lt;Long&gt; ids = searchList.stream().map(User::getId).collect(Collectors.toList()); return userMapper.getUserByIds(ids);} 提供一个根据用户id集合批量查询​用户的接口，只远程调用一次，就能查询出所有的数据。 这里有个需要注意的地方是：id集合的大小要做限制，最好一次不要请求太多的数据。要根据实际情况而定，建议控制每次请求的记录条数在500以内。 12345678910111213func queryUsers(searchList []User) []User { if len(searchList) == 0 { return []User{} } var ids []int for _, user := range searchList { ids = append(ids, user.ID) } return getUserByIDList(ids)} 这种批处理的方式还是看业务应用场景比较好理解 11 集群系统部署的服务器节点，可能会down机，比如：服务器的磁盘坏了，或者操作系统出现内存不足问题。 为了保证系统的高可用，我们需要部署多个节点，构成一个集群​，防止因为部分服务器节点挂了，导致系统的整个服务不可用的情况发生。 集群有很多种： 应用服务器集群 数据库集群 中间件集群 文件服务器集群 我们以中间件Redis​为例。 在高并发系统中，用户的数据量非常庞大时，比如用户的缓存数据总共大小有40G，一个服务器节点只有16G的内存。 这样需要部署3台服务器节点。 该业务场景，使用普通的master/slave模式，或者使用哨兵模式都行不通。 40G的数据，不能只保存到一台服务器节点，需要均分到3个master服务器节点上，一个master服务器节点保存13.3G的数据。 当有用户请求过来的时候，先经过路由，根据用户的id或者ip，每次都访问指定的服务器节点。这用就构成了一个集群。 但这样有风险，为了防止其中一个master服务器节点挂掉，导致部分用户的缓存访问不了，还需要对数据做备份。 这样每一个master，都需要有一个slave，做数据备份。 如果master挂了，可以将slave升级为新的master，而不影响用户的正常使用。 本质还是结合了主从的思想，这里有个问题，一个节点就代表一个服务器吗？ 12 负载均衡如果我们的系统部署到了多台服务器节点。那么哪些用户的请求，访问节点a，哪些用户的请求，访问节点b，哪些用户的请求，访问节点c？ 我们需要某种机制，将用户的请求，转发到具体的服务器节点上。 这就需要使用负载均衡​机制了。 在linux下有Nginx​、LVS​、Haproxy​等服务可以提供负载均衡服务。 在SpringCloud微服务架构中，大部分使用的负载均衡组件就是Ribbon​、OpenFegin​或SpringCloud Loadbalancer​。 硬件方面，可以使用F5​实现负载均衡。它可以基于交换机实现负载均衡，性能更好，但是价格更贵一些。 常用的负载均衡策略有： ​轮询​：每个请求按时间顺序逐一分配到不同的服务器节点，如果服务器节点down掉，能自动剔除。 ​weight权重​：weight代表权重默认为1，权重越高，服务器节点被分配到的概率越大。weight和访问比率成正比，用于服务器节点性能不均的情况。 ​ip hash​：每个请求按访问ip的hash结果分配, 这样每个访客固定访问同一个服务器节点，它是解诀Session共享的问题的解决方案之一。 ​最少连接数​：把请求转发给连接数较少的服务器节点。轮询算法是把请求平均的转发给各个服务器节点，使它们的负载大致相同；但有些请求占用的时间很长，会导致其所在的服务器节点负载较高。这时least_conn方式就可以达到更好的负载均衡效果。 ​最短响应时间​：按服务器节点的响应时间来分配请求，响应时间短的服务器节点优先被分配。 从划分大类上还可以分为动态负载均衡、静态负载均衡；动态负载均衡考虑服务器当前状态，静态不考虑 13 限流对于高并发系统，为了保证系统的稳定性，需要对用户的请求量做限流​。 特别是秒杀系统中，如果不做任何限制，绝大部分商品可能是被机器抢到，而非正常的用户，有点不太公平。 所以，我们有必要识别这些非法请求，做一些限制。那么，我们该如何现在这些非法请求呢？ 目前有两种常用的限流方式： 基于nginx限流 基于redis限流 13.1 对同一用户限流为了防止某个用户，请求接口次数过于频繁，可以只针对该用户做限制。限制同一个用户id，比如每分钟只能请求5次接口。 13.2 对同一ip限流有时候只对某个用户限流是不够的，有些高手可以模拟多个用户请求，这种nginx就没法识别了。 这时需要加同一ip限流功能。限制同一个ip，比如每分钟只能请求5次接口。 但这种限流方式可能会有误杀的情况，比如同一个公司或网吧的出口ip是相同的，如果里面有多个正常用户同时发起请求，有些用户可能会被限制住。 13.3 对接口限流别以为限制了用户和ip就万事大吉，有些高手甚至可以使用代理，每次都请求都换一个ip。 这时可以限制请求的接口总次数。在高并发场景下，这种限制对于系统的稳定性是非常有必要的。但可能由于有些非法请求次数太多，达到了该接口的请求上限，而影响其他的正常用户访问该接口。看起来有点得不偿失。 13.4 加验证码相对于上面三种方式，加验证码的方式可能更精准一些，同样能限制用户的访问频次，但好处是不会存在误杀的情况。 ​通常情况下，用户在请求之前，需要先输入验证码。用户发起请求之后，服务端会去校验该验证码是否正确。只有正确才允许进行下一步操作，否则直接返回，并且提示验证码错误。 此外，验证码一般是一次性的，同一个验证码只允许使用一次，不允许重复使用。 普通验证码，由于生成的数字或者图案比较简单，可能会被破解。优点是生成速度比较快，缺点是有安全隐患。 还有一个验证码叫做：移动滑块​​，它生成速度比较慢，但比较安全，是目前各大互联网公司的首选。 限流应用很常见 14 服务降级前面已经说过，对于高并发系统，为了保证系统的稳定性，需要做限流。 但光做限流还不够。 我们需要合理利用服务器资源，保留核心的功能，将部分非核心的功能，我们可以选择屏蔽或者下线掉。 我们需要做服务降级​。 我们在设计高并发系统时，可以预留一些服务降级的开关。 比如在秒杀系统中，核心的功能是商品的秒杀，对于商品的评论功能，可以暂时屏蔽掉。 在服务端的分布式配置中心，比如：apollo中，可以增加一个开关，配置是否展示评论功能，默认是true。 前端页面通过服务器的接口，获取到该配置参数。 如果需要暂时屏蔽商品评论功能，可以将apollo中的参数设置成false。 此外，我们在设计高并发系统时，还可以预留一些兜底方案。 比如某个分类查询接口，要从redis中获取分类数据，返回给用户。但如果那一条redis挂了，则查询数据失败。 这时候，我们可以增加一个兜底方案。 如果从redis中获取不到数据，则从apollo中获取一份默认的分类数据。 目前使用较多的熔断降级中间件是：Hystrix​ 和 Sentinel​。 Hystrix是Netflix开源的熔断降级组件。 Sentinel是阿里中间件团队开源的一款不光具有熔断降级功能，同时还支持系统负载保护的组件。 二者的区别如下图所示： 降级确实了解的不多 15 故障转移在高并发的系统当中，同一时间有大量的用户访问系统。 如果某一个应用服务器节点处于假死状态，比如CPU使用率100%了，用户的请求没办法及时处理，导致大量用户出现请求超时的情况。 如果这种情况下，不做任何处理，可能会影响系统中部分用户的正常使用。 这时我们需要建立故障转移​机制。 当检测到经常接口超时，或者CPU打满，或者内存溢出的情况，能够自动重启那台服务器节点上的应用。 在SpringCloud微服务当中，可以使用Ribbon​做负载均衡器。 Ribbon是Spring Cloud中的一个负载均衡器组件，它可以检测服务的可用性，并根据一定规则将请求分发至不同的服务节点。在使用Ribbon时，需要注意以下几个方面： 设置请求超时时间，当请求超时时，Ribbon会自动将请求转发到其他可用的服务上。 设置服务的健康检查，Ribbon会自动检测服务的可用性，并将请求转发至可用的服务上。 此外，还需要使用Hystrix​做熔断处理。 Hystrix是SpringCloud中的一个熔断器组件，它可以自动地监测所有通过它调用的服务，并在服务出现故障时自动切换到备用服务。在使用Hystrix时，需要注意以下几个方面： 设置断路器的阈值，当故障率超过一定阈值后，断路器会自动切换到备用服务上。 设置服务的超时时间，如果服务在指定的时间内无法返回结果，断路器会自动切换到备用服务上。到其他的能够正常使用的服务器节点上。 16 异地多活有些高并发系统，为了保证系统的稳定性，不只部署在一个机房当中。 为了防止机房断电，或者某些不可逆的因素，比如：发生地震，导致机房挂了。 需要把系统部署到多个机房。 我们之前的游戏登录系统，就部署到了深圳、天津和成都，这三个机房。 这三个机房都有用户的流量，其中深圳机房占了40%，天津机房占了30%，成都机房占了30%。 如果其中的某个机房突然挂了，流量会被自动分配到另外两个机房当中，不会影响用户的正常使用。 这就需要使用异地多活​​架构了。 用户请求先经过第三方的DNS服务器解析，然后该用户请求到达路由服务器，部署在云服务器上。 路由服务器，根据一定的算法，会将该用户请求分配到具体的机房。 问题也来了：异地多活的难度是多个机房需要做数据同步，如何保证数据的一致性？ 这个好像是多数据中心的问题，是否可以参考多集群下的数据同步，缓存同步同理。比如，通常一个mysql集群有一主多从构成。用户的数据都是写入主库Master，Master将数据写入到本地二进制日志binary log中。从库Slave启动一个IO线程(I/O Thread)从主从同步binlog，写入到本地的relay log中，同时slave还会启动一个SQL Thread，读取本地的relay log，写入到本地，从而实现数据同步。 17 压测高并发系统，在上线之前，必须要做的一件事是做压力测试​。 我们先要预估一下生产环境的请求量，然后对系统做压力测试，之后评估系统需要部署多少个服务器节点。 比如预估有10000的qps，一个服务器节点最大支持1000pqs，这样我们需要部署10个服务器节点。 但假如只部署10个服务器节点，万一突增了一些新的用户请求，服务器可能会扛不住压力。 因此，部署的服务器节点，需要把预估用户请求量的多一些，比如：按3倍的用户请求量来计算。 这样我们需要部署30个服务器节点。 压力测试的结果跟环境有关，在dev环境或者test环境，只能压测一个大概的趋势。 想要更真实的数据，我们需要在pre环境，或者跟生产环境相同配置的专门的压测环境中，进行压力测试。 目前市面上做压力测试的工具有很多，比如开源的有：Jemter、LoaderRunnder、Locust等等。 收费的有：阿里自研的云压测工具PTS。 18 监控监控系统！ 为了出现系统或者SQL问题时，能够让我们及时发现，我们需要对系统做监控。 目前业界使用比较多的开源监控系统是：Prometheus​。 它提供了 监控​ 和 预警​ 的功能。 架构图如下：​ 我们可以用它监控如下信息： 接口响应时间 调用第三方服务耗时 慢查询sql耗时 cpu使用情况 内存使用情况 磁盘使用情况 数据库使用情况 等等······ 它的界面大概长这样子： 可以看到mysql当前qps，活跃线程数，连接数，缓存池的大小等信息。 如果发现数据量连接池占用太多，对接口的性能肯定会有影响。 这时可能是代码中开启了连接忘了关，或者并发量太大了导致的，需要做进一步排查和系统优化。 截图中只是它一小部分功能，如果你想了解更多功能，可以访问 Prometheus的官网 其实，高并发的系统中，还需要考虑安全问题，比如： 遇到用户不断变化ip刷接口怎办？ 遇到用户大量访问缓存中不存在的数据，导致缓存雪崩怎么办？ 如果用户发起ddos攻击怎么办？ 用户并发量突增，导致服务器扛不住了，如何动态扩容？ promethues+grafana 搭建起来确实可以监测很多方面的数据，服务器运行、数据库运行等等均可以很直观的展现，很利于微服务下的项目管控。 ‍","link":"/post/high-combined-design-thinking-system-11vul.html"},{"title":"My Blog ’s Plan","text":"My Blog ’s Plan 早在之前就有过建立自己的博客，但没有坚持下来。现重操旧业，坚持每天输出一篇Blog 整体思路，标签用来关键词联想与提示，或者自成体系的一套内容，分类为专题系列。 ‍ timeline：时间线，结合思源dailynote记录 标签：主要是一些主题性相关的，可能会很杂 例如：十大排序算法Ten-Sorts​​、杂记​​、英语​​、前沿技术​​ 分类： Golang 重学Go（偏基础重新巩固） Golang门面担当（常用的一些底层或者核心） 并发编程（并发相关） 数据结构与算法（偏入门，但是成体系） 架构设计师（面向考试与架构理解） MySQL Redis MQ ELK Docker 分布式 微服务 计算机底层（操作系统、网络、等一些综合性的理解） 🏳️‍🌈 秉持原则: ​ 拒绝无脑CV，深恶痛绝 CSDN 低劣文章，没头没尾，浪费时间 对于容易搜索的到内容有三点：一是要站在巨人的肩膀上总结和理解；二是确实很重点的部分才值得重复做；三自己的新学到内容，可能很粗浅，没有深刻领会，领会后可删除 将精力放在核心上，而不是排版、工具等无意义的点上 详情： A detailed list ‍ ‍","link":"/post/my-blog-content-planning-and-current-plan-z1tjjzq.html"},{"title":"微服务下分库分表的思考","text":"微服务下分库分表的思考 分库分表的这个名词再常见不过了，一开始的理解不够，随着对mysql理解的加深。 关于这个问题目前我的整体前置思路是：Mysql的瓶颈在哪里——InnoDB存储引擎——MySQL单表存储的瓶颈以及瓶颈推演与测试——分库分表，内容不一定绝对，但是思路是完整、有迹可循的。 关联文章：Mysql单表存储数据量瓶颈推演（2000W左右） 目录 什么是分库分表？ 为什么需要分库分表？ 如何分库分表？ 什么时候开始考虑分库分表？ 分库分表会导致哪些问题？如何解决？ 分库分表中间件？ PS: 这里有个小插曲，关于分区的问题，这一点我是在架构师考试备考（数据库）中遇到的问题，mysql为什么好像从来没有听说分区的相关内容，经查资料才了解到数据库按理说是支持分区的，所谓的是将一个表按照一定规则水平划分成多个子表，每个子表存储一部分数据。分区是针对单个表的，个人理解上是物理上可能跨磁盘、跨系统，但本质上还是一张逻辑表，主要的目的是提高查询效率和管理大型表的数据，减少索引长度和IO操作等问题。MySQL不支持分区，但是可以通过其他方式来实现分区的功能。比如，可以通过应用程序来实现分区的功能，或者使用其他数据库管理系统，比如Oracle、SQL Server等，它们都支持分区。MySQL不支持分区是由于历史原因、成本问题和性能问题所致。追根揭底还是技术栈范围扩大后，很多概念是宏观的，很难保证一致性。比如说只聊数据库，会聊关系模式、关系代数、-（前面这些都是关系数据库讲的，我只用Redis的话谈什么这些）数据库设计、聊数据库优化技术，这些东西太过宏观，像是“基础”可我本质上还是觉得完全就不是一类东西，只能算是时代的眼泪，曾经的思想参考。 1. 什么是分库分表分库：就是一个数据库分成多个数据库，部署到不同机器。单体架构下就没有分库分表，比较单一，SOA到微服务的发展中演进的 ​​ 分表：就是一个数据库表分成多个表。 ​​ 2.为什么需要分库分表呢？如果业务量剧增，数据库可能会出现性能瓶颈，这时候我们就需要考虑拆分数据库。从这几方面来看： 磁盘存储（很容易想到，这边便硬件层面的因素） 业务量剧增，MySQL单机磁盘容量会撑爆，拆成多个数据库，磁盘使用率大大降低。 并发连接支撑（这个是mysql本身的瓶颈） 我们知道数据库连接是有限的。在高并发的场景下，大量请求访问数据库，MySQL单机是扛不住的！当前非常火的微服务架构出现，就是为了应对高并发。它把订单、用户、商品等不同模块，拆分成多个应用，并且把单个数据库也拆分成多个不同功能模块的数据库（订单库、用户库、商品库），以分担读写压力。 为什么需要分表？ 数据量太大的话，SQL的查询就会变慢。如果一个查询SQL没命中索引，千百万数据量的表可能会拖垮这个数据库。 即使SQL命中了索引，如果表的数据量超过一千万的话，查询也是会明显变慢的。这是因为索引一般是B+树结构，数据千万级别的话，B+树的高度会增高，查询就变慢啦。 Mysql单表存储数据量瓶颈推演（2000W左右） MySQL的B+树的高度怎么计算的呢？ InnoDB存储引擎最小储存单元是页，一页大小就是16k。B+树叶子存的是数据，内部节点存的是键值+指针。索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而再去数据页中找到需要的数据，B+树结构图如下： ​​ 假设B+树的高度为2的话，即有一个根结点和若干个叶子结点。这棵B+树的存放总记录数为=根结点指针数*单个叶子节点记录行数。 如果一行记录的数据大小为1k，那么单个叶子节点可以存的记录数 =16k/1k =16​ 非叶子节点内存放多少指针呢？我们假设主键ID为bigint类型，长度为8字节(面试官问你int类型，一个int就是32位，4字节)，而指针大小在InnoDB源码中设置为6字节，所以就是 8+6=14 ​​字节，16k/14B =16*1024B/14B = 1170​ 因此，一棵高度为2的B+树，能存放1170 * 16=18720​条这样的数据记录。 同理一棵高度为3​的B+树，能存放1170 *1170 *16 =21902400​，大概可以存放两千万左右的记录。B+树高度一般为1-3层，如果B+到了4层，查询的时候会多查磁盘的次数，SQL就会变慢。 因此单表数据量超过千万-&gt;就需要考虑分表啦。 这个地方从两种角度分析：颗粒度不一样，层面也不一样 1.页的细节角度 16K的页内结构 ​​ ​​ 这种角度： 非叶子节点内指向其他页的数量为 x 叶子节点内能容纳的数据行数为 y B+ 数的层数为 z 页的结构，索引也也不例外，都会有 File Header (38 byte)、Page Header (56 Byte)、Infimum + Supermum（26 byte）、File Trailer（8byte）, 再加上页目录，大概 1k 左右。 我们就当做它就是 1K, 那整个页的大小是 16K, 剩下 15k 用于存数据，在索引页中主要记录的是主键与页号，主键我们假设是 Bigint (8 byte), 而页号也是固定的（4Byte）, 那么索引页中的一条数据的大小=8+4=12byte。15K=15*1024B 所以 非叶子节点内指向其他页的数量x ​=15*1024/12≈1280 行。 叶子节点和非叶子节点的结构是一样的，同理，能放数据的空间也是 15k。 但是叶子节点中存放的是真正的行数据，这个影响的因素就会多很多，比如，字段的类型，字段的数量。每行数据占用空间越大，页中所放的行数量就会越少。 这边我们暂时按一条行数据 1k 来算，那一页就能存下 15 条，Y = 15*1024/1000 ≈15。 算到这边了，是不是心里已经有谱了啊。 Total 总数据行数 根据上述的公式，Total =x^(z-1) *y，已知 x=1280，y=15： 假设 B+ 树是两层，那就是 z = 2， Total = （1280 ^1 ）*15 = 19200 假设 B+ 树是三层，那就是 z = 3， Total = （1280 ^2） *15 = 24576000 （约 2.45kw） ​​ 2.磁盘块角度（上述即是）： ​​ ‍ 3. 如何分库分表 水平即行，垂直即列，一横一竖，横即拆行，竖即拆列 3.1 垂直拆分​​ 3.1.1 垂直分库在业务发展初期，业务功能模块比较少，为了快速上线和迭代，往往采用单个数据库来保存数据。数据库架构如下： ​​ 但是随着业务蒸蒸日上，系统功能逐渐完善。这时候，可以按照系统中的不同业务进行拆分，比如拆分成用户库、订单库、积分库、商品库，把它们部署在不同的数据库服务器，这就是垂直分库。 垂直分库，将原来一个单数据库的压力分担到不同的数据库，可以很好应对高并发场景。数据库垂直拆分后的架构如下： ​​ 3.1.2 垂直分表如果一个单表包含了几十列甚至上百列，管理起来很混乱，每次都select *​的话，还占用IO资源。这时候，我们可以将一些不常用的、数据较大或者长度较长的列拆分到另外一张表。 比如一张用户表，它包含user_id、user_name、mobile_no、age、email、nickname、address、user_desc​，如果email、address、user_desc​等字段不常用，我们可以把它拆分到另外一张表，命名为用户详细信息表。这就是垂直分表： ​​ 3.2 水平拆分3.2.1 水平分库水平分库是指，将表的数据量切分到不同的数据库服务器上，每个服务器具有相同的库和表，只是表中的数据集合不一样。它可以有效的缓解单机单库的性能瓶颈和压力。 用户库的水平拆分架构如下： ​​ 3.2.2 水平分表如果一个表的数据量太大，可以按照某种规则（如hash取模、range​），把数据切分到多张表去。 一张订单表，按时间range​拆分如下： ​​ 3.3. 水平分库分表策略分库分表策略一般有几种，使用与不同的场景： range范围 hash取模 range+hash取模混合 3.3.1 range范围range，即范围策略划分表。比如我们可以将表的主键，按照从0~1000万​的划分为一个表，1000~2000万​划分到另外一个表，以此类推。如下图： ​​ 当然，有时候我们也可以按​时间范围来划分，如不同年月的订单放到不同的表，它也是一种range的划分策略。 这种方案的优点： 这种方案有利于扩容，不需要数据迁移。假设数据量增加到5千万，我们只需要水平增加一张表就好啦，之前0~4000万​的数据，不需要迁移。 缺点： 这种方案会有热点问题，因为订单id是一直在增大的，也就是说最近一段时间都是汇聚在一张表里面的。比如最近一个月的订单都在1000万~2000​万之间，平时用户一般都查最近一个月的订单比较多，请求都打到order_1​表啦，这就导致表的数据热点问题。 3.3.2 hash取模hash取模策略：指定的路由key（一般是user_id、订单id作为key）对分表总数进行取模，把数据分散到各个表中。 比如原始订单表信息，我们把它分成4张分表： ​​ 比如id=1，对4取模，就会得到1，就把它放到第1张表，即t_order_0​; id=3，对4取模，就会得到3，就把它放到第3张表，即t_order_2​; 这种方案的优点： hash取模的方式，不会存在明显的热点集中问题。 缺点： 如果一开始按照hash取模分成4个表了，未来某个时候，表数据量又到瓶颈了，需要扩容，这就比较棘手了。比如你从4张表，又扩容成8​张表，那之前id=5​的数据是在（5%4=1​，即第一张表），现在应该放到（5%8=5​，即第5​张表），也就是说历史数据要做迁移了。 3.3.3 range+hash取模混合既然range存在热点数据问题，hash取模扩容迁移数据比较困难，我们可以综合两种方案一起嘛，取之之长，弃之之短。 比较简单的做法就是，在拆分库的时候，我们可以先用range范围方案，比如订单id在04000万的区间，划分为订单库1，id在4000万8000万的数据，划分到订单库2,将来要扩容时，id在8000万~1.2亿的数据，划分到订单库3。然后订单库内，再用hash取模的策略，把不同订单划分到不同的表。 ​​ 4. 什么时候考虑分库分表？前提：能不能切分就不要分，分了会极大的导致系统的复杂性。避免”过度设计”和”过早优化”。 在分库分表之前，不要为分而分，先尽力去做力所能及的事情，例如：升级硬件、升级网络、读写分离、索引优化等等。当数据量达到单表的瓶颈时候，再考虑分库分表。 4.1 什么时候分表？ 如果你的系统处于快速发展时期，如果每天的订单流水都新增几十万，并且，订单表的查询效率明变慢时，就需要规划分库分表了。一般B+树索引高度是2~3层最佳，如果数据量千万级别，可能高度就变4层了，数据量就会明显变慢了。不过业界流传，一般500万数据就要考虑分表了，属于提前考虑，留好空间。 4.2 什么时候分库 这一点我的理解是看业务量，微服务架构下，微服务特别多，或者很多重要的业务要维护高并发高可用的要求，就要分库，比如说重点的业务单体抽取出来单独分库。 业务发展很快，还是多个服务共享一个单体数据库，数据库成为了性能瓶颈，就需要考虑分库了。比如订单、用户等，都可以抽取出来，新搞个应用（其实就是微服务思想），并且拆分数据库（订单库、用户库）。 综合来讲，考虑分库分表的无非以下方面： ① 数据量快速增长，当业务中数据量急速增长时 ② 维护困难时：比如，备份时较为困难，单表太大，备份时需要大量的磁盘IO和网络IO；对一个很大的表进行DDL修改时，MySQL会锁住全表，这个时间会很长，这段时间业务不能访问此表，影响很大。如果使用pt-online-schema-change，使用过程中会创建触发器和影子表，也需要很长的时间。在此操作过程中，都算为风险时间。将数据表拆分，总量减少，有助于降低这个风险；经常访问与更新，就更有可能出现锁等待，将数据切分，用空间换时间，变相降低访问压力。 ③ 业务需求：需要对某些字段垂直拆分，本质上还是因用户增多导致的业务特点发生了变化 举个例子，假如项目一开始设计的用户表如下： 12345id bigint #用户的IDname varchar #用户的名字last_login_time datetime #最近登录时间personal_info text #私人信息..... #其他信息字段 在项目初始阶段，这种设计是满足简单的业务需求的，也方便快速迭代开发。而当业务快速发展时，用户量从10w激增到10亿，用户非常的活跃，每次登录会更新 last_login_name 字段，使得 user 表被不断update，压力很大。 而其他字段：id, name, personal_info 是不变的或很少更新的，此时在业务角度，就要将 last_login_time 拆分出去，新建一个 user_time 表。 personal_info 属性是更新和查询频率较低的，并且text字段占据了太多的空间。这时候，就要对此垂直拆分出 user_ext 表了 ④ 安全性角度：鸡蛋不要放在一个篮子里。在业务层面上垂直切分，将不相关的业务的数据库分隔，因为每个业务的数据量、访问量都不同，不能因为一个业务把数据库搞挂而牵连到其他业务。利用水平切分，当一个数据库出现问题时，不会影响到100%的用户，每个库只承担业务的一部分数据，这样整体的可用性就能提高。 5. 分库分表会导致哪些问题分库分表之后，也会存在一些问题： 事务问题 跨库关联 排序问题 分页问题 分布式ID 数据迁移、扩容问题 5.1 事务问题 分库分表后，假设两个表在不同的数据库，那么本地事务已经无效啦，需要使用分布式事务了。 5.2 跨库关联 跨节点Join的问题：解决这一问题可以分两次查询实现； 冗余处理，反规范化设计： 增加冗余列(复制某一列的数据) 这一点是真的好用 增加派生列(计算总和，平均值..) 表合并(把部分来自不同表的常用列合并成新表) 表分割(把数据拆分为常用和不常用，行拆分是比如订单信息，列拆分比如账户信息&lt;额外的住址之类的并不常用，减少查询压力&gt;) 题中要求是商品信息冗余，所以应该采用&lt;增加冗余列&gt;的方法 5.3 排序问题 跨节点的count,order by,group by以及聚合函数等问题：可以分别在各个节点上得到结果后在应用程序端进行合并。 5.4 分页问题 方案1：在个节点查到对应结果后，在代码端汇聚再分页。 方案2：把分页交给前端，前端传来pageSize和pageNo，在各个数据库节点都执行分页，然后汇聚总数量前端。这样缺点就是会造成空查，如果分页需要排序，也不好搞。 5.5 分布式ID 据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID，或者使用雪花算法生成分布式ID。 UUID: UUID标准形式包含32个16进制数字，分为5段，形式为8-4-4-4-12的32个字符，例如：550e8400-e29b-41d4-a716-446655440000 UUID是主键是最简单的方案，本地生成，性能高，没有网络耗时。但缺点也很明显，由于UUID非常长，会占用大量的存储空间；另外，作为主键建立索引和基于索引进行查询时都会存在性能问题，在InnoDB下，UUID的无序性会引起数据位置频繁变动，导致分页。 雪花算法： Twitter的snowflake算法解决了分布式系统生成全局ID的需求，生成64位的Long型数字，组成部分： 第一位未使用 接下来41位是毫秒级时间戳，41位的长度可以表示69年的时间 5位datacenterId，5位workerId。10位的长度最多支持部署1024个节点 最后12位是毫秒内的计数，12位的计数顺序号支持每个节点每毫秒产生4096个ID序列 ​​ 好处：毫秒数在高位，生成的ID整体上按时间趋势递增；不依赖第三方系统，稳定性和效率较高，理论上QPS约为409.6w/s（1000*2^12），并且整个分布式系统内不会产生ID碰撞；可根据自身业务灵活分配bit位。 不足：强依赖机器时钟，如果时钟回拨，则可能导致生成ID重复。 综上，结合数据库和snowflake的唯一ID方案，可以参考业界较为成熟的解法：Leaf——美团点评分布式ID生成系统，并考虑到了高可用、容灾、分布式下时钟等问题。 数据迁移、扩容问题： 当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。 此外还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过1000W）。 如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。 6. 分库分表中间件目前流行的分库分表中间件比较多： cobar Mycat Sharding-JDBC（当当） Atlas TDDL（淘宝） vitess（谷歌开发的数据库中间件） ​ ​ 参考资料：如何分库分表！ ‍","link":"/post/my-thinking-about-the-mysql-database-table-zmjl3t.html"},{"title":"Nacos相关记录","text":"Nacos配置与使用 Nacos1.X与2.X有差异，目前基本使用2.X版本，也是推荐的版本 Nacos初次尝试…. ‍ ‍ 权限认证🔒开启权限认证： 注意 Nacos是一个内部微服务组件，需要在可信的内部网络中运行，不可暴露在公网环境，防止带来安全风险。 Nacos提供简单的鉴权实现，为防止业务错用的弱鉴权体系，不是防止恶意攻击的强鉴权体系。 如果运行在不可信的网络环境或者有强鉴权诉求，请参考官方简单实现做进行自定义插件开发。 修改nacos配置文件 ——这个时候再访问nacos控制台页面，则会直接报错。 因此，还需要再设置两个属性（数值可随便填） 12nacos.core.auth.server.identity.key=authKeynacos.core.auth.server.identity.value=nacosSecurty 这两个属性是auth的白名单，用于标识来自其他服务器的请求。 添加好这两个属性时页面就能正常访问了。 还需要再其他服务的配置文件中加上如下配置，这也就是服务注册的权限 （修改代码方式）注意：密码不要有特殊符号不然会报错 12spring.cloud.nacos.username=nacospring.cloud.nacos.password=nacos 🤡 此外还需要配置： NACOS_AUTH_TOKEN token 默认:SecretKey012345678901234567890123456789012345678901234567890123456789 ‍","link":"/post/nacos-configuration-and-use-zm1qbo.html"},{"title":"Reverse a String","text":"字符串反转翻转含有中文、数字、英文字母​的字符串 如：&quot;子asdf黑g白hjkl小&quot;​ 1234567891011121314151617181920212223242526272829303132package mainimport &quot;fmt&quot;/** @Title main @Description: 1.rune关键字，从golang源码中看出，它是int32的别名（-2^31 ~ 2^31-1），比起byte（-128～127），可表示更多的字符。 2.由于rune可表示的范围更大，所以能处理一切字符，当然也包括中文字符。在平时计算中文字符，可用rune。 3.因此将字符串转为rune的切片，再进行翻转，完美解决。 @Author luommy 2023-09-22 00:19:14**/func main() { src := &quot;子asdf黑g白hjkl小&quot; // int32 is the set of all signed 32-bit integers. Range: -2147483648 through 2147483647. str := reverse([]rune(src)) fmt.Printf(&quot;%v\\n&quot;, string(str))}/** @Title reverse @Description @Author luommy 2023-09-22 00:12:29 @Param s @Return []rune**/func reverse(s []rune) []rune { for i, j := 0, len(s)-1; i &lt; j; i, j = i+1, j-1 { s[i], s[j] = s[j], s[i] } return s} ‍ 运行结果： ​​","link":"/post/string-reverse-1jimhs.html"}],"tags":[{"name":"timeline","slug":"timeline","link":"/tags/timeline/"},{"name":"领域算法","slug":"领域算法","link":"/tags/%E9%A2%86%E5%9F%9F%E7%AE%97%E6%B3%95/"},{"name":"知识体系","slug":"知识体系","link":"/tags/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"},{"name":"goland技巧","slug":"goland技巧","link":"/tags/goland%E6%8A%80%E5%B7%A7/"},{"name":"高并发","slug":"高并发","link":"/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"},{"name":"Myblog","slug":"Myblog","link":"/tags/Myblog/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"Nacos","slug":"Nacos","link":"/tags/Nacos/"}],"categories":[{"name":"京东到家","slug":"京东到家","link":"/categories/%E4%BA%AC%E4%B8%9C%E5%88%B0%E5%AE%B6/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"算法加练","slug":"算法加练","link":"/categories/%E7%AE%97%E6%B3%95%E5%8A%A0%E7%BB%83/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"知识体系","slug":"知识体系","link":"/categories/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"},{"name":"并发编程","slug":"算法加练/并发编程","link":"/categories/%E7%AE%97%E6%B3%95%E5%8A%A0%E7%BB%83/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"MySQL","slug":"MySQL","link":"/categories/MySQL/"}],"pages":[]}