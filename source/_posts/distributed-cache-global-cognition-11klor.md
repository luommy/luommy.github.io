---
title: 分布式缓存全局认知
date: '2024-01-03 16:09:58'
updated: '2024-01-03 16:09:59'
excerpt: 一文系统认识缓存全局
tags:
  - 缓存
categories:
  - 分布式、微服务、架构
  - 分布式
permalink: /post/distributed-cache-global-cognition-11klor.html
comments: true
toc: true
---



---

* 缓存背景与项目需要
* 缓存的发展：本地缓存和分布式缓存
* 最常见的缓存技术与Mysql与Redis缓存同步一致性

---

> 认知之路
>
> 有些东西不接触永远不知道为什么是这样的，之前可能会觉得：我不了解Mysql日志相关内容、Mysql日志底层的相关原理并不影响我对Mysql的CRUD，日志篇的核心正是undo log 、redo log 、binlog，不深入研究他们的原理可能就永远不知道Mysql集群建设的核心部分。或者可以说你深刻理解Mysql日志篇的原理，Mysql集群就是小菜一碟，日志篇的内容我也做了一些总结和理解：Mysql-日志篇（一）

# 背景与介绍

我们的微服务项目中缓存是考虑的因素，在目前我们的分布式环境下，缓存最大的问题可能就是一致性问题，一旦没有管理好可能会造成不小的Bug，缓存对于微服务的提升是巨大的，也是当下行业主流的解决方案之一。

既然项目中使用了缓存，且在分布式的环境下，必然会涉及到分布式缓存的常见问题，及时未雨绸缪，针对全局整体建立起系统性的认知对于我们开发和维护项目有着不小的帮助，开发时会思路清晰考虑的更加全面，维护时会快速定位问题所在，快速解决问题。

<span style="font-weight: bold;" data-type="strong">*缓存，消息队列，分库分表</span>* 是高并发解决方案三剑客。

同样缓存、限流、降级我理解更加倾向于微服务治理三板斧，可见缓存在开发中具有不可取代的地位，不论你的项目如何，大概率是离不开缓存的。

其实从宏观程度下理解：缓存是一个通用化的概念，或许对于我们后端开发，好像只有Redis缓存，其实不止步于此，从架构师角度或者资深开发分析:

​![image](https://cdn.jsdelivr.net/gh/luommy/myblogimg@img/myblog/202401031610970.png)​

整个业务流程中，从前端 Web 请求，到网络传输，再到服务端和数据库服务，各个阶段都有缓存的应用，这才是完整的体系。

如果要再底层认知，可能就是：操作系统设计的多种缓存，比如 Page Cache、Buffer Cache 等技术。

缓存之所以能够让系统“更快”，本质上做到了如下两点：

* 减小 CPU 消耗

  将原来需要实时计算的内容提前算好、把一些公用的数据进行复用，这可以减少 CPU 消耗，从而提升响应性能。
* 减小 I/O 消耗

  将原来对网络、磁盘等较慢介质的读写访问变为对内存等较快介质的访问，从而提升响应性能。

其实很多涉及到操作系统层次的思考很容易就想到IO问题、CPU问题

对于<span style="font-weight: bold;" data-type="strong">应用系统</span>来讲，经常将缓存划分为<span style="font-weight: bold;" data-type="strong">本地缓存</span>和<span style="font-weight: bold;" data-type="strong">分布式缓存</span>。

<span style="font-weight: bold;" data-type="strong">本地缓存</span> ：应用中的缓存组件，缓存组件和应用在同一进程中，缓存的读写非常快，没有网络开销。但各应用或集群的各节点都需要维护自己的单独缓存，无法共享缓存。

​<span style="font-weight: bold;" data-type="strong">分布式缓存</span>​：和应用分离的缓存组件或服务，与本地应用隔离，多个应用可直接共享缓存。

我的目标是：在面对不同的业务场景时，能够做出合理的缓存选型。

# 本地缓存与分布式缓存

## 本地缓存 JDK Map

JDK Map 经常用于缓存实现：

* HashMap

  HashMap 是一种基于哈希表的集合类，它提供了快速的插入、查找和删除操作。可以将键值对作为缓存项的存储方式，将键作为缓存项的唯一标识符，值作为缓存项的内容。
* ConcurrentHashMap

  ConcurrentHashMap 是线程安全的 HashMap，它在多线程环境下可以保证高效的并发读写操作。
* LinkedHashMap

  LinkedHashMap 是一种有序的 HashMap ，它保留了元素插入的顺序，可以按照插入顺序或者访问顺序进行遍历。
* TreeMap

  TreeMap 是一种基于红黑树的有序 Map，它可以按照键的顺序进行遍历。

我看了一个例子：

艺龙红包系统，<span style="font-weight: bold;" data-type="strong">红包活动</span>就是<span style="font-weight: bold;" data-type="strong">存储在ConcurrentHashMap</span> 中 ，通过<span style="font-weight: bold;" data-type="strong">定时任务刷新缓存</span> 。

<span style="font-weight: bold;" data-type="strong">这也是单体服务最常用的一种设计思路</span>

​![图片](https://cdn.jsdelivr.net/gh/luommy/myblogimg@img/myblog/202401031610989.png)​

核心流程：

1、红包系统启动后，初始化一个 ConcurrentHashMap 作为红包活动缓存 ；

2、数据库查询所有的红包活动 , 并将活动信息存储在 Map 中 ;

3、定时任务每隔 30 秒 ，执行缓存加载方法，刷新缓存。

为什么将红包活动信息存储在本地内存 ConcurrentHashMap 呢 ？

* 红包系统是高并发应用，快速将请求结果响应给前端，大大提升用户体验；——满足高并发
* 红包活动<u><span style="font-weight: bold;" data-type="strong">*数量 </span>*</u> 并不多，就算全部放入到 Map 里也不会产生内存溢出的问题；——满足性能要求
* 定时任务刷新缓存并不会影响红包系统的业务。——满足服务合理性

很多<span style="font-weight: bold;" data-type="strong">单体应用</span>都使用这种方案，该方案的特点是简洁易用，工程实现也容易 。这个例子也很好很清晰。

## 本地缓存

虽然使用 JDK Map 能快捷构建缓存，但缓存的功能还是比较孱弱的。

因为现实场景里，我们可能需要给缓存添加​<span style="font-weight: bold;" data-type="strong">缓存统计</span>、<span style="font-weight: bold;" data-type="strong">过期失效</span>、<span style="font-weight: bold;" data-type="strong">淘汰策略</span>等功能。<span style="font-weight: bold;" data-type="strong">本地缓存框架</span>应运而生。

流行的 Java 缓存框架包括：Ehcache , Google Guava ,  Caffeine Cache

​![图片](https://cdn.jsdelivr.net/gh/luommy/myblogimg@img/myblog/202401031610737.png)​

go中常见的缓存框架应该就是[go-cache](https://github.com/patrickmn/go-cache)了​​

虽然本地缓存框架的功能很强大，但是本地缓存的缺陷依然明显。

1、高并发的场景，​<span style="font-weight: bold;" data-type="strong">应用重启之后，本地缓存就失效了，系统的负载就比较大</span>​，需要花较长的时间才能恢复；

2、每个应用节点都会维护自己的单独缓存，<span style="font-weight: bold;" data-type="strong">缓存同步比较头疼</span>。

对于后端人员而言，提缓存问题肯定大概是分布式的缓存问题，也大概率是这个位置进行优化

## 分布式缓存

<span style="font-weight: bold;" data-type="strong">分布式缓存是指将缓存数据分布在多台机器上，以提高缓存容量和并发读写能力的缓存系统。</span> 分布式缓存通常由多台机器组成一个集群，每台机器上都运行着相同的缓存服务进程，缓存数据被均匀地分布在集群中的各个节点上。

Redis 是分布式缓存的首选，甚至我们一提到缓存，很多后端工程师首先想到的就它。

下图是神州专车订单的 Redis 集群架构 。将 Redis 集群拆分成四个分片，每个分片包含一主一从，主从可以切换。应用 A 根据不同的缓存 key 访问不同的分片。

​![图片](https://cdn.jsdelivr.net/gh/luommy/myblogimg@img/myblog/202401031610422.png)​

与本地缓存相比，分布式缓存具有以下优点：

<span style="font-weight: bold;" data-type="strong">1、容量和性能可扩展</span>

通过增加集群中的机器数量，可以扩展缓存的容量和并发读写能力。同时，缓存数据对于应用来讲都是共享的。

<span style="font-weight: bold;" data-type="strong">2、高可用性</span>

由于数据被分布在多台机器上，即使其中一台机器故障，缓存服务也能继续提供服务。

<span style="font-weight: bold;" data-type="strong">分布式缓存的缺点</span>：

<span style="font-weight: bold;" data-type="strong">1、网络延迟</span>

分布式缓存通常需要通过网络通信来进行数据读写，可能会出现网络延迟等问题，相对于本地缓存而言，响应时间更长。

<span style="font-weight: bold;" data-type="strong">2、复杂性</span>

分布式缓存需要考虑序列化、数据分片、缓存大小等问题，相对于本地缓存而言更加复杂。且在分布式下很多问题可能并不是单一的问题，很有可能触发连锁反应，导致一系列的问题，这是个基础的认知。

---

> 真实的案例
>
> 分布式缓存的认知的提升：
>
> 2014年，同事开发了比分直播的系统，所有的请求都是从分布式缓存 Memcached 中获取后直接响应。常规情况下，从缓存中查询数据非常快，但在线用户稍微多一点，整个系统就会特别卡。
>
> 通过 jstat 命令发现 GC 频率极高，几次请求就将新生代占满了，而且 CPU 的消耗都在 GC 线程上。初步判断是缓存值过大导致的，果不其然，缓存大小在 300k 到 500k 左右。
>
> 解决过程还比较波折，分为两个步骤：
>
> 1. <span style="font-weight: bold;" data-type="strong">修改新生代大小</span>，从原来的 2G 修改成 4G，并精简缓存数据大小 (从平均 300k 左右降为 80k 左右)；
> 2. 把<span style="font-weight: bold;" data-type="strong">缓存拆成两个部分</span>，第一部分是<span style="font-weight: bold;" data-type="strong">全量数据</span>，第二部分是<span style="font-weight: bold;" data-type="strong">增量数据</span>（数据量很小）。页面第一次请求拉取全量数据，当比分有变化的时候，通过 websocket 推送增量数据。

经过这次优化，深刻认识到：缓存虽然可以提升整体速度，但是在高并发场景下，缓存对象大小依然是需要关注的点，稍不留神就会产生事故。另外我们也需要合理地控制读取策略，最大程度减少 GC 的频率 , 从而提升整体性能。

# 多级缓存

多级缓存是一个解决方案，主要就是提供了多层的缓存以解决问题，对于一些大型项目可能会用到

开源中国网站最开始完全是用本地缓存框架 Ehcache 。后来随着访问量的激增，出现了一个可怕的问题：“因为 Java 程序更新很频繁，每次更新的时候都要重启。一旦重启后，整个 Ehcache 缓存里的数据都被清掉。重启后若大量访问进来的话，开源中国的数据库基本上很快就会崩掉”。

于是，开源中国开发了多级缓存框架  ​<span style="font-weight: bold;" data-type="strong">J2Cache</span>​，使用了多级缓存 <span style="font-weight: bold;" data-type="strong">Ehcache + Redis</span> 。

多级缓存有如下优势：

1. 离用户越近，速度越快；
2. 减少分布式缓存查询频率，降低序列化和反序列化的 CPU 消耗；
3. 大幅度减少网络 IO 以及带宽消耗。

本地缓存做为一级缓存，分布式缓存做为二级缓存，首先从一级缓存中查询，若能查询到数据则直接返回，否则从二级缓存中查询，若二级缓存中可以查询到数据，则回填到一级缓存中，并返回数据。若二级缓存也查询不到，则从数据源中查询，将结果分别回填到一级缓存，二级缓存中。

​![图片](https://cdn.jsdelivr.net/gh/luommy/myblogimg@img/myblog/202401031610175.png)、

> 真实案例
>
> 2018年，一家电商公司需要进行 app 首页接口的性能优化。采取的是两级缓存模式，同时利用了 Guava 的惰性加载机制，整体架构如下图所示：
>
> ​![图片](https://cdn.jsdelivr.net/gh/luommy/myblogimg@img/myblog/202401031610893.png)​
>
> 缓存读取流程如下：
>
> 1、业务网关刚启动时，本地缓存没有数据，读取 Redis 缓存，如果 Redis 缓存也没数据，则通过 RPC 调用导购服务读取数据，然后再将数据写入本地缓存和 Redis 中；若 Redis 缓存不为空，则将缓存数据写入本地缓存中。
>
> 2、由于步骤1已经对本地缓存预热，后续请求直接读取本地缓存，返回给用户端。
>
> 3、Guava 配置了 refresh 机制，每隔一段时间会调用自定义 LoadingCache 线程池（5个最大线程，5个核心线程）去导购服务同步数据到本地缓存和 Redis 中。
>
> 优化后，性能表现很好，平均耗时在 5ms 左右。最开始我以为出现问题的几率很小，可是有一天晚上，突然发现 app 端首页显示的数据时而相同，时而不同。
>
> 也就是说：虽然 LoadingCache 线程一直在调用接口更新缓存信息，但是各个服务器本地缓存中的数据并非完成一致。说明了两个很重要的点：
>
> 	1、惰性加载仍然可能造成多台机器的数据不一致
>
> 	2、LoadingCache 线程池数量配置的不太合理,  导致了线程堆积
>
> 最终的解决方案是：
>
> 	1、惰性加载结合消息机制来更新缓存数据，也就是：当导购服务的配置发生变化时，通知业务网关重新拉取数据，更新缓存。
>
> 	2、适当调大 LoadigCache 的线程池参数，并在线程池埋点，监控线程池的使用情况，当线程繁忙时能发出告警，然后动态修改线程池参数。

最常用最经典的解决方案无疑是从Mysql与Redis开展，因为分布式缓存大都是通过Redis实现，Redis的强大不言而喻。

对于缓存，针对于我们的业务而言，常用的一些数据，为了避免反复查询也好、不方便查询也罢，想避免反复进行服务之间的调用就需要使用缓存来解决问题。比如最最常用的用户信息，正常不会经常改动这个东西，本质来说属于“查多写少”的性质，这种的可以理解为热点数据，这也是热点数据的基本属性，这部分数据就可以放在缓存中，由此联想单机情况下如何利用Map实现缓存，但是分布式情况下就不一样了，市面上目前几乎都是使用Redis来解决的，将“用户信息”相关数据放入Redis缓存中，以增加查询效率，这里面的就涉及到很多细节上的问题，总体来说最核心的就是一致性问题。

## 操作手法

即分布式环境下，对于你的服务业务数据如何保证一致性？

顺序大概是可以分为下面四种情况：

1. 先更新数据库，再更新缓存
2. 先更新缓存，再更新数据库
3. 先删除缓存，再更新数据库
4. 先更新数据库，再删除缓存

在参考了大量资料后我觉得还是要<span style="font-weight: bold;" data-type="strong"><u>清楚整个脉络才是最重要的</u></span>，比如我们的“用户信息”缓存采用的是删除策略还是更新策略、

然后再考虑是先更新（删除）数据库还是先更新（删除）缓存，即2X2=4

## 删除缓存与更新缓存 

删除缓存对比更新缓存

* 删除缓存: 数据只会写入数据库，不会写入缓存，只会删除缓存，也就是缓存还需要从数据库中重新读
* 更新缓存: 数据不但写入数据库，还会写入缓存

<span style="font-weight: bold;" data-type="strong">删除缓存</span>

* 优点：操作简单，无论更新操作是否复杂，直接删除，并且能防止更新出现的线程安全问题，在更新链路长的时候有优势
* 缺点：删除后，下一次查询无法在 cache 中查到，会有一次 Cache Miss，在下一次查询中需要重新读取数据库，“重新恢复为热点数据”，高并发下可能会出现上面说的缓存问题

<span style="font-weight: bold;" data-type="strong">更新缓存</span>

* 优点：命中率高，直接更新缓存，不会有 Cache Miss 的情况
* 缺点：更新缓存消耗较大，尤其在复杂的操作流程中,在复杂的涉及到缓存计算的场景下很差

那到底是选择更新缓存还是删除缓存呢，主要取决于更新缓存的复杂度

* 更新缓存的代价很小，此时我们应该更倾向于更新缓存，以保证更高的缓存命中率
* 更新缓存的代价很大，此时我们应该更倾向于删除缓存

例如：只是简单的更新一下用户登录情况，只操作一个字段，那就可以采用更新缓存，还有类似秒杀下商品库存数量这种并发下查询频繁的数据，也可以使用更新缓存，不过也要注意线程安全的问题，防止产生脏数据。但是当更新操作的逻辑较复杂时，需要涉及到其它数据，如用户购买商品付款时，需要考虑打折、优惠券、红包等多种因素，这样需要缓存与数据库进行多次交互，将打折等信息传入缓存，再与缓存中的其它值进行计算才能得到最终结果，此时更新缓存的消耗要大于直接淘汰缓存，这个时候通常会采用淘汰的方式。

最终还是要根据业务场景来进行选择，<span style="font-weight: bold;" data-type="strong">不过大部分场景下删除缓存操作简单，并且带来的副作用只是增加了一次 Cache Miss，是比较通用的处理方式。</span>

## ① 先更新数据库，再更新缓存

这种方式就适合更新缓存的代价很小的数据，例如上面说的用户情况，库存数量这类数据，同样还是要注意线程安全的问题。

<span style="font-weight: bold;" data-type="strong">线程安全角度</span>

同时有请求 A 和请求 B 进行更新操作，那么会出现

1. 线程 A 更新了数据库
2. 线程 B 更新了数据库
3. 线程 B 更新了缓存
4. 线程 A 更新了缓存

这就出现请求 A 更新缓存应该比请求 B 更新缓存早才对，但是因为网络等原因，B 却比 A 更早更新了缓存，这就导致了脏数据。

<span style="font-weight: bold;" data-type="strong">业务场景角度</span>

有如下两种不适合场景（前面已经暗示过）：

1. 如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能
2. 如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是也浪费性能的

## ② 先更新缓存，再更新数据库

这种方式是最简单不过的了，很容易理解。

但是肯定会想到，缓存更新成功了，数据库更新失败了怎么办？

更简单了：重试机制

​![image](https://cdn.jsdelivr.net/gh/luommy/myblogimg@img/myblog/202401031610584.png)​

可参考资料：

 [操作的SQL有序决定了线程安全问题](https://www.cnblogs.com/rjzheng/p/9240611.html)

 [高性能：点赞功能](https://juejin.im/post/5bdc257e6fb9a049ba410098)

## ③ 先删除缓存，再更新数据库

简单的想一下，好像这种方式不错，就算是第一步删除缓存成功，第二步写数据库失败，则只会引发一次 Cache Miss，对数据没有影响，其实仔细一想并发下也很容易导致了脏数据，例如

1. 请求 A 进行写操作，删除缓存
2. 请求 B 查询发现缓存不存在
3. 请求 B 去数据库查询得到旧值
4. 请求 B 将旧值写入缓存
5. 请求 A 将新值写入数据库

这种情况就是那么的巧了，偏偏A进程改的时候，已经删除了缓存还没来得及更新写入数据，你B正好来查了，且B执行的还挺快

## ④ 先更新数据库，再删除缓存

先说一下，国外有人提出了一个缓存更新套路，名为[ Cache-Aside Pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside)

* <span style="font-weight: bold;" data-type="strong">失效</span>：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中
* <span style="font-weight: bold;" data-type="strong">命中</span>：应用程序从 cache 中取数据，渠道后返回
* <span style="font-weight: bold;" data-type="strong">更新</span>：先把数据存到数据库中，成功后再让缓存失效

更新操作就是先更新数据库，再删除缓存；读取操作先从缓存取数据，没有，则从数据库中取数据，成功后，放到缓存中

为什么他们都用这种方式呢，这种情况不存在并发问题么? 答案是也存在，但是出现概率比第三种低，例如：

1. 请求缓存刚好失效
2. 请求A查询数据库，得一个旧值
3. 请求B将新值写入数据库
4. 请求B删除缓存
5. 请求A将查到的旧值写入缓存

这样就出现脏数据了，然而，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作删除缓存，所有的这些条件都具备的概率基本并不大，但是还是会有出现的概率。

并且假如第一步写数据库成功，第二步删除缓存失败，这样也导致脏数据，请看解决方案。

## 方案 ③ 和 ④ 脏数据的解决方案

那怎么解决呢，可以采用大名鼎鼎的<span style="font-weight: bold;" data-type="strong">延时双删策略(缓存双淘汰法)</span> ，可以将前面所造成的缓存脏数据，再次删除

1. 先删除(淘汰)缓存
2. 再写数据库（这两步和原来一样）
3. 休眠1秒，再次删除(淘汰)缓存

或者是

1. 先写数据库
2. 再删除(淘汰)缓存（这两步和原来一样）
3. 休眠1秒，再次删除(淘汰)缓存

这个1秒应该看你的业务场景，应该自行评估自己的项目的读数据业务逻辑的耗时，然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百毫秒即可，这么做确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

如果你用了 MySql 的读写分离架构怎么办？，例如：

1. 请求 A 进行写操作，删除缓存
2. 请求 A 将数据写入数据库了，(或者是先更新数据库，后删除缓存)
3. 请求 B 查询缓存发现，缓存没有值
4. 请求 B 去从库查询，这时，还没有完成主从同步，因此查询到的是旧值
5. 请求 B 将旧值写入缓存
6. 数据库完成主从同步，从库变为新值

这种情景，就是数据不一致的原因，还是采用延时双删策略(缓存双淘汰法)，只是，休眠时间修改为在主从同步的延时时间基础上，加几百毫秒

<span style="font-weight: bold;" data-type="strong">并且为了性能更快，可以把第二次删除缓存可以做成异步的，这样不会阻塞请求了，如果再严谨点，防止第二次删除缓存失败，这个异步删除缓存可以加上重试机制，失败一直重试，直到成功。</span>

这里给出两种重试机制参考

方案一

1. 更新数据库数据
2. 缓存因为种种问题删除失败
3. 将需要删除的 key 发送至消息队列
4. 自己消费消息，获得需要删除的 key
5. 继续重试删除操作，直到成功

​![image](https://cdn.jsdelivr.net/gh/luommy/myblogimg@img/myblog/202401031610285.png)​

然而，该方案有一个缺点，对业务线代码造成大量的侵入，于是有了方案二，启动一个订阅程序去订阅数据库的Binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作

方案二

1. 更新数据库数据
2. 数据库会将操作信息写入 binlog 日志当中
3. 订阅程序提取出所需要的数据以及key
4. 另起一段非业务代码，获得该信息
5. 尝试删除缓存操作，发现删除失败
6. 将这些信息发送至消息队列
7. 重新从消息队列中获得该数据，重试操作

​![image](https://cdn.jsdelivr.net/gh/luommy/myblogimg@img/myblog/202401031610232.png)​

上述的订阅 Binlog 程序在 MySql 中有现成的中间件叫 Canal，可以完成订阅 Binlog 日志的功能，另外，重试机制，这里采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。

<span style="font-weight: bold;" data-type="strong">总结：</span> 大部分应该使用的都是第三种或第四种方式，如果都是采用延时双删策略(缓存双淘汰法)，可能区别不会很大，不过第四种方式出现脏数据概率是更小点，更多的话还是要结合自身业务场景使用，灵活变通。

# 小结

通俗来讲：<span style="font-weight: bold;" data-type="strong">在技术领域中没有一种通用的解决方案可以解决所有问题</span>。缓存也是，解决了一个问题但也可能会引入新的问题。

<span style="font-weight: bold;" data-type="strong">缓存是把双刃剑</span>，一方面我们享受缓存带来的系统性能提升，另一方面引入缓存会提高系统复杂度，因为你要考虑缓存的失效、更新、一致性等问题。

‍

‍

‍
