---
title: “0-1”实现ELK日志系统
date: '2023-08-23 22:42:25'
updated: '2023-08-29 15:06:21'
tags:
  - ELK
permalink: /post/01-to-implement-the-elk-log-system-comeh.html
comments: true
toc: true
---

# “0-1”实现ELK日志系统

# 总过程方案

——**2023.8 记录**

搭建 ELK（Elasticsearch, Logstash, Kibana） 是构建一个日志分析和可视化平台的常用方案，更重要的建立起微服务建设，综合提升企业的信息化的技术栈；

过往对于我而言，或者对于我们普通的开发者而言，可能需要学会如何在日志平台看日志，如果检索日志关键信息，结合自身服务进行优化或者改bug，这一次的在创立角度考虑问题，要考虑如何搭建、搭建流程是怎样的，搭建好如何调试，调试好如何应用，应用了如何维护和管理，远远比直接用要考虑的更全面更复杂；

对此我查看了官网资料、ES开源社区，其实主要的参考资料也就这俩，官方资料可能比较全，但是读起来非常像官方说明书，不易读，而且比较分散，不够系统，但是很多资源只能从官方参考，如新版本的有关资料，网上几乎没有什么资料，ES作为迭代狂魔，每月都可能迭代一个版本，这一点是非常明显的；

下面是一个从0-1制定 ELK 开发方案的总体过程与关注点：

---

**构建步骤分解**

## 1.定位和目标

  ①信息化平台实时的分布式日志聚合平台，用于收集、存储、搜索和可视化大量日志数据，以便快速定位和解决系统问题，同时可扩展业务功能搜索；

  ②为监控系统提供指标来源；

  ③后台业务请求可视化监控，避免去服务器上捞日志，后端开发测试阶段调试工具；

## 2.硬件和软件性能需求

目前申请了两台服务器，均先用来测试，先用一台服务器进行ELK测试环境搭建，不设立集群。集群至少需要三台服务器以上才可实现。

软硬件需求方面没有过多担心，目前申请的服务器问题不大，本地win下搭建确实很耗内存和资源

 --》win/linux环境搭建

​![image](assets/image-20230726092745-202a78l.png)​

这部分最大的问题版本决策问题，不同版本之间差异可能会很大很大，单就Kibana方面就可能发生翻天覆地的变化

‍

[历代 ES 官方版本](https://www.elastic.co/guide/en/elasticsearch/reference/index.html)

## 3.确定整体架构

官方的生态：![image](assets/image-20230801192548-hntzfls.png)​

对于我们部门，主采用Logstash->ES->Kibana方式

其中测试环境下单机ES即可；可先在测试环境验证业务测试

​![ELK集群设想架构](assets/ELK集群设想架构-20230808161049-55z3sn0.png)​

其实beats->elasticsearch->kibana也是可以的

Elasticsearch 用于存储和搜索数据，Logstash 用于日志的收集和处理，Kibana 用于数据可视化和查询；

Beats是一个面向**轻量型采集器**的平台，这些采集器可以从边缘机器向Logstash、ElasticSearch发送数据，它是由Go语言进行开发的，运行效率方面比较快。从下图中可以看出，不同Beats的套件是针对不同的数据源。

​![image](assets/image-20230801192806-stabbf0.png)​

​

可以容易想到稍微复杂些的架构设计：

beats+logstath+elasticsearch+kibana

beats+MQ/Redis+logstash+elasticsearch+kibana

多数据中心方案……

## 4.数据采集和传输方式

描述如何采集日志数据并将其传输到 Elasticsearch。例如，通过 Logstash 配置输入插件来接收日志数据，使用过滤器插件对数据进行预处理，然后通过输出插件将数据发送到 Elasticsearch。

 这部分采用Go和Java操作，Go一般通过微服务日志框架集成来构建发送给ES数据，Java也是同样的思路

--》涉及demo调试中间件

--》涉及日志框架与中间件集成开发

这部分主要涉及阅读ES-go/java 的官方文档；Java通过添加依赖也可实现，道理类似，但是具体Java是否要通过日志框架通过钩子函数传输要看具体Java的框架，毕竟Java的生态会更全面

## 5.数据存储和索引

描述 Elasticsearch 的数据存储和索引设计。可能会涉及：创建合适的索引模板，确定字段映射，调整分片和副本设置等。

--》需要对接业务开发人员，对设计业务进行划分，熟知有哪些业务、服务分类

--》对已获知的业务进行数据建模

--》数据建模后，考虑字段设计以及索引创建

‍

 tip:大概确定业务归类，定义索引模式和统一基本规范，方便后台微服务格式统一

--》明确业务归类，一个微服务一个索引还是怎样

 其次确定存储哪些字段，要做哪些内容

需要数据建模：依据业务，参考如下，这是一个航班系统的业务

​![image](assets/image-20230801105830-yvecu3g.png)​

​​![image](assets/image-20230801105912-w8g7v5v.png)​

 索引创建一般可通过对应语言的官方库实现、也可以手动创建

## 6.建立可视化设计+监控

这一部分涉及的很多都是Kibana公司商业化的东西，也都是付费的

使用 Kibana 进行数据可视化和仪表盘的创建。例如，使用图表、图形等来展示数据，创建仪表盘来监控系统状态。

 --》涉及微服务可观测性

 使用图表和图形展示数据

## 7.数据查询和搜索

描述如何使用 Elasticsearch 进行数据查询和搜索。例如，使用查询语句来检索特定时间范围内的日志数据，根据关键字搜索日志信息等。

 在上一步骤完成后，可以依据索引进行搜索关键数据

 --》涉及Kibana官网文档

 --》常用的操作

上述是开发流程，下述是维护流程

---

## 8.安全和权限控制

保障系统的安全性

 --》权限控制管理

 对指定人员开通账户权限，可限制某些人看制定的索引记录；管理员拥有最高权限，即服务器管理员可控制用户访问；

## 9.高可用、故障恢复和备份策略（后续）

这部分目的是为了保障 ELK 系统的高可用性，制定的保护策略。可以后续或者整体架构搭起来再实现也不迟

主要从三方面着手考虑：

1. **Elasticsearch故障恢复**：

    * **备份和恢复**：定期使用Elasticsearch的snapshot API创建索引的快照。在发生故障时，可以使用这些快照恢复数据。
    * **副本和分片**：通过配置索引的副本和分片数量，可以提高数据的可用性和容错性。如果某个节点失败，Elasticsearch可以从其他节点的副本中恢复数据。
    * **集群健康监控**：定期检查Elasticsearch集群的健康状态，如果发现问题，可以及时进行故障转移或恢复。（集群实现）
2. **Logstash故障恢复**：

    * **持久化队列**：启用Logstash的持久化队列功能，可以在Logstash进程重启或崩溃时防止数据丢失。(可能会影响磁盘IO甚至影响logstash性能)
    * **多实例部署**：部署多个Logstash实例，可以提高处理能力和容错性。如果一个实例失败，其他实例可以继续处理数据。（集群实现）
3. **Kibana故障恢复**：

    * **备份和恢复**：定期备份Kibana的配置信息（保存在Elasticsearch的.kibana索引中）。在发生故障时，可以从备份中恢复配置。
    * **多实例部署**：部署多个Kibana实例，可以提高可用性。如果一个实例失败，用户可以连接到其他实例。（集群实现）

关于集群部分的考虑：

集群是否一定要搭建？目前测试服没有集群搭建计划 ，这部分以当前的数据量不需要复杂的搭建，可能     会制定故障恢复策略，属于上层建筑，可最后考虑

## 10.联合监控系统

 --》涉及监控系统搭建，短时间内不搭建/可搭建测试服，可后续考虑

 搭建Prometheus+Grafana监控系统实现对关键性能指标的监控

 搭建后可帮助优化ELK系统

 其实kibana也有微服务可观测性 （P＋G）更专业，重点是免费

## 11.功能测试、性能测试、压力测试。主要是功能测试

测试方面，分为本地环境测试、测试服上线测试，前期偏重对功能性的测试，后续稳定后，可写对性能和压力进行测试，以验证ELK系统的稳定性。

--》功能性测试：写Go、Java写一些业务程序/demo验证

--》性能、压力测试：JMeter、Gatling、Locust等工具来添加线程组模拟用户HTTP请求实现验证；也可以使用并发编程来验证

## 12.部署上线测试服

--》win搭建

--》Linux（docker）搭建

--》部署文档

--》制定上线计划

## 13.后续持续维护

 规划系统的后续维护工作。例如：定期维护策略和升级 ELK 组件等。

 --》维护文档

如：

​![ELK系统开发流程](assets/ELK系统开发流程-20230825135741-wntq6pf.png)​

[ELK系统开发流程.xmind](assets/ELK系统开发流程-20230825135751-0a91nrk.xmind)

---

​![ELK系统上线维护流程](assets/ELK系统上线维护流程-20230825140231-oy69b6u.png)​

[ELK系统维护流程.xmind](assets/ELK系统维护流程-20230825140020-5jo07bb.xmind)

# 管理与建设

在环境搭建完成后考虑的是如何管理和建设问题

考虑到问题与决策选择：

1.ES、Kibana 时间同步问题

2.中文设置

3.建立可视化－－仪表盘

4.中文插件　kibana中文设置

5.版本问题  [各版本官网](https://www.elastic.co/guide/en/elasticsearch/reference/index.html)

6.数据建模、业务与索引模式设计

7.sleuth+zipkin与ELK搭配使用？

8.在微服务架构下，每一个服务都会有链路追踪，是否在Kibana中要为每一个服务的链路追踪单独创立索引？

为每个服务的链路追踪数据单独创建索引可能会导致索引数量过多，管理和查询的复杂性增加。

主要使用以下两种方法来管理多个服务的链路追踪数据：

1. 单索引模式：将所有服务的链路追踪数据存储在一个索引中。这意味着所有服务的跟踪数据将被混合存储在同一个索引中。可以使用 Sleuth 支持的自定义 Span 名称、自定义标签等功能，将每个跟踪数据标记为属于哪个服务，以便后续查询和过滤。在 Kibana 中，您可以使用过滤器或搜索功能，根据服务名称或其他属性来查找和分析特定的服务链路追踪数据。
2. 多索引模式：为每个服务的链路追踪数据创建独立的索引。这种方式可以更好地隔离和管理不同服务的跟踪数据，但索引数量会增加。在 Kibana 中，您可以创建多个索引模式，分别关联到每个索引，并在仪表板和可视化中使用过滤器或搜索功能来选择特定的索引。

如果数据隔离要求较弱，或者管理和维护较多索引的复杂性较高，那么单索引模式可能更适合。如果数据隔离要求较强，或者需要针对不同服务进行更精细的查询和分析，那么多索引模式可能更适合。

9.X-pack 是面向收费的

​![image](assets/image-20230801192421-rv5djmp.png)​

‍

思考的问题：

1. [ELK时间显示数据量柱状图](https://blog.csdn.net/liaomingwu/article/details/123234927) 需要对应的时间字段名称：如timestamp
2. ES、Kibana 时间同步问题
3. docker 离线问题

**补充：**

---》kibana Dev tools　，比ES插件header更好用，是开发必备工具![00788843](assets/75DB708C-20220429135010-dgwr86t.png)​

---》优化方向：涉及如何优化 ELK 系统的性能，并进行系统的监控。例如，调整 Elasticsearch 的内存设置，优化查询性能，使用监控工具来监测系统运行状况等

‍
